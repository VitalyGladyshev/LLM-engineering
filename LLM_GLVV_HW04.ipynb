{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef538bfe-80e6-4d0a-84eb-103cabc635a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import torch, gc, os, math, random\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd6b96c5-c6b3-49ca-b6e2-61ae101a43d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "nvmlInit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe370538-ebcc-4bd7-9b42-04faafa20342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "904d2417-aae3-45a4-b185-b671e36d547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-09 17:10:30 [__init__.py:241] Automatically detected platform cuda.\n",
      "WARNING 09-09 17:10:30 [cuda.py:605] Detected different devices in the system: NVIDIA GeForce RTX 3090 Ti, NVIDIA GeForce RTX 3090. Please make sure to set `CUDA_DEVICE_ORDER=PCI_BUS_ID` to avoid unexpected behavior.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c940c92a-e77a-41bb-8da7-0d3705922198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, AutoTokenizer\n",
    "from trl import SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235d7e66-55cc-498f-a91d-fd84161c54b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aae08193-58ab-4ebb-878f-d13047002e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def gpu_mem(note=\"\"):\n",
    "    if not torch.cuda.is_available():\n",
    "        print(f\"[{note}] No CUDA available.\")\n",
    "        return\n",
    "    torch.cuda.synchronize()\n",
    "    alloc = torch.cuda.memory_allocated() / (1024**3)\n",
    "    resrv = torch.cuda.memory_reserved() / (1024**3)\n",
    "    peak = torch.cuda.max_memory_allocated() / (1024**3)\n",
    "    print(f\"[{note}] allocated={alloc:.2f}GB, reserved={resrv:.2f}GB, peak={peak:.2f}GB\")\n",
    "\n",
    "def nvidia_mem():\n",
    "    if not torch.cuda.is_available():\n",
    "        return\n",
    "\n",
    "    nvmlInit()\n",
    "    h = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(h)\n",
    "    print(f\"NVML used={info.used/(1024**3):.2f}GB / total={info.total/(1024**3):.2f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53310e3b-f80d-4703-8327-67cc9fea00dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fresh] allocated=0.00GB, reserved=0.00GB, peak=0.00GB\n",
      "NVML used=1.08GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "flush()\n",
    "gpu_mem(\"fresh\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f4099-b723-43af-8b0c-ad13de19e27c",
   "metadata": {},
   "source": [
    "## Модель Meta-Llama-3.1-8B-Instruct-bnb-4bit от Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67ed1d4a-0af9-4216-8d6c-33ee8a9c55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "063a7abe-3de6-423c-89b9-524263697962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Клонирование в «Llama-3.1-8B-Instruct»...\n",
      "remote: Enumerating objects: 109, done.\u001b[K\n",
      "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
      "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
      "remote: Total 109 (delta 53), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
      "Получение объектов: 100% (109/109), 2.28 МиБ | 4.57 МиБ/с, готово.\n",
      "Определение изменений: 100% (53/53), готово.\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://viv232:hf_xxxxx@huggingface.co/meta-llama/Llama-3.1-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b99b98b3-0693-4629-8b1b-b335b334031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"meta-llama/Llama-3.1-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70fef332-d529-4248-b804-52f43ef279e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Клонирование в «Meta-Llama-3.1-8B-Instruct-bnb-4bit»...\n",
      "remote: Enumerating objects: 131, done.\u001b[K\n",
      "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
      "remote: Compressing objects: 100% (128/128), done.\u001b[K\n",
      "remote: Total 131 (delta 44), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
      "Получение объектов: 100% (131/131), 2.30 МиБ | 3.76 МиБ/с, готово.\n",
      "Определение изменений: 100% (44/44), готово.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a947cca9-efef-4fff-bd48-df5455fe38a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b77bc1d-cb60-4a6f-8796-cc11c0f6dbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[before load QLoRA] allocated=0.00GB, reserved=0.00GB, peak=0.00GB\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 1024\n",
    "\n",
    "flush()\n",
    "gpu_mem(\"before load QLoRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "241ce030-458e-489f-9251-8738645afb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.1: Fast Llama patching. Transformers: 4.56.1. vLLM: 0.10.1.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090 Ti. Num GPUs = 2. Max memory: 23.536 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,    # QLoRA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d92c9bb0-b82d-44ae-9efb-2f1446b37e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.9.1 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c74494c0-c740-47c4-bda8-6ba576e544c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[after load QLoRA] allocated=5.50GB, reserved=5.52GB, peak=7.02GB\n",
      "NVML used=6.64GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"after load QLoRA\")\n",
    "nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cffbeac3-1aa3-4334-affb-3f56a43b3519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|eot_id|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78cd47d9-c4ef-4190-825e-6fe55aeb749e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чат-шаблон: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- set date_string = \"26 Jul 2024\" %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message + builtin tools #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if builtin_tools is defined or tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{%- if builtin_tools is defined %}\n",
      "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
      "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
      "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
      "                {%- if not loop.last %}\n",
      "                    {{- \", \" }}\n",
      "                {%- endif %}\n",
      "                {%- endfor %}\n",
      "            {{- \")\" }}\n",
      "        {%- else  %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "            {{- '\"parameters\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- \"}\" }}\n",
      "        {%- endif %}\n",
      "        {%- if builtin_tools is defined %}\n",
      "            {#- This means we're in ipython mode #}\n",
      "            {{- \"<|eom_id|>\" }}\n",
      "        {%- else %}\n",
      "            {{- \"<|eot_id|>\" }}\n",
      "        {%- endif %}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Чат-шаблон: {tokenizer.chat_template}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a7642-4e04-4f9d-b021-850f17422119",
   "metadata": {},
   "source": [
    "### Оценка до LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17984ca1-d489-4052-975a-2204a7946368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1193e7b9-9a9d-4049-9b1d-d5f156c506f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_for_test = [\n",
    "    'Как вкусно приготовить индейку на гриле?',\n",
    "    'Как распознать приближающийся инсульт?',\n",
    "    'Сформулируй основные каноны архитектуры древних цивилизаций',\n",
    "    'Облагать ли страховыми взносами суммы прощенного долга по займу от организации где работает застрахованный?',\n",
    "    'Расскажи мне про Курчатова'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a92eadf6-5744-4e0c-8fa8-f455409b518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(prompt):\n",
    "    dialog = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": prompt}], \n",
    "                                           tokenize=False, \n",
    "                                           add_generation_prompt=True)\n",
    "    inputs = tokenizer(dialog, return_tensors = \"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=300, use_cache=True)\n",
    "    return tokenizer.batch_decode(outputs)[0].split(\"assistant\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84e5b651-9400-4ff1-9ee8-7bf3d6b03690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|end_header_id|>\n",
      "\n",
      "Чтобы приготовить вкусную индейку на гриле, следуйте этим рекомендациям:\n",
      "\n",
      "**Приготовление индейки на гриле:**\n",
      "\n",
      "Ингредиенты:\n",
      "\n",
      "*   1 индейка (весом 1,5-2 кг)\n",
      "*   2 столовые ложки оливкового масла\n",
      "*   1 чайная ложка соли\n",
      "*   1 чайная ложка черного перца\n",
      "*   1 чайная ложка паприки\n",
      "*   1 чайная ложка чеснока, измельченного\n",
      "*   1 луковица, измельченная\n",
      "*   2 веточки розмарина (по желанию)\n",
      "*   1 лимон, нарезанный (по желанию)\n",
      "\n",
      "**Подготовка индейки:**\n",
      "\n",
      "1.  Налейте индейку в форму для гриля или на противень.\n",
      "2.  В миске смешайте оливковое масло, соль, черный перец, паприку, чеснок и лук.\n",
      "3.  Нанесите смесь на индейку, равномерно распределив ее по всей поверхности.\n",
      "4.  Добавьте розмарин и лимон по желанию.\n",
      "\n",
      "**Гриляние индейки:**\n",
      "\n",
      "1.  Разогрейте гриль до средней температуры.\n",
      "2.  П\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "Приближающийся инсульт может быть сложно распознать, особенно в его ранних стадиях. Однако существуют некоторые признаки и симптомы, которые могут указывать на потенциальный инсульт. Вот некоторые из них:\n",
      "\n",
      "1.  **Нарушение речи**: проблемы с речью, такие как затруднение произношения слов, трудности с пониманием или непонимание речи других людей.\n",
      "2.  **Нарушение зрения**: потеря зрения в одном или обоих глазах, слепота или двоение в глазах.\n",
      "3.  **Нарушение движений**: слабость или паралич в одной или обеих руках или ногах, трудности с ходьбой или потеря равновесия.\n",
      "4.  **Нарушение чувствительности**: потеря чувствительности в одной или обеих руках или ногах.\n",
      "5.  **Головная боль**: сильная головная боль, особенно в одной стороне головы.\n",
      "6.  **Синяя кожа**: синяя кожа на лице или конечностях.\n",
      "7.  **Нарушение памяти**: проблемы с памятью или внимание.\n",
      "8.  **Нарушение настроения**: перепады настроения или агрессивное поведение.\n",
      "9.  **Нарушение мыш\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "Архитектура древних цивилизаций включала в себя различные стили и принципы, но существуют некоторые общие каноны, которые были распространены среди различных культур. Вот некоторые основные каноны:\n",
      "\n",
      "1. **Симметрия и баланс**: Архитектура древних цивилизаций часто включала симметричные композиции, которые создавали чувство баланса и гармонии. Это могло выражаться в симметричной планировке зданий, фасадов и интерьеров.\n",
      "2. **Использование природных материалов**: Древние цивилизации часто использовали местные материалы, такие как камень, дерево, глина и кирпичи, для постройки зданий и сооружений.\n",
      "3. **Использование геометрических форм**: Архитектура древних цивилизаций часто включала использование геометрических форм, таких как круги, квадраты, треугольники и ромбы, для создания композиций и орнаментов.\n",
      "4. **Использование орнаментов**: Древние цивилизации часто использовали орнаменты, такие как узоры, мотивы и символы, для украшения зданий и сооружений.\n",
      "5. **Связь с природой**: Архитектура\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "Вопрос о взимании страховых взносов на суммы прощенного долга по займу от организации, где работает застрахованный, является сложным и зависит от ряда факторов. В России действуют следующие правила:\n",
      "\n",
      "1. **Законодательство**: Согласно статье 16.1 Налогового кодекса РФ, страховые взносы взимаются на доходы, полученные от предпринимательской деятельности, а также на суммы, полученные от реализации имущества, если оно не является основным имуществом организации. Однако, если организация предоставляет займы своим сотрудникам, то эти займы не должны учитываться в качестве доходов, если они не были возвращены в течение определенного срока.\n",
      "\n",
      "2. **Правило \"возвратности\"**: Согласно п. 5.15 Положения о страховых взносах, если организация предоставляет займы своим сотрудникам и не требует возврата, эти суммы не учитываются в качестве доходов и не облагаются страховыми взносами. Однако, если организация требует возврата, то эти суммы учитываются в качестве доходов и облагаются страховыми взносами.\n",
      "\n",
      "3. **Прокредитование сотрудников**: Если организация предоставляет своим сотрудникам кредиты под залог недвижимости или другого имущества, то\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "Курчатов - это русский учёный и изобретатель, который внес значительный вклад в развитие радиотехники и радиолокации. Он родился в 1903 году и умер в 1991 году.\n",
      "\n",
      "В годы Великой Отечественной войны Курчатов работал в области радиолокации и радиотехники, разрабатывая системы радиолокации и радиопередачи. После войны он продолжил свою работу в области радиотехники и радиолокации, в частности, в области разработки радиолокационных систем для военных целей.\n",
      "\n",
      "Курчатов также работал в области радиолокации и радиотехники в области гражданских приложений, например, в области телевидения и радиотелефонии. Он был одним из первых, кто использовал радиолокацию для навигации в гражданском воздухоплавании.\n",
      "\n",
      "Курчатов был также известен как организатор научно-технического труда и преподаватель. Он преподавал в высших учебных заведениях и был ректором Московского института инженеров радиотехники, электронной техники и автоматики.\n",
      "\n",
      "В 1951 году Курчатов был удостоен Сталинской премии за разработку радиолокационной системы \"Свема\". В 1960 году\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for text in prompts_for_test:\n",
    "    print(generate_answer(text))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd757c80-f9bc-40eb-8332-f3ecbe8c9ee0",
   "metadata": {},
   "source": [
    "lm_eval --model hf \\\n",
    "    --model_args pretrained=unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit,dtype=\"float\" \\\n",
    "    --tasks truthfulqa_ru_mc1 \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size auto:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d58037e0-e997-4caf-a3f9-3ad54c1743ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "INFO 09-09 14:33:34 [__init__.py:241] Automatically detected platform cuda.\n",
      "WARNING 09-09 14:33:34 [cuda.py:605] Detected different devices in the system: NVIDIA GeForce RTX 3090 Ti, NVIDIA GeForce RTX 3090. Please make sure to set `CUDA_DEVICE_ORDER=PCI_BUS_ID` to avoid unexpected behavior.\n",
      "2025-09-09:14:33:36 INFO     [__main__:446] Selected Tasks: ['truthfulqa_ru_mc1']\n",
      "2025-09-09:14:33:36 WARNING  [evaluator:172] pretrained=pretrained=unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit,dtype=float appears to be an instruct or chat variant but chat template is\n",
      "        not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).\n",
      "2025-09-09:14:33:36 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-09-09:14:33:36 INFO     [evaluator:240] Initializing hf model, with arguments: {'pretrained': 'unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit', 'dtype': 'float'}\n",
      "2025-09-09:14:33:36 INFO     [models.huggingface:147] Using device 'cuda:0'\n",
      "2025-09-09:14:33:37 INFO     [models.huggingface:414] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/quantizers/auto.py:239: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "2025-09-09:14:33:42 INFO     [api.task:434] Building contexts for truthfulqa_ru_mc1 on rank 0...\n",
      "100%|█████████████████████████████████████| 788/788 [00:00<00:00, 173706.39it/s]\n",
      "2025-09-09:14:33:42 INFO     [evaluator:574] Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|                  | 0/3961 [00:00<?, ?it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Determined largest batch size: 22\n",
      "Running loglikelihood requests:  24%|█▉      | 948/3961 [01:42<02:50, 17.65it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  24%|█▉      | 969/3961 [01:58<02:49, 17.65it/s]Determined largest batch size: 25\n",
      "Running loglikelihood requests:  49%|███▍   | 1950/3961 [03:09<01:48, 18.51it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  50%|███▍   | 1974/3961 [03:28<01:47, 18.51it/s]Determined largest batch size: 25\n",
      "Running loglikelihood requests:  74%|█████▏ | 2926/3961 [04:32<00:53, 19.41it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  74%|█████▏ | 2950/3961 [04:48<00:52, 19.41it/s]Determined largest batch size: 25\n",
      "Running loglikelihood requests:  99%|██████▉| 3930/3961 [05:54<00:01, 20.33it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests: 100%|██████▉| 3954/3961 [06:08<00:00, 20.33it/s]Determined largest batch size: 32\n",
      "Running loglikelihood requests: 100%|███████| 3961/3961 [06:21<00:00, 10.39it/s]\n",
      "fatal: не найден git репозиторий (или один из родительских каталогов): .git\n",
      "2025-09-09:14:40:06 INFO     [loggers.evaluation_tracker:280] Output path not provided, skipping saving results aggregated\n",
      "hf (pretrained=unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit,dtype=float), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto:4 (22,25,25,25,32)\n",
      "|      Tasks      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
      "|-----------------|------:|------|-----:|------|---|-----:|---|-----:|\n",
      "|truthfulqa_ru_mc1|      1|none  |     0|acc   |↑  |0.3185|±  |0.0166|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash ./lm-evaluation-harness/run_lmesh.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319e902-0ec2-4033-9f46-323e7dd7ed15",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c95b763-6617-4602-be3b-86195ffcceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 151822/151822 [00:00<00:00, 171669.37 examples/s]\n",
      "Generating test split: 100%|██████████| 3291/3291 [00:00<00:00, 157742.95 examples/s]\n"
     ]
    }
   ],
   "source": [
    "vikhr_dataset = load_dataset(\"Vikhrmodels/GrandMaster-PRO-MAX\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6783cb38-5c5a-45fa-afcb-64aeccafa5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'conversation', 'prompt_tokens', 'answer_tokens', 'cluster', 'prompt_lang', 'answer_lang'],\n",
       "    num_rows: 151822\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vikhr_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6c4ae45-abb2-44e9-a5a7-7a9be64a368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_russian(example):\n",
    "    return example['prompt_lang'] == 'ru' and example['answer_lang'] == 'ru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "646cb801-adcc-4f5c-8f7f-97af3321defb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 151822/151822 [00:01<00:00, 101434.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "vikhr_dataset = vikhr_dataset.filter(filter_russian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8322674c-7d75-4b69-a20c-9cae524c8f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86295"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vikhr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4033d046-bb07-41d3-bed5-8254711b520b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'слушай, у меня тут возникла задачка по архитектуре компьютера, и я не могу в ней разобраться. мне нужно разработать алгоритм, который оптимизирует доступ к кэш-памяти в многоядерном процессоре для параллельных вычислений. ты не мог бы помочь с этим? вот как я представляю задачу:\\n\\n1. имеется многоядерный процессор с общим кэшем второго уровня.\\n2. необходимо минимизировать промахи кэша при параллельном выполнении нескольких интенсивных задач по обработке данных.\\n3. алгоритм должен распределять данные таким образом, чтобы максимально использовать преимущества локальности данных и минимизировать конфликтные промахи.\\n\\nможет есть идеи, как это можно организовать на уровне алгоритма? буду рад любым предложениям и советам!',\n",
       "  'role': 'user'},\n",
       " {'content': 'Ваша задача действительно интересная и актуальная в контексте современных многоядерных процессоров. Для оптимизации доступа к кэш-памяти важно учитывать такие аспекты, как пространственная и временная локальность данных, а также избегать конфликтов при кэшировании. Вот основные шаги, которые помогут в разработке алгоритма:\\n\\n### Шаг 1: Анализ задач\\nПрежде всего, нужно проанализировать характеристики задач, которые будут выполняться параллельно. Важно понять, какие данные используются и как часто они запрашиваются.\\n\\n### Шаг 2: Разработка стратегии распределения данных\\nДалее, необходимо разработать стратегию, которая позволит распределить данные таким образом, чтобы максимально использовать преимущества пространственной и временной локальности. Это может включать в себя:\\n\\n- **Группировка связанных данных**: чтобы при обращении к одному элементу данных рядом находились и другие часто используемые элементы.\\n- **Разделение данных между ядрами**: чтобы каждое ядро работало с уникальным набором данных и минимизировать конфликтные промахи.\\n\\n### Шаг 3: Разбиение данных на блоки\\nПосле того как стратегия распределения данных разработана, следует разбить данные на блоки оптимального размера для кэширования. В идеале, размер блока должен соответствовать размеру линейки кэша.\\n\\n### Шаг 4: Реализация алгоритма предвыборки (prefetching)\\nРазработайте алгоритм предвыборки данных, который будет загружать данные в кэш заранее, основываясь на предсказании обращений к данным.\\n\\n### Шаг 5: Синхронизация доступа к данным\\nНеобходимо также обеспечить эффективную синхронизацию доступа к данным между ядрами, чтобы избежать ситуаций, когда несколько ядер одновременно обновляют данные в кэше.\\n\\n### Шаг 6: Тестирование и отладка\\nПроведите тестирование алгоритма на различных наборах данных и рабочих нагрузках. Оцените эффективность алгоритма, подсчитывая количество промахов кэша и сравнивая с базовым случаем.\\n\\n### Шаг 7: Итерация и оптимизация\\nНа основе полученных результатов внесите коррективы в алгоритм и повторите тестирование. Ищите возможности для дальнейшей оптимизации.\\n\\nЭти шаги должны помочь вам в разработке эффективного алгоритма оптимизации доступа к кэш-памяти для параллельных вычислений. Успехов в работе!',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vikhr_dataset[1][\"conversation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cb329e9-73fd-4731-b61c-7d9cc274eb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nслушай, у меня тут возникла задачка по архитектуре компьютера, и я не могу в ней разобраться. мне нужно разработать алгоритм, который оптимизирует доступ к кэш-памяти в многоядерном процессоре для параллельных вычислений. ты не мог бы помочь с этим? вот как я представляю задачу:\\n\\n1. имеется многоядерный процессор с общим кэшем второго уровня.\\n2. необходимо минимизировать промахи кэша при параллельном выполнении нескольких интенсивных задач по обработке данных.\\n3. алгоритм должен распределять данные таким образом, чтобы максимально использовать преимущества локальности данных и минимизировать конфликтные промахи.\\n\\nможет есть идеи, как это можно организовать на уровне алгоритма? буду рад любым предложениям и советам!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nВаша задача действительно интересная и актуальная в контексте современных многоядерных процессоров. Для оптимизации доступа к кэш-памяти важно учитывать такие аспекты, как пространственная и временная локальность данных, а также избегать конфликтов при кэшировании. Вот основные шаги, которые помогут в разработке алгоритма:\\n\\n### Шаг 1: Анализ задач\\nПрежде всего, нужно проанализировать характеристики задач, которые будут выполняться параллельно. Важно понять, какие данные используются и как часто они запрашиваются.\\n\\n### Шаг 2: Разработка стратегии распределения данных\\nДалее, необходимо разработать стратегию, которая позволит распределить данные таким образом, чтобы максимально использовать преимущества пространственной и временной локальности. Это может включать в себя:\\n\\n- **Группировка связанных данных**: чтобы при обращении к одному элементу данных рядом находились и другие часто используемые элементы.\\n- **Разделение данных между ядрами**: чтобы каждое ядро работало с уникальным набором данных и минимизировать конфликтные промахи.\\n\\n### Шаг 3: Разбиение данных на блоки\\nПосле того как стратегия распределения данных разработана, следует разбить данные на блоки оптимального размера для кэширования. В идеале, размер блока должен соответствовать размеру линейки кэша.\\n\\n### Шаг 4: Реализация алгоритма предвыборки (prefetching)\\nРазработайте алгоритм предвыборки данных, который будет загружать данные в кэш заранее, основываясь на предсказании обращений к данным.\\n\\n### Шаг 5: Синхронизация доступа к данным\\nНеобходимо также обеспечить эффективную синхронизацию доступа к данным между ядрами, чтобы избежать ситуаций, когда несколько ядер одновременно обновляют данные в кэше.\\n\\n### Шаг 6: Тестирование и отладка\\nПроведите тестирование алгоритма на различных наборах данных и рабочих нагрузках. Оцените эффективность алгоритма, подсчитывая количество промахов кэша и сравнивая с базовым случаем.\\n\\n### Шаг 7: Итерация и оптимизация\\nНа основе полученных результатов внесите коррективы в алгоритм и повторите тестирование. Ищите возможности для дальнейшей оптимизации.\\n\\nЭти шаги должны помочь вам в разработке эффективного алгоритма оптимизации доступа к кэш-памяти для параллельных вычислений. Успехов в работе!<|eot_id|>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template(vikhr_dataset[1][\"conversation\"], tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44cbfa61-543a-4cf8-8dee-012caede6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    return {\"text\": tokenizer.apply_chat_template(example[\"conversation\"], tokenize=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c682408-5a64-4532-b028-c93af43236b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_prep = vikhr_dataset.select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36f54688-5540-48ca-bf28-1237e217f86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check_data_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5908bdd0-6305-4689-a454-e11d00f8ed44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5/5 [00:00<00:00, 1229.86 examples/s]\n"
     ]
    }
   ],
   "source": [
    "check_data = check_data_prep.map(formatting_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e1ddf2d-2413-4daa-adcc-2b39c8618be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'conversation', 'prompt_tokens', 'answer_tokens', 'cluster', 'prompt_lang', 'answer_lang', 'text'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb4c4353-dbc3-4472-aee4-d72cf7da5706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'generated/saiga/tagengo/lmsys_pref',\n",
       " 'conversation': [{'content': 'мне очень интересны стратегические игры, и я недавно узнал про игру ним. не мог бы ты объяснить мне стратегию оптимальной игры в ним? и еще, если есть, поделись интересным вариантом игры в крестики-нолики или другие стратегические головоломки, в которые мы могли бы сыграть вместе. как насчет того, чтобы рассмотреть 15 puzzle? мне бы хотелось узнать, есть ли для неё какая-то выигрышная стратегия или подход, который гарантирует победу.',\n",
       "   'role': 'user'},\n",
       "  {'content': 'Расскажу тебе о стратегиях игры в Ним и затрону тему 15 Puzzle.\\n\\n### Стратегия оптимальной игры в Ним\\n\\nИгра Ним — это математическая игра, для которой существует чёткая выигрышная стратегия. Основа стратегии лежит в понятии ним-суммы — это побитовое исключающее ИЛИ (XOR) размеров кучек.\\n\\nОптимальная стратегия заключается в следующем:\\n\\n1. Вычисли ним-сумму всех кучек.\\n2. Если ним-сумма равна нулю, то ваше положение проигрышное при оптимальной игре соперника. В этом случае просто делайте ход и старайтесь создать трудности для соперника.\\n3. Если ним-сумма не равна нулю, вам нужно сделать ход, который уменьшит размер одной из кучек так, чтобы новая ним-сумма всех кучек была равна нулю.\\n4. После вашего хода соперник окажется в положении с ним-суммой равной нулю, что является проигрышным положением при вашей оптимальной игре.\\n\\n### Играем в крестики-нолики\\n\\nЧто касается крестиков-ноликов, можно попробовать игру на расширенном поле 5x5 или 10x10, где для победы нужно выстроить ряд из 5 символов. Это добавит сложности и стратегической глубины.\\n\\n### 15 Puzzle (Пятнашки)\\n\\n15 Puzzle — это головоломка с плитками, которые нужно упорядочить по порядку, перемещая их в пустое пространство. \\n\\nДля 15 Puzzle существуют алгоритмы, которые позволяют определить решаемость пазла (не все начальные позиции решаемы) и выигрышная стратегия, если пазл решаем. Основной подход к решению:\\n\\n1. Разделите пазл на зоны и решайте поэтапно (например, сначала верхние две строки, затем левая половина и т.д.).\\n2. Используйте алгоритмы для перестановки плиток, которые минимизируют количество нежелательных изменений (например, метод \"переворота угла\").\\n3. Для каждого этапа запоминайте последовательность ходов, которая позволяет решать типичные задачи (например, как поменять местами две конкретные плитки).\\n\\nСложность заключается в том, что без знания алгоритмов и последовательностей ходов решить пазл может быть довольно непросто, особенно если вы не имеете опыта с подобными головоломками. Но при наличии практики и понимания методов, пазл становится решаемым практически всегда.',\n",
       "   'role': 'assistant'}],\n",
       " 'prompt_tokens': 185,\n",
       " 'answer_tokens': 894,\n",
       " 'cluster': 21,\n",
       " 'prompt_lang': 'ru',\n",
       " 'answer_lang': 'ru',\n",
       " 'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nмне очень интересны стратегические игры, и я недавно узнал про игру ним. не мог бы ты объяснить мне стратегию оптимальной игры в ним? и еще, если есть, поделись интересным вариантом игры в крестики-нолики или другие стратегические головоломки, в которые мы могли бы сыграть вместе. как насчет того, чтобы рассмотреть 15 puzzle? мне бы хотелось узнать, есть ли для неё какая-то выигрышная стратегия или подход, который гарантирует победу.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nРасскажу тебе о стратегиях игры в Ним и затрону тему 15 Puzzle.\\n\\n### Стратегия оптимальной игры в Ним\\n\\nИгра Ним — это математическая игра, для которой существует чёткая выигрышная стратегия. Основа стратегии лежит в понятии ним-суммы — это побитовое исключающее ИЛИ (XOR) размеров кучек.\\n\\nОптимальная стратегия заключается в следующем:\\n\\n1. Вычисли ним-сумму всех кучек.\\n2. Если ним-сумма равна нулю, то ваше положение проигрышное при оптимальной игре соперника. В этом случае просто делайте ход и старайтесь создать трудности для соперника.\\n3. Если ним-сумма не равна нулю, вам нужно сделать ход, который уменьшит размер одной из кучек так, чтобы новая ним-сумма всех кучек была равна нулю.\\n4. После вашего хода соперник окажется в положении с ним-суммой равной нулю, что является проигрышным положением при вашей оптимальной игре.\\n\\n### Играем в крестики-нолики\\n\\nЧто касается крестиков-ноликов, можно попробовать игру на расширенном поле 5x5 или 10x10, где для победы нужно выстроить ряд из 5 символов. Это добавит сложности и стратегической глубины.\\n\\n### 15 Puzzle (Пятнашки)\\n\\n15 Puzzle — это головоломка с плитками, которые нужно упорядочить по порядку, перемещая их в пустое пространство. \\n\\nДля 15 Puzzle существуют алгоритмы, которые позволяют определить решаемость пазла (не все начальные позиции решаемы) и выигрышная стратегия, если пазл решаем. Основной подход к решению:\\n\\n1. Разделите пазл на зоны и решайте поэтапно (например, сначала верхние две строки, затем левая половина и т.д.).\\n2. Используйте алгоритмы для перестановки плиток, которые минимизируют количество нежелательных изменений (например, метод \"переворота угла\").\\n3. Для каждого этапа запоминайте последовательность ходов, которая позволяет решать типичные задачи (например, как поменять местами две конкретные плитки).\\n\\nСложность заключается в том, что без знания алгоритмов и последовательностей ходов решить пазл может быть довольно непросто, особенно если вы не имеете опыта с подобными головоломками. Но при наличии практики и понимания методов, пазл становится решаемым практически всегда.<|eot_id|>'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "708343a9-a718-4c84-81d5-032b6fd02c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nмне очень интересны стратегические игры, и я недавно узнал про игру ним. не мог бы ты объяснить мне стратегию оптимальной игры в ним? и еще, если есть, поделись интересным вариантом игры в крестики-нолики или другие стратегические головоломки, в которые мы могли бы сыграть вместе. как насчет того, чтобы рассмотреть 15 puzzle? мне бы хотелось узнать, есть ли для неё какая-то выигрышная стратегия или подход, который гарантирует победу.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nРасскажу тебе о стратегиях игры в Ним и затрону тему 15 Puzzle.\\n\\n### Стратегия оптимальной игры в Ним\\n\\nИгра Ним — это математическая игра, для которой существует чёткая выигрышная стратегия. Основа стратегии лежит в понятии ним-суммы — это побитовое исключающее ИЛИ (XOR) размеров кучек.\\n\\nОптимальная стратегия заключается в следующем:\\n\\n1. Вычисли ним-сумму всех кучек.\\n2. Если ним-сумма равна нулю, то ваше положение проигрышное при оптимальной игре соперника. В этом случае просто делайте ход и старайтесь создать трудности для соперника.\\n3. Если ним-сумма не равна нулю, вам нужно сделать ход, который уменьшит размер одной из кучек так, чтобы новая ним-сумма всех кучек была равна нулю.\\n4. После вашего хода соперник окажется в положении с ним-суммой равной нулю, что является проигрышным положением при вашей оптимальной игре.\\n\\n### Играем в крестики-нолики\\n\\nЧто касается крестиков-ноликов, можно попробовать игру на расширенном поле 5x5 или 10x10, где для победы нужно выстроить ряд из 5 символов. Это добавит сложности и стратегической глубины.\\n\\n### 15 Puzzle (Пятнашки)\\n\\n15 Puzzle — это головоломка с плитками, которые нужно упорядочить по порядку, перемещая их в пустое пространство. \\n\\nДля 15 Puzzle существуют алгоритмы, которые позволяют определить решаемость пазла (не все начальные позиции решаемы) и выигрышная стратегия, если пазл решаем. Основной подход к решению:\\n\\n1. Разделите пазл на зоны и решайте поэтапно (например, сначала верхние две строки, затем левая половина и т.д.).\\n2. Используйте алгоритмы для перестановки плиток, которые минимизируют количество нежелательных изменений (например, метод \"переворота угла\").\\n3. Для каждого этапа запоминайте последовательность ходов, которая позволяет решать типичные задачи (например, как поменять местами две конкретные плитки).\\n\\nСложность заключается в том, что без знания алгоритмов и последовательностей ходов решить пазл может быть довольно непросто, особенно если вы не имеете опыта с подобными головоломками. Но при наличии практики и понимания методов, пазл становится решаемым практически всегда.<|eot_id|>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b77849b-b3e2-45f6-802a-2c7f2cbcb4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 86295/86295 [00:10<00:00, 8503.30 examples/s] \n"
     ]
    }
   ],
   "source": [
    "train_data = vikhr_dataset.map(formatting_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c3f7a9-bd87-4613-a9da-22946c77b31d",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8406e941-3d1e-439e-82e2-4f39fbbdee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=24): 100%|██████████| 86295/86295 [00:07<00:00, 11717.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_data,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = SFTConfig(\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=30,\n",
    "        num_train_epochs=1,\n",
    "        max_steps=100,\n",
    "        learning_rate=2e-3,\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51a93a66-43b4-446f-bacf-81aeac3de5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA before train] allocated=5.50GB, reserved=5.52GB, peak=7.02GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA before train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5225d2b-b300-4353-a2c7-28bd8738cfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "2.7.1+cu126\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(torch.__version__); print(torch.cuda.is_available())\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7027802-6562-42f6-a909-fd7b2e703939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccd7ad18-187c-4576-b33d-d3aa8d870d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device count: 2\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 3090 Ti\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd6254b7-d7ca-48c3-9175-fb4448247d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 86,295 | Num Epochs = 1 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 35:15, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.319000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.439800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.394200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.206600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.215700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.084200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.080200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.121300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.140200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.992200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.944200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.955500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.963900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.985900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.056100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.995500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.080800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.988700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.975700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.972800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.940700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.907100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.980400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.089000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.071900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.979400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.971400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.987300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.990700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.983900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.941500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.083600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.989900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.930900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.021200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.963200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.920500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.871800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.969800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.924000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.866200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.949600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.955300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.998600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.834200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.976500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.980300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.954400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.916600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.964500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.943100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.968700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.992100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.948800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.943900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.982300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.906900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.983300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.897900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.984300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.903100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.873400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.871100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.940300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.866000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>1.014100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.842600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.977100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.924700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.950700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.966900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.873500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.954800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.995800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "554314e2-af7a-4ca1-a9e9-d1de5e0ce21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=5.77GB, reserved=10.22GB, peak=11.74GB\n",
      "NVML used=11.35GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41e70f11-0c48-47bf-b93b-1929813862f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_model/tokenizer_config.json',\n",
       " 'lora_model/special_tokens_map.json',\n",
       " 'lora_model/chat_template.jinja',\n",
       " 'lora_model/tokenizer.json')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"lora_model\")\n",
    "tokenizer.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba60ed9a-3cf3-407c-be79-d6a0b42bbc57",
   "metadata": {},
   "source": [
    "### Оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d2e4c5c-ae46-4290-af66-3ce2e17b6e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.1: Fast Llama patching. Transformers: 4.56.1. vLLM: 0.10.1.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090 Ti. Num GPUs = 2. Max memory: 23.536 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.9.1 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"lora_model\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,    # QLoRA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "397e307f-b719-4b2b-961d-d39c2187c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found HuggingFace hub cache directory: /home/viv232/.cache/huggingface/hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking cache directory for required files...\n",
      "Cache check failed: model-00001-of-00004.safetensors not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|██████████| 4/4 [36:15<00:00, 543.96s/it]\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(\"llama-3.1-8B-instruct_lora_ru\", tokenizer, save_method=\"merged_16bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07160058-de60-4d8d-8943-35e156fcc7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|end_header_id|>\n",
      "\n",
      "Конечно, давайте разберемся, как можно приготовить вкусную индейку на гриле.\n",
      "\n",
      "### Шаги приготовления индейки на гриле:\n",
      "\n",
      "#### Шаг 1: Подготовка индейки\n",
      "Прежде всего, убедитесь, что у вас есть свежая индейка. Если индейка заморожена, её нужно разморозить.\n",
      "\n",
      "#### Шаг 2: Маринад\n",
      "Маринад помогает индейке стать более сочной и ароматной. В блендере смешайте:\n",
      "- 1/2 стакана оливкового масла\n",
      "- 2 столовые ложки лимонного сока\n",
      "- 1 столовая ложка соли\n",
      "- 1 столовая ложка сахара\n",
      "- 2 зубчика чеснока, измельченного\n",
      "- 1 чайную ложку молотого черного перца\n",
      "- 1 чайную ложку молотого орегано\n",
      "- 1 чайную ложку молотого розмарина\n",
      "\n",
      "#### Шаг 3: Нарезка индейки\n",
      "Нарежьте индейку на порции. Если у вас есть грудка, режьте её поперёк волокон на порции. Если у вас есть ножка, режьте её на порции по 1-2 стебельцам. Если у\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "Исходя из вашего вопроса, можно предположить, что вы ищете информацию о признаках приближающегося инсульта. Инсульт – это острое нарушение мозгового кровообращения, которое может привести к повреждению мозговых тканей. Проблемы с кровообращением в мозге могут возникать из-за различных причин, включая высокое кровяное давление, атеросклероз, диабет, курение и другие.\n",
      "\n",
      "Чтобы распознать приближающийся инсульт, необходимо обратить внимание на следующие признаки:\n",
      "\n",
      "1. **Тошнота и рвота**: Это может быть одним из первых признаков приближающегося инсульта, особенно если они появляются без видимой причины.\n",
      "2. **Головная боль**: Острая головная боль, особенно в левом или правом затылке, может быть признаком приближающегося инсульта.\n",
      "3. **Дезориентация и нарушения сознания**: У людей с приближающимся инсультом может возникнуть ощущение потерянности, недоумение или потеря сознания.\n",
      "4. **Нарушения речи**: Сложности с речью, включая бормотание, заминки или полное отсутств\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "Каноны архитектуры древних цивилизаций включают в себя ряд общих принципов и правил, которые применялись при проектировании и строительстве зданий, сооружений и городов в древности. Вот основные из них:\n",
      "\n",
      "### 1. Принципы симметрии\n",
      "- **Асимметрия**: Некоторые древние стили использовали асимметрию, чтобы создавать ощущение динамики и движения.\n",
      "- **Симметрия**: Симметрия использовалась для создания чувства гармонии и баланса.\n",
      "\n",
      "### 2. Принципы пропорций\n",
      "- **Геометрические пропорции**: Использование простых геометрических форм и соотношений для создания гармоничных композиций.\n",
      "- **Пропорциональность**: Соответствие размеров элементов здания, чтобы создавать чувство единства и баланса.\n",
      "\n",
      "### 3. Участие природы\n",
      "- **Адаптация к окружающей среде**: Здания часто проектировались с учетом местных климатических и геологических условий.\n",
      "- **Использование природных материалов**: Материалы, такие как камень, дерево, были часто использованы в архитектуре для создания естественного внешнего вида.\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "Облагать страховыми взносами суммы прощенного долга по займу от организации, где работает застрахованный, не является обычной практикой. В большинстве стран и регионов страховые взносы рассчитываются на основе заработной платы застрахованного и не зависят от его личных долгов или взаимоотношений с работодателями.\n",
      "\n",
      "### Общие принципы страховых взносов:\n",
      "\n",
      "1. **Страховые взносы** – это обязательные взносы, которые работодатели вносят на страхование своих сотрудников.\n",
      "2. **Обязательность** – страховые взносы обязательны для работодателей, которые имеют определенное количество сотрудников или превышают определенный порог доходов.\n",
      "3. **Страховые взносы** не зависят от личных финансовых обстоятельий сотрудников. Они рассчитываются на основе заработной платы сотрудников, а не на основе их долгов или личных финансовых состояний.\n",
      "\n",
      "### Вопросы, которые могут возникнуть:\n",
      "\n",
      "- **Случай, когда работодатель является кредитором:** Если работодатель является кредитором и прощает долг сотруднику, он может получить компенсацию от страховой организации за страховые взносы, которые он уже уплатил за этого сотрудника в течение времени, когда сотрудник был его к\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "Курчатов, Игорь Васильевич — это имя, которое ассоциируется с многими вещами, включая физику, атомную энергетику и образование. Вот краткое описание, связанное с этим именем:\n",
      "\n",
      "### Биография\n",
      "Игорь Васильевич Курчатов родился 12 января 1902 года в деревне Солдатское, в семье служащего железнодорожной станции. Умер 26 февраля 1960 года в Москве.\n",
      "\n",
      "### Научная деятельность\n",
      "Курчатов был выдающимся советским ученым-теоретиком и экспериментатором, который работал в области ядерной физики. Он получил известность благодаря своим исследованиям в области ядерных реакций и разработке атомной бомбы. Курчатов был директором Института атомной энергии (ныне Институт Курчатова), который он основал в 1943 году.\n",
      "\n",
      "### Основные достижения\n",
      "- **Ядерная физика**: Курчатов сделал значительный вклад в понимание ядерных реакций и разработку ядерного оружия. Он предложил принципы и методы для создания атомной бомбы.\n",
      "- **Институт атомной энергии**: Курчатов основал Институт атомной энергии, который стал одним из\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for text in prompts_for_test:\n",
    "    print(generate_answer(text))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf00683b-ed7d-4a5a-b964-e6139ed2f521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA before train] allocated=5.69GB, reserved=5.84GB, peak=7.08GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA before train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a988d7c8-ae50-4cc2-9067-a5ffd42da3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVML used=7.19GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5f92b01-c24d-4535-a0cd-fadf415a02cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# del tokenizer\n",
    "# del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ff541d1-ea0d-4154-9075-3a966ec0348f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44949"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11fe3896-3872-4e28-a469-47f4bcf3eafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA before train] allocated=0.12GB, reserved=5.84GB, peak=7.08GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA before train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f44d68ad-499d-49d9-8d8d-e09a8b384824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVML used=7.28GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da2ed3c3-24fb-4085-94fe-b8c6c83295f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "162a2c5c-3d63-4781-be4c-808c95a68c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA before train] allocated=0.12GB, reserved=0.16GB, peak=7.08GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA before train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7651a35-ce50-40ea-aa22-2ebc0f666daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVML used=1.58GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0377618-8833-4384-bf17-f26b5fb62406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVML used=1.57GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30e370e0-8269-4ee9-9abf-420560e2a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "INFO 09-09 18:16:51 [__init__.py:241] Automatically detected platform cuda.\n",
      "WARNING 09-09 18:16:51 [cuda.py:605] Detected different devices in the system: NVIDIA GeForce RTX 3090 Ti, NVIDIA GeForce RTX 3090. Please make sure to set `CUDA_DEVICE_ORDER=PCI_BUS_ID` to avoid unexpected behavior.\n",
      "2025-09-09:18:16:53 INFO     [__main__:446] Selected Tasks: ['truthfulqa_ru_mc1']\n",
      "2025-09-09:18:16:53 WARNING  [evaluator:172] pretrained=pretrained=llama-3.1-8B-instruct_lora_ru,dtype=float appears to be an instruct or chat variant but chat template is not applied.\n",
      "        Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).\n",
      "2025-09-09:18:16:53 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-09-09:18:16:53 INFO     [evaluator:240] Initializing hf model, with arguments: {'pretrained': 'llama-3.1-8B-instruct_lora_ru', 'dtype': 'float'}\n",
      "2025-09-09:18:16:53 INFO     [models.huggingface:147] Using device 'cuda:0'\n",
      "2025-09-09:18:16:53 INFO     [models.huggingface:414] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards:  50%|█████████         | 2/4 [00:01<00:01,  1.72it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/viv232/anaconda3/envs/peft/bin/lm_eval\", line 7, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/llm-eng/12 PEFT/lm-evaluation-harness/lm_eval/__main__.py\", line 455, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/llm-eng/12 PEFT/lm-evaluation-harness/lm_eval/utils.py\", line 456, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/llm-eng/12 PEFT/lm-evaluation-harness/lm_eval/evaluator.py\", line 245, in simple_evaluate\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/llm-eng/12 PEFT/lm-evaluation-harness/lm_eval/api/model.py\", line 155, in create_from_arg_string\n",
      "    return cls(**args, **args2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/llm-eng/12 PEFT/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 210, in __init__\n",
      "    self._create_model(\n",
      "  File \"/home/viv232/llm-eng/12 PEFT/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 622, in _create_model\n",
      "    self._model = self.AUTO_MODEL_CLASS.from_pretrained(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py\", line 604, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 288, in _wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 5176, in from_pretrained\n",
      "    ) = cls._load_pretrained_model(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 5639, in _load_pretrained_model\n",
      "    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)\n",
      "                                                         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 946, in load_shard_file\n",
      "    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 815, in _load_state_dict_into_meta_model\n",
      "    param = param.to(casting_dtype)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 23.54 GiB of which 167.88 MiB is free. Process 7515 has 500.00 MiB memory in use. Including non-PyTorch memory, this process has 22.25 GiB memory in use. Of the allocated memory 21.80 GiB is allocated by PyTorch, and 161.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "!bash ./lm-evaluation-harness/run_lmesh_lora.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cced6b79-a881-4963-b416-487064b32aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.1: Fast Llama patching. Transformers: 4.56.1. vLLM: 0.10.1.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090 Ti. Num GPUs = 2. Max memory: 23.536 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"lora_model\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,    # QLoRA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cc2448b-95f3-4cbb-8c2a-59bcb7ef0e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging LoRA weights into 4bit model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging finished.\n",
      "Unsloth: Found skipped modules: ['lm_head']. Updating config.\n",
      "Unsloth: Saving merged 4bit model to llama-3.1-8B-instruct_lora_ru-4bit...\n",
      "Unsloth: Merged 4bit model saved.\n",
      "Unsloth: Merged 4bit model process completed.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(\"llama-3.1-8B-instruct_lora_ru-4bit\", tokenizer, save_method=\"merged_4bit_forced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d314208-e911-447f-ae7f-685e34f19a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "INFO 09-09 18:28:38 [__init__.py:241] Automatically detected platform cuda.\n",
      "WARNING 09-09 18:28:38 [cuda.py:605] Detected different devices in the system: NVIDIA GeForce RTX 3090 Ti, NVIDIA GeForce RTX 3090. Please make sure to set `CUDA_DEVICE_ORDER=PCI_BUS_ID` to avoid unexpected behavior.\n",
      "2025-09-09:18:28:40 INFO     [__main__:446] Selected Tasks: ['truthfulqa_ru_mc1']\n",
      "2025-09-09:18:28:40 WARNING  [evaluator:172] pretrained=pretrained=llama-3.1-8B-instruct_lora_ru-4bit,dtype=float appears to be an instruct or chat variant but chat template is not\n",
      "        applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).\n",
      "2025-09-09:18:28:40 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-09-09:18:28:40 INFO     [evaluator:240] Initializing hf model, with arguments: {'pretrained': 'llama-3.1-8B-instruct_lora_ru-4bit', 'dtype': 'float'}\n",
      "2025-09-09:18:28:40 INFO     [models.huggingface:147] Using device 'cuda:0'\n",
      "2025-09-09:18:28:40 INFO     [models.huggingface:414] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/quantizers/auto.py:239: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:00<00:00,  3.12it/s]\n",
      "README.md: 3.45kB [00:00, 8.66MB/s]\n",
      "data/ru/val.jsonl: 100%|███████████████████| 2.84M/2.84M [00:01<00:00, 1.71MB/s]\n",
      "Generating val split: 100%|█████████| 788/788 [00:00<00:00, 21785.72 examples/s]\n",
      "Map: 100%|██████████████████████████| 788/788 [00:00<00:00, 25013.14 examples/s]\n",
      "2025-09-09:18:28:48 INFO     [api.task:434] Building contexts for truthfulqa_ru_mc1 on rank 0...\n",
      "100%|█████████████████████████████████████| 788/788 [00:00<00:00, 204031.83it/s]\n",
      "2025-09-09:18:28:48 INFO     [evaluator:574] Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|                  | 0/3961 [00:00<?, ?it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Determined largest batch size: 19\n",
      "Running loglikelihood requests:  24%|█▉      | 952/3961 [01:50<03:06, 16.14it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  24%|█▉      | 970/3961 [02:02<03:05, 16.14it/s]Determined largest batch size: 22\n",
      "Running loglikelihood requests:  49%|███▍   | 1944/3961 [03:21<01:52, 17.88it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  50%|███▍   | 1965/3961 [03:32<01:51, 17.88it/s]Determined largest batch size: 22\n",
      "Running loglikelihood requests:  74%|█████▏ | 2935/3961 [04:50<00:56, 18.23it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  75%|█████▏ | 2956/3961 [05:02<00:55, 18.23it/s]Determined largest batch size: 25\n",
      "Running loglikelihood requests:  99%|██████▉| 3911/3961 [06:10<00:02, 19.59it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  99%|██████▉| 3935/3961 [06:22<00:01, 19.59it/s]Determined largest batch size: 28\n",
      "Running loglikelihood requests: 100%|███████| 3961/3961 [06:38<00:00,  9.93it/s]\n",
      "fatal: не найден git репозиторий (или один из родительских каталогов): .git\n",
      "2025-09-09:18:35:30 INFO     [loggers.evaluation_tracker:280] Output path not provided, skipping saving results aggregated\n",
      "hf (pretrained=llama-3.1-8B-instruct_lora_ru-4bit,dtype=float), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto:4 (19,22,22,25,28)\n",
      "|      Tasks      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
      "|-----------------|------:|------|-----:|------|---|-----:|---|-----:|\n",
      "|truthfulqa_ru_mc1|      1|none  |     0|acc   |↑  |0.3261|±  |0.0167|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash ./lm-evaluation-harness/run_lmesh_lora.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a74cfc-a2fa-4c9a-8617-8314572915ac",
   "metadata": {},
   "source": [
    "## Модель YandexGPT-5-Lite-8B-instruct LoRA PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad27aa7f-ae2b-4804-88b8-8cf2bc14aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8335045-7154-4588-91e0-78abe3bc7adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['UNSLOTH_DISABLE'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48402818-de99-48c2-9bbb-ce5725dcf9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"yandex/YandexGPT-5-Lite-8B-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a1736cc-4219-4a83-945e-9209814ab2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конфигурация 4-битной квантизации для QLoRA\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f899d234-1873-445d-8859-844285e44657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка токенизатора\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    use_fast=False  # Используем оригинальный токенизатор, а не FastTokenizers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a5fa8de-525a-42df-aeb5-5739ee73db16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92f95eec-96ba-4643-ab14-c57ee026ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ae34ff7-b26c-4521-a3f3-463dbf56e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffd019d8-1eac-4eed-a21c-5a81afcecb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    dtype=torch.float16,  # Явно указываем тип данных\n",
    "    trust_remote_code=True,\n",
    "    use_cache=False,  # Должно быть False при gradient checkpointing\n",
    "    low_cpu_mem_usage=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41f51aaf-5bec-495d-b20d-3683cc7aa6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка модели для k-bit обучения\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2238779c-a2c0-4f64-8826-8198d26bef58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA before train] allocated=2.81GB, reserved=4.11GB, peak=3.79GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA before train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be6d42f9-dedc-4343-9876-800eb09e79b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVML used=5.24GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c3e3798-b614-41a4-901c-0f51ef09c950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a6c4932-82b1-480a-9f2c-0c5e39730fba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0.self_attn.q_proj\n",
      "model.layers.0.self_attn.k_proj\n",
      "model.layers.0.self_attn.v_proj\n",
      "model.layers.0.self_attn.o_proj\n",
      "model.layers.0.mlp.gate_proj\n",
      "model.layers.0.mlp.up_proj\n",
      "model.layers.0.mlp.down_proj\n",
      "model.layers.1.self_attn.q_proj\n",
      "model.layers.1.self_attn.k_proj\n",
      "model.layers.1.self_attn.v_proj\n",
      "model.layers.1.self_attn.o_proj\n",
      "model.layers.1.mlp.gate_proj\n",
      "model.layers.1.mlp.up_proj\n",
      "model.layers.1.mlp.down_proj\n",
      "model.layers.2.self_attn.q_proj\n",
      "model.layers.2.self_attn.k_proj\n",
      "model.layers.2.self_attn.v_proj\n",
      "model.layers.2.self_attn.o_proj\n",
      "model.layers.2.mlp.gate_proj\n",
      "model.layers.2.mlp.up_proj\n",
      "model.layers.2.mlp.down_proj\n",
      "model.layers.3.self_attn.q_proj\n",
      "model.layers.3.self_attn.k_proj\n",
      "model.layers.3.self_attn.v_proj\n",
      "model.layers.3.self_attn.o_proj\n",
      "model.layers.3.mlp.gate_proj\n",
      "model.layers.3.mlp.up_proj\n",
      "model.layers.3.mlp.down_proj\n",
      "model.layers.4.self_attn.q_proj\n",
      "model.layers.4.self_attn.k_proj\n",
      "model.layers.4.self_attn.v_proj\n",
      "model.layers.4.self_attn.o_proj\n",
      "model.layers.4.mlp.gate_proj\n",
      "model.layers.4.mlp.up_proj\n",
      "model.layers.4.mlp.down_proj\n",
      "model.layers.5.self_attn.q_proj\n",
      "model.layers.5.self_attn.k_proj\n",
      "model.layers.5.self_attn.v_proj\n",
      "model.layers.5.self_attn.o_proj\n",
      "model.layers.5.mlp.gate_proj\n",
      "model.layers.5.mlp.up_proj\n",
      "model.layers.5.mlp.down_proj\n",
      "model.layers.6.self_attn.q_proj\n",
      "model.layers.6.self_attn.k_proj\n",
      "model.layers.6.self_attn.v_proj\n",
      "model.layers.6.self_attn.o_proj\n",
      "model.layers.6.mlp.gate_proj\n",
      "model.layers.6.mlp.up_proj\n",
      "model.layers.6.mlp.down_proj\n",
      "model.layers.7.self_attn.q_proj\n",
      "model.layers.7.self_attn.k_proj\n",
      "model.layers.7.self_attn.v_proj\n",
      "model.layers.7.self_attn.o_proj\n",
      "model.layers.7.mlp.gate_proj\n",
      "model.layers.7.mlp.up_proj\n",
      "model.layers.7.mlp.down_proj\n",
      "model.layers.8.self_attn.q_proj\n",
      "model.layers.8.self_attn.k_proj\n",
      "model.layers.8.self_attn.v_proj\n",
      "model.layers.8.self_attn.o_proj\n",
      "model.layers.8.mlp.gate_proj\n",
      "model.layers.8.mlp.up_proj\n",
      "model.layers.8.mlp.down_proj\n",
      "model.layers.9.self_attn.q_proj\n",
      "model.layers.9.self_attn.k_proj\n",
      "model.layers.9.self_attn.v_proj\n",
      "model.layers.9.self_attn.o_proj\n",
      "model.layers.9.mlp.gate_proj\n",
      "model.layers.9.mlp.up_proj\n",
      "model.layers.9.mlp.down_proj\n",
      "model.layers.10.self_attn.q_proj\n",
      "model.layers.10.self_attn.k_proj\n",
      "model.layers.10.self_attn.v_proj\n",
      "model.layers.10.self_attn.o_proj\n",
      "model.layers.10.mlp.gate_proj\n",
      "model.layers.10.mlp.up_proj\n",
      "model.layers.10.mlp.down_proj\n",
      "model.layers.11.self_attn.q_proj\n",
      "model.layers.11.self_attn.k_proj\n",
      "model.layers.11.self_attn.v_proj\n",
      "model.layers.11.self_attn.o_proj\n",
      "model.layers.11.mlp.gate_proj\n",
      "model.layers.11.mlp.up_proj\n",
      "model.layers.11.mlp.down_proj\n",
      "model.layers.12.self_attn.q_proj\n",
      "model.layers.12.self_attn.k_proj\n",
      "model.layers.12.self_attn.v_proj\n",
      "model.layers.12.self_attn.o_proj\n",
      "model.layers.12.mlp.gate_proj\n",
      "model.layers.12.mlp.up_proj\n",
      "model.layers.12.mlp.down_proj\n",
      "model.layers.13.self_attn.q_proj\n",
      "model.layers.13.self_attn.k_proj\n",
      "model.layers.13.self_attn.v_proj\n",
      "model.layers.13.self_attn.o_proj\n",
      "model.layers.13.mlp.gate_proj\n",
      "model.layers.13.mlp.up_proj\n",
      "model.layers.13.mlp.down_proj\n",
      "model.layers.14.self_attn.q_proj\n",
      "model.layers.14.self_attn.k_proj\n",
      "model.layers.14.self_attn.v_proj\n",
      "model.layers.14.self_attn.o_proj\n",
      "model.layers.14.mlp.gate_proj\n",
      "model.layers.14.mlp.up_proj\n",
      "model.layers.14.mlp.down_proj\n",
      "model.layers.15.self_attn.q_proj\n",
      "model.layers.15.self_attn.k_proj\n",
      "model.layers.15.self_attn.v_proj\n",
      "model.layers.15.self_attn.o_proj\n",
      "model.layers.15.mlp.gate_proj\n",
      "model.layers.15.mlp.up_proj\n",
      "model.layers.15.mlp.down_proj\n",
      "model.layers.16.self_attn.q_proj\n",
      "model.layers.16.self_attn.k_proj\n",
      "model.layers.16.self_attn.v_proj\n",
      "model.layers.16.self_attn.o_proj\n",
      "model.layers.16.mlp.gate_proj\n",
      "model.layers.16.mlp.up_proj\n",
      "model.layers.16.mlp.down_proj\n",
      "model.layers.17.self_attn.q_proj\n",
      "model.layers.17.self_attn.k_proj\n",
      "model.layers.17.self_attn.v_proj\n",
      "model.layers.17.self_attn.o_proj\n",
      "model.layers.17.mlp.gate_proj\n",
      "model.layers.17.mlp.up_proj\n",
      "model.layers.17.mlp.down_proj\n",
      "model.layers.18.self_attn.q_proj\n",
      "model.layers.18.self_attn.k_proj\n",
      "model.layers.18.self_attn.v_proj\n",
      "model.layers.18.self_attn.o_proj\n",
      "model.layers.18.mlp.gate_proj\n",
      "model.layers.18.mlp.up_proj\n",
      "model.layers.18.mlp.down_proj\n",
      "model.layers.19.self_attn.q_proj\n",
      "model.layers.19.self_attn.k_proj\n",
      "model.layers.19.self_attn.v_proj\n",
      "model.layers.19.self_attn.o_proj\n",
      "model.layers.19.mlp.gate_proj\n",
      "model.layers.19.mlp.up_proj\n",
      "model.layers.19.mlp.down_proj\n",
      "model.layers.20.self_attn.q_proj\n",
      "model.layers.20.self_attn.k_proj\n",
      "model.layers.20.self_attn.v_proj\n",
      "model.layers.20.self_attn.o_proj\n",
      "model.layers.20.mlp.gate_proj\n",
      "model.layers.20.mlp.up_proj\n",
      "model.layers.20.mlp.down_proj\n",
      "model.layers.21.self_attn.q_proj\n",
      "model.layers.21.self_attn.k_proj\n",
      "model.layers.21.self_attn.v_proj\n",
      "model.layers.21.self_attn.o_proj\n",
      "model.layers.21.mlp.gate_proj\n",
      "model.layers.21.mlp.up_proj\n",
      "model.layers.21.mlp.down_proj\n",
      "model.layers.22.self_attn.q_proj\n",
      "model.layers.22.self_attn.k_proj\n",
      "model.layers.22.self_attn.v_proj\n",
      "model.layers.22.self_attn.o_proj\n",
      "model.layers.22.mlp.gate_proj\n",
      "model.layers.22.mlp.up_proj\n",
      "model.layers.22.mlp.down_proj\n",
      "model.layers.23.self_attn.q_proj\n",
      "model.layers.23.self_attn.k_proj\n",
      "model.layers.23.self_attn.v_proj\n",
      "model.layers.23.self_attn.o_proj\n",
      "model.layers.23.mlp.gate_proj\n",
      "model.layers.23.mlp.up_proj\n",
      "model.layers.23.mlp.down_proj\n",
      "model.layers.24.self_attn.q_proj\n",
      "model.layers.24.self_attn.k_proj\n",
      "model.layers.24.self_attn.v_proj\n",
      "model.layers.24.self_attn.o_proj\n",
      "model.layers.24.mlp.gate_proj\n",
      "model.layers.24.mlp.up_proj\n",
      "model.layers.24.mlp.down_proj\n",
      "model.layers.25.self_attn.q_proj\n",
      "model.layers.25.self_attn.k_proj\n",
      "model.layers.25.self_attn.v_proj\n",
      "model.layers.25.self_attn.o_proj\n",
      "model.layers.25.mlp.gate_proj\n",
      "model.layers.25.mlp.up_proj\n",
      "model.layers.25.mlp.down_proj\n",
      "model.layers.26.self_attn.q_proj\n",
      "model.layers.26.self_attn.k_proj\n",
      "model.layers.26.self_attn.v_proj\n",
      "model.layers.26.self_attn.o_proj\n",
      "model.layers.26.mlp.gate_proj\n",
      "model.layers.26.mlp.up_proj\n",
      "model.layers.26.mlp.down_proj\n",
      "model.layers.27.self_attn.q_proj\n",
      "model.layers.27.self_attn.k_proj\n",
      "model.layers.27.self_attn.v_proj\n",
      "model.layers.27.self_attn.o_proj\n",
      "model.layers.27.mlp.gate_proj\n",
      "model.layers.27.mlp.up_proj\n",
      "model.layers.27.mlp.down_proj\n",
      "model.layers.28.self_attn.q_proj\n",
      "model.layers.28.self_attn.k_proj\n",
      "model.layers.28.self_attn.v_proj\n",
      "model.layers.28.self_attn.o_proj\n",
      "model.layers.28.mlp.gate_proj\n",
      "model.layers.28.mlp.up_proj\n",
      "model.layers.28.mlp.down_proj\n",
      "model.layers.29.self_attn.q_proj\n",
      "model.layers.29.self_attn.k_proj\n",
      "model.layers.29.self_attn.v_proj\n",
      "model.layers.29.self_attn.o_proj\n",
      "model.layers.29.mlp.gate_proj\n",
      "model.layers.29.mlp.up_proj\n",
      "model.layers.29.mlp.down_proj\n",
      "model.layers.30.self_attn.q_proj\n",
      "model.layers.30.self_attn.k_proj\n",
      "model.layers.30.self_attn.v_proj\n",
      "model.layers.30.self_attn.o_proj\n",
      "model.layers.30.mlp.gate_proj\n",
      "model.layers.30.mlp.up_proj\n",
      "model.layers.30.mlp.down_proj\n",
      "model.layers.31.self_attn.q_proj\n",
      "model.layers.31.self_attn.k_proj\n",
      "model.layers.31.self_attn.v_proj\n",
      "model.layers.31.self_attn.o_proj\n",
      "model.layers.31.mlp.gate_proj\n",
      "model.layers.31.mlp.up_proj\n",
      "model.layers.31.mlp.down_proj\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if \"proj\" in name:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa44f7eb-93c8-4aac-a211-a23ffda0b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройка LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # Ранг\n",
    "    lora_alpha=16,  # Коэффициент масштабирования\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13af1229-281c-4e09-8f2e-437248af34dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 41,943,040 || all params: 8,078,495,744 || trainable%: 0.5192\n"
     ]
    }
   ],
   "source": [
    "# Применение LoRA к модели\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbafa494-1a1e-4c05-993e-18d71f91175b",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e70aed06-3b42-48fc-9c52-30133d475301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae4251c2-b033-4cec-81c1-22309ed6134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vikhr_dataset = load_dataset(\"Vikhrmodels/GrandMaster-PRO-MAX\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21da9545-8296-431d-ade5-dd487c5f3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(vikhr_dataset) > 10000:\n",
    "    vikhr_dataset = vikhr_dataset.select(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "640af3c9-97f0-4e02-8fb0-629058a50c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vikhr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46028e73-3fa8-435e-9121-cf20075e2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_russian(example):\n",
    "    return example['prompt_lang'] == 'ru' and example['answer_lang'] == 'ru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42bccd2b-c8f5-4377-929b-96917849877b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 10000/10000 [00:00<00:00, 81301.19 examples/s]\n"
     ]
    }
   ],
   "source": [
    "vikhr_dataset = vikhr_dataset.filter(filter_russian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6b8c9d7-022d-4c66-838f-e419144b2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(vikhr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce501657-d6c2-40d7-a3a5-78dfab97fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "\n",
    "    conversation = example[\"conversation\"]\n",
    "    \n",
    "    # Токенизируем с применением чат-шаблона\n",
    "    # Сначала получаем текст из чат-шаблона\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        conversation,\n",
    "        tokenize=False,  # Не токенизируем, получаем текст\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "        padding=False,  # Не добавляем паддинг здесь\n",
    "    )\n",
    "    \n",
    "    # Теперь токенизируем текст обычным способом\n",
    "    tokenized = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    # print(f'input_ids: {tokenized[\"input_ids\"][:10]}...')  # Первые 10 токенов\n",
    "    # print(f'attention_mask: {tokenized[\"attention_mask\"][:10]}...')\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": tokenized[\"input_ids\"],\n",
    "        \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "        \"labels\": tokenized[\"input_ids\"].copy()  # Копируем для labels\n",
    "    }\n",
    "    \n",
    "    # # Токенизируем с применением чат-шаблона\n",
    "    # tokenized = tokenizer.apply_chat_template(\n",
    "    #     example[\"conversation\"],\n",
    "    #     # tokenize=True,\n",
    "    #     truncation=True,\n",
    "    #     max_length=1024,\n",
    "    #     padding=\"max_length\",  # Добавляем паддинг до максимальной длины\n",
    "    #     return_tensors=None\n",
    "    # )\n",
    "\n",
    "    # # Создаем attention_mask\n",
    "    # # attention_masks = []\n",
    "    # # mask = [token_id != tokenizer.pad_token_id for token_id in input_ids]\n",
    "    # # attention_masks.append(mask)\n",
    "\n",
    "    # print(tokenized)\n",
    "    # print(f'input_ids: {tokenized[\"input_ids\"]}')\n",
    "    # print(f'attention_mask: {tokenized[\"attention_mask\"]}')\n",
    "    \n",
    "    # return {\n",
    "    #     \"input_ids\": tokenized[\"input_ids\"],\n",
    "    #     \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "    #     \"labels\": tokenized[\"input_ids\"].copy()  # Копируем для labels\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75316b10-a8aa-453a-9145-7a60d8626102",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_prep = dataset.select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b40d5204-5620-49aa-a867-98cf74b381fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5/5 [00:00<00:00, 323.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "check_data = check_data_prep.map(formatting_func,\n",
    "                                 batched=False,\n",
    "                                 # batch_size=1000,\n",
    "                                 remove_columns=check_data_prep.column_names  # Удаляем оригинальные колонки\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c291a78-5a83-4ecb-a85c-de9517e7d4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b17570a-4dfa-4355-9fbb-65fda833037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9906/9906 [00:04<00:00, 2268.72 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    formatting_func,\n",
    "    batched=False,\n",
    "    remove_columns=dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d662a07-e8b0-47bf-8e50-98cd1170b448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: [1, 1, 16861, 125851, 1759, 1403, 52612, 26900, 2019, 5386]\n",
      "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Length: 1024\n"
     ]
    }
   ],
   "source": [
    "print(\"Input IDs:\", tokenized_dataset[0][\"input_ids\"][:10])\n",
    "print(\"Attention mask:\", tokenized_dataset[0][\"attention_mask\"][:10])\n",
    "print(\"Length:\", len(tokenized_dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "347e78fd-5955-4d99-8185-7db52016b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_for_test = [\n",
    "    'Как вкусно приготовить индейку на гриле?',\n",
    "    'Как распознать приближающийся инсульт?',\n",
    "    'Сформулируй основные каноны архитектуры древних цивилизаций',\n",
    "    'Облагать ли страховыми взносами суммы прощенного долга по займу от организации где работает застрахованный?',\n",
    "    'Расскажи мне про Курчатова'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec33f9d4-8890-4011-9a00-b292d170bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(prompt):\n",
    "    dialog = tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": prompt}], \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    inputs = tokenizer(dialog, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=300,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Извлекаем только ответ ассистента\n",
    "    if \"assistant\" in response:\n",
    "        return response.split(\"assistant\")[-1].strip()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca8e8770-8aec-4675-9e60-c23770e3339d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пользователь: Как вкусно приготовить индейку на гриле?\n",
      "\n",
      " Ассистент: [SEP] Чтобы вкусно приготовить индейку на гриле, можно воспользоваться следующим рецептом:\n",
      "\n",
      "**Ингредиенты:**\n",
      "* индейка (любые части, например, крылья, грудка или ножки) — 1 кг;\n",
      "* оливковое масло — 2 ст. л.;\n",
      "* чеснок — 3–4 зубчика;\n",
      "* свежий розмарин — 1 веточка;\n",
      "* свежий тимьян — 1 веточка;\n",
      "* свежий орегано (или другие травы по вкусу) — 1 веточка;\n",
      "* соль — по вкусу;\n",
      "* чёрный перец (молотый) — по вкусу;\n",
      "* лимонный сок — 2 ст. л. (по желанию).\n",
      "\n",
      "**Приготовление:**\n",
      "1. Разогрейте гриль до средней температуры.\n",
      "2. Смешайте оливковое масло, измельчённый чеснок, травы, соль и перец в миске.\n",
      "3. Натрите этой смесью кусочки индейки со всех сторон.\n",
      "4. Оставьте мариноваться на 30–60 минут (или на ночь, если есть время).\n",
      "5. Выложите индейку на гриль и жарьте, переворачивая, до золотистой корочки и готовности.\n",
      "6. Время приготовления зависит от размера и толщины кусочков индейки. Обычно это занимает от 8 до 15 минут с каждой стороны.\n",
      "7. Готовность можно проверить, проткнув мясо вилкой или ножом — вытекающий сок должен быть прозрачным.\n",
      "8. Подавайте индейку с любимыми гарнирами, например, с овощами-\n",
      "--------------------------------------------------\n",
      "Пользователь: Как распознать приближающийся инсульт?\n",
      "\n",
      " Ассистент: [SEP] При подозрении на инсульт важно как можно скорее обратиться за медицинской помощью. **Распознать приближающийся инсульт можно по следующим симптомам:**\n",
      "\n",
      "1. **Слабость или онемение в лице, руке или ноге с одной стороны.** Это может проявляться в виде внезапной слабости в одной половине тела, онемения или потери чувствительности.\n",
      "\n",
      "2. **Проблемы с речью.** Человек может испытывать трудности с пониманием речи, говорить невнятно или не может выразить свои мысли.\n",
      "\n",
      "3. **Нарушение зрения.** Может появиться внезапное ухудшение зрения, двоение в глазах, потеря зрения в одном или обоих глазах.\n",
      "\n",
      "4. **Головная боль.** Внезапная и сильная головная боль, которая может быть описана как «самая сильная в жизни», может быть признаком инсульта.\n",
      "\n",
      "5. **Проблемы с координацией и равновесием.** Человек может чувствовать головокружение, шататься при ходьбе, терять равновесие.\n",
      "\n",
      "6. **Онемение или покалывание в конечностях.** Онемение или покалывание в руках, ногах или лице, особенно с одной стороны тела.\n",
      "\n",
      "7. **Спутанность сознания.** Человек может испытывать дезориентацию, быть растерянным или не понимать, что происходит.\n",
      "\n",
      "8. **Тошнота и рвота.** Они могут быть связаны с головной болью или головокружением.\n",
      "\n",
      "**Важно помнить, что инсульт — это неотложное состояние, требующее немедленной медицинской помощи.** Если вы заметили у себя\n",
      "--------------------------------------------------\n",
      "Пользователь: Сформулируй основные каноны архитектуры древних цивилизаций\n",
      "\n",
      " Ассистент: [SEP] Основные каноны архитектуры древних цивилизаций могут различаться в зависимости от региона и исторического периода. Вот некоторые общие принципы и каноны, которые можно выделить:\n",
      "\n",
      "1. **Симметрия и гармония.** Многие древние цивилизации, такие как Древний Египет, Греция и Рим, придавали большое значение симметрии и гармонии в архитектуре. Здания строились с учётом строгих пропорций и симметрии, что создавало ощущение порядка и гармонии.\n",
      "\n",
      "2. **Использование определённых материалов.** В разных цивилизациях использовались разные материалы для строительства. Например, в Древнем Египте основным строительным материалом был камень, в то время как в Древней Греции широко использовались мрамор и известняк.\n",
      "\n",
      "3. **Религиозная символика.** Многие древние здания, такие как храмы и пирамиды, были тесно связаны с религиозными верованиями и практиками. Архитектурные формы и детали часто имели символическое значение.\n",
      "\n",
      "4. **Функциональность.** Древние архитекторы уделяли большое внимание функциональности зданий. Здания строились с учётом их предназначения — храмы для религиозных обрядов, дворцы для правителей, жилые дома для обычных людей.\n",
      "\n",
      "5. **Масштаб и монументальность.** Многие древние цивилизации строили монументальные сооружения, такие как пирамиды, храмы и дворцы, которые должны были впечатлять своей масштабностью и величием.\n",
      "\n",
      "6. **Стилизация и орнаментика.** Архитектурные элементы, такие как колонны, арки и фронтоны, часто украшались стилизованными изображениями и орнаментами\n",
      "--------------------------------------------------\n",
      "Пользователь: Облагать ли страховыми взносами суммы прощенного долга по займу от организации где работает застрахованный?\n",
      "\n",
      " Ассистент: [SEP] Согласно Налоговому кодексу РФ, страховые взносы начисляются на выплаты, которые работодатель производит в пользу работника в рамках трудовых отношений. \n",
      "\n",
      "В случае прощения долга по займу между организацией и сотрудником вопрос о начислении страховых взносов зависит от того, как оформлена эта операция и её суть. Если прощение долга рассматривается как подарок или иной доход работника, то такие суммы могут облагаться страховыми взносами.\n",
      "\n",
      "Чтобы точно определить, облагаются ли страховые взносы суммы прощённого долга, необходимо учитывать нормы Налогового кодекса РФ и разъяснения контролирующих органов, а также внимательно изучить документы, на основании которых была осуществлена прощение долга.\n",
      "\n",
      "Для получения более точного ответа на ваш вопрос рекомендую обратиться к специалисту по бухгалтерскому учёту и налогообложению или в соответствующий государственный орган.\n",
      "--------------------------------------------------\n",
      "Пользователь: Расскажи мне про Курчатова\n",
      "\n",
      " Ассистент: [SEP] **Курчатов Игорь Васильевич** (1902–1960) — советский физик, организатор и руководитель работ по атомной науке и технике в СССР. Основатель и первый директор Института атомной энергии. Академик АН СССР (1943).\n",
      "\n",
      "Игорь Курчатов родился в 1902 году в посёлке Симский завод (ныне г. Сим, Челябинская область). В 1923 году окончил физико-математическое отделение физико-математического факультета Ростовского университета. Затем учился в Петроградском политехническом институте (ныне Санкт-Петербургский политехнический университет Петра Великого).\n",
      "\n",
      "Курчатов известен своими работами в области ядерной физики и создания ядерного оружия в СССР. Под его руководством были разработаны и созданы первые советские атомная и водородная бомбы. Также Курчатов внёс значительный вклад в развитие мирного использования атомной энергии, в частности, в создание первой в Евразии атомной электростанции в Обнинске.\n",
      "\n",
      "За свои достижения Курчатов был награждён множеством наград и званий, включая звание Героя Социалистического Труда и Сталинскую премию.\n",
      "\n",
      "Имя Курчатова носит множество научных и учебных заведений, в том числе Национальный исследовательский ядерный университет МИФИ в Москве.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for text in prompts_for_test:\n",
    "    print(generate_answer(text))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c53495-8e6c-4a4c-9484-df5348e92df4",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c96d7ef-6b18-4fd7-bb06-00809638f990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs type: <class 'int'>\n",
      "Attention mask type: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Input IDs type:\", type(tokenized_dataset[0][\"input_ids\"][0]))\n",
    "print(\"Attention mask type:\", type(tokenized_dataset[0][\"attention_mask\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ca6eeff-24ad-4405-b985-32055226c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Кастомный data collator для правильной обработки типов данных\n",
    "# class CustomDataCollator(DataCollatorForLanguageModeling):\n",
    "#     def __call__(self, features):\n",
    "#         batch = super().__call__(features)\n",
    "        \n",
    "#         # Преобразуем attention_mask в bool\n",
    "#         if 'attention_mask' in batch:\n",
    "#             batch['attention_mask'] = batch['attention_mask'].bool()\n",
    "        \n",
    "#         return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6093fd76-288c-4930-9fe5-ece8b6a1fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "eval_dataset = dataset_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83f5c4ac-4d38-410a-aa1a-f20bf0c473ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./yandexgpt-lora-finetuned\",\n",
    "    per_device_train_batch_size=1, #2,\n",
    "    per_device_eval_batch_size=1, #2,\n",
    "    gradient_accumulation_steps=8, #4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=1, #3,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",  # Оценка после каждой эпохи\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    optim=\"paged_adamw_8bit\",       # Важно для QLoRA\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3212ed16-84c2-4175-96c3-7f52c476a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False), # CustomDataCollator(tokenizer, mlm=False), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1695151e-b299-45fb-b176-09f54be3c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Принудительно используем eager attention вместо SDPA\n",
    "model.config._attn_implementation = \"eager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d05ce3c-c4b7-4d39-99eb-2c3165337b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=2.86GB, reserved=4.18GB, peak=3.79GB\n",
      "NVML used=5.29GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddf347b3-4480-454f-8e59-4ab5904ab868",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f684c50-f242-48c4-809c-a55dee6e169c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=2.86GB, reserved=4.15GB, peak=3.79GB\n",
      "NVML used=5.27GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9115d1f-00db-4f8a-8102-63767d287e6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1115' max='1115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1115/1115 3:43:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.510600</td>\n",
       "      <td>1.981060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1115, training_loss=1.7642043417344713, metrics={'train_runtime': 13406.1206, 'train_samples_per_second': 0.665, 'train_steps_per_second': 0.083, 'total_flos': 4.135426241593344e+17, 'train_loss': 1.7642043417344713, 'epoch': 1.0})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "474c0231-09d7-41dc-b738-f9646bae6371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=2.87GB, reserved=4.32GB, peak=3.79GB\n",
      "NVML used=5.54GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6611ae3-5cfc-4ed4-88e1-7e340de90c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./yandexgpt-lora-finetuned/tokenizer_config.json',\n",
       " './yandexgpt-lora-finetuned/special_tokens_map.json',\n",
       " './yandexgpt-lora-finetuned/chat_template.jinja',\n",
       " './yandexgpt-lora-finetuned/tokenizer.model',\n",
       " './yandexgpt-lora-finetuned/added_tokens.json')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(\"./yandexgpt-lora-finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bab3f0-0b3f-4839-8637-f3e68340df04",
   "metadata": {},
   "source": [
    "### Оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "950a5b14-c2c9-40c2-8120-6d157d1be946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2024024-cfdd-4119-94b6-500609dee322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конфигурация для 4-битной загрузки (такая же как при обучении)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50d58e25-453c-432d-9f73-f4fdf8c91f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Загрузка базовой модели с квантизацией\n",
    "model_name = \"yandex/YandexGPT-5-Lite-8B-instruct\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "656153aa-c59a-41a7-ba7e-5e0dd8076078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка токенизатора\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    use_fast=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ccf35b92-eb7f-40ed-9d90-3c1154229f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем паддинг токен если нужно\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a63ac2f-3ecd-4e5d-8ca7-29e967e8f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка LoRA адаптера\n",
    "lora_adapter_path = \"./yandexgpt-lora-finetuned\"  # путь к вашему адаптеру\n",
    "model = PeftModel.from_pretrained(base_model, lora_adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d30aab0-62cb-40ae-8bb0-f9fc544589ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(129024, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=129024, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d13e2117-3b59-4c72-9b3a-adf2e131f8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пользователь: Как вкусно приготовить индейку на гриле?\n",
      "\n",
      " Ассистент: [SEP] Ассистент: [SEP] Ассистент: [SEP] Ассистент: Ты не мог бы поделиться рецептом вкусного маринада для индейки? Я хочу приготовить её на гриле, но не знаю, какие специи и приправы использовать.\n",
      "--------------------------------------------------\n",
      "Пользователь: Как распознать приближающийся инсульт?\n",
      "\n",
      " Ассистент: [SEP] Ассистент: [SEP] Ассистент: [SEP] Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Асси\n",
      "--------------------------------------------------\n",
      "Пользователь: Сформулируй основные каноны архитектуры древних цивилизаций\n",
      "\n",
      " Ассистент: [SEP] Ассистент: [SEP] Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент: Ассистент\n",
      "--------------------------------------------------\n",
      "Пользователь: Облагать ли страховыми взносами суммы прощенного долга по займу от организации где работает застрахованный?\n",
      "\n",
      " Ассистент: [SEP] Ассистент: [SEP] Ассистент: Ассистент: Сумма прощенного долга по займу от организации, где работает застрахованный, не облагается страховыми взносами, если она не является доходом застрахованного лица.\n",
      "\n",
      "Если сумма прощенного долга является доходом, то она облагается страховыми взносами в общем порядке.\n",
      "--------------------------------------------------\n",
      "Пользователь: Расскажи мне про Курчатова\n",
      "\n",
      " Ассистент: [SEP] Ассистент: [SEP] Ассистент: Ассистент: Игорь Васильевич Курчатов был выдающимся советским физиком, академиком АН СССР, одним из основателей и руководителей атомной науки в СССР. Он родился 12 января 1902 года и умер 7 февраля 1960 года.\n",
      "\n",
      "Курчатов внес значительный вклад в развитие ядерной физики и создание ядерного оружия в СССР. Он руководил созданием первой советской атомной бомбы и атомной энергетики. Под его руководством были проведены важные исследования в области физики атомного ядра, а также разработаны методы разделения изотопов.\n",
      "\n",
      "Курчатов также занимался теоретическими исследованиями и экспериментами, связанными с ядерной физикой, и был одним из первых, кто изучал свойства ядерного деления. Его работы оказали огромное влияние на развитие атомной науки и технологии в СССР и во всем мире.\n",
      "\n",
      "В честь Курчатова назван город Курчатов в Казахстане и несколько научных учреждений и объектов, связанных с атомной наукой и энергетикой.\n",
      "\n",
      " Ассистент: Ассистент: Игорь Васильевич Курчатов (1902–1960) — выдающийся советский физик, академик АН СССР, один из основателей атомной науки в СССР. Родился 12 января 1902 года, умер 7 февраля 1960 года.\n",
      "\n",
      "Внёс значительный вклад в развитие ядерной физики, руководил созданием первой советской атомной бомбы и атомной энергетики. Под его руководством были проведены важные исследования в области физики атомного ядра и разработаны методы разделения изотопов\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for text in prompts_for_test:\n",
    "    print(generate_answer(text))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f72ccdea-ce67-45a0-8ddb-164f59139d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=6.38GB, reserved=8.95GB, peak=7.31GB\n",
      "NVML used=10.26GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf1d64-0916-4c50-ae82-51548a76b480",
   "metadata": {},
   "source": [
    "Буду благодарен если подскажете где я накосячил с шаблоном"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda2450-466a-4988-a5bd-2448ef5aa85e",
   "metadata": {},
   "source": [
    ":("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60844011-2648-4e0b-8782-a7bf537b26ad",
   "metadata": {},
   "source": [
    "## Работа над ошибками - второй заход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe8dca53-4ac6-41e8-b02b-d8abdfbaaaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    conversation = example[\"conversation\"]\n",
    "    \n",
    "    # Применяем чат-шаблон с токенизацией\n",
    "    tokenized = tokenizer.apply_chat_template(\n",
    "        conversation,\n",
    "        tokenize=True,  # Токенизируем сразу!\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    # Для causal LM метки такие же как input_ids\n",
    "    return {\n",
    "        \"input_ids\": tokenized,\n",
    "        \"attention_mask\": [1] * len(tokenized),  # Все токены значимые\n",
    "        \"labels\": tokenized.copy()  # Копируем для labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ee404-24b0-4755-bea1-7d681a7f43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_prep = dataset.select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cfa906c2-a766-4dbf-85de-08bcd80b2d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5/5 [00:00<00:00, 821.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "check_data = check_data_prep.map(formatting_func,\n",
    "                                 batched=False,\n",
    "                                 # batch_size=1000,\n",
    "                                 remove_columns=check_data_prep.column_names  # Удаляем оригинальные колонки\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c21d06f-75d5-437a-b254-d79785c0694e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: [1, 1, 16861, 125851, 1759, 1403, 52612, 26900, 2019, 5386]\n",
      "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Length: 1024\n"
     ]
    }
   ],
   "source": [
    "print(\"Input IDs:\", tokenized_dataset[0][\"input_ids\"][:10])\n",
    "print(\"Attention mask:\", tokenized_dataset[0][\"attention_mask\"][:10])\n",
    "print(\"Length:\", len(tokenized_dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f9b9728-e7db-4946-b374-e2546b049bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    conversation = example[\"conversation\"]\n",
    "    \n",
    "    # Применяем чат-шаблон БЕЗ обрезки\n",
    "    tokenized = tokenizer.apply_chat_template(\n",
    "        conversation,\n",
    "        tokenize=True,\n",
    "        truncation=False,  # Отключаем обрезку!\n",
    "        max_length=None,   # Без ограничения длины\n",
    "        padding=False,     # Не добавляем паддинг здесь\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    # Теперь добавляем паддинг отдельно\n",
    "    if len(tokenized) < 1024:\n",
    "        # Добавляем паддинг\n",
    "        padded = tokenized + [tokenizer.pad_token_id] * (1024 - len(tokenized))\n",
    "        attention_mask = [1] * len(tokenized) + [0] * (1024 - len(tokenized))\n",
    "    else:\n",
    "        # Обрезаем до максимальной длины\n",
    "        padded = tokenized[:1024]\n",
    "        attention_mask = [1] * 1024\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": padded,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": padded.copy()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d78f6d62-3879-4403-8e1b-3bac6bbf281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func_final(example):\n",
    "    conversation = example[\"conversation\"]\n",
    "    \n",
    "    # Создаем полный диалог\n",
    "    full_dialog = \"<s>\"\n",
    "    for message in conversation:\n",
    "        if message[\"role\"] == \"user\":\n",
    "            full_dialog += f\" Пользователь: {message['content']}\"\n",
    "        elif message[\"role\"] == \"assistant\":\n",
    "            full_dialog += f\" Ассистент: {message['content']}[SEP]\"\n",
    "    \n",
    "    # Токенизируем\n",
    "    tokenized = tokenizer(\n",
    "        full_dialog,\n",
    "        truncation=True,\n",
    "        max_length=2048,  # Достаточно для полных ответов\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": tokenized[\"input_ids\"],\n",
    "        \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "        \"labels\": tokenized[\"input_ids\"].copy()  # Для simple causal LM\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1abc8a27-fd3f-4909-8758-0610a17f5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_training_data():\n",
    "    print(\"Проверка подготовки данных для обучения:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i in range(min(3, len(dataset))):\n",
    "        sample = dataset[i]\n",
    "        tokenized = formatting_func_final(sample)\n",
    "        decoded = tokenizer.decode(tokenized[\"input_ids\"])\n",
    "        \n",
    "        print(f\"\\nПример {i+1}:\")\n",
    "        print(f\"Длина: {len([x for x in tokenized['input_ids'] if x != tokenizer.pad_token_id])} токенов\")\n",
    "        \n",
    "        # Проверяем ключевые элементы\n",
    "        has_user = \"Пользователь:\" in decoded\n",
    "        has_assistant = \"Ассистент:\" in decoded\n",
    "        has_sep = \"[SEP]\" in decoded\n",
    "        has_content = any(word in decoded for word in [\"страте\", \"игр\", \"ответ\"])\n",
    "        \n",
    "        print(f\"✓ Пользователь: {has_user}\")\n",
    "        print(f\"✓ Ассистент: {has_assistant}\")\n",
    "        print(f\"✓ [SEP]: {has_sep}\")\n",
    "        print(f\"✓ Контент: {has_content}\")\n",
    "        print(decoded)\n",
    "        \n",
    "        if all([has_user, has_assistant, has_sep, has_content]):\n",
    "            print(\"✓ Данные корректны для обучения\")\n",
    "        else:\n",
    "            print(\"✗ Проблема с данными\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4a41e259-4d6b-4dc9-993f-b9e378156635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка подготовки данных для обучения:\n",
      "============================================================\n",
      "\n",
      "Пример 1:\n",
      "Длина: 569 токенов\n",
      "✓ Пользователь: True\n",
      "✓ Ассистент: True\n",
      "✓ [SEP]: True\n",
      "✓ Контент: True\n",
      "<s><s> Пользователь: мне очень интересны стратегические игры, и я недавно узнал про игру ним. не мог бы ты объяснить мне стратегию оптимальной игры в ним? и еще, если есть, поделись интересным вариантом игры в крестики-нолики или другие стратегические головоломки, в которые мы могли бы сыграть вместе. как насчет того, чтобы рассмотреть 15 puzzle? мне бы хотелось узнать, есть ли для неё какая-то выигрышная стратегия или подход, который гарантирует победу. Ассистент: Расскажу тебе о стратегиях игры в Ним и затрону тему 15 Puzzle.\n",
      "\n",
      "### Стратегия оптимальной игры в Ним\n",
      "\n",
      "Игра Ним — это математическая игра, для которой существует чёткая выигрышная стратегия. Основа стратегии лежит в понятии ним-суммы — это побитовое исключающее ИЛИ (XOR) размеров кучек.\n",
      "\n",
      "Оптимальная стратегия заключается в следующем:\n",
      "\n",
      "1. Вычисли ним-сумму всех кучек.\n",
      "2. Если ним-сумма равна нулю, то ваше положение проигрышное при оптимальной игре соперника. В этом случае просто делайте ход и старайтесь создать трудности для соперника.\n",
      "3. Если ним-сумма не равна нулю, вам нужно сделать ход, который уменьшит размер одной из кучек так, чтобы новая ним-сумма всех кучек была равна нулю.\n",
      "4. После вашего хода соперник окажется в положении с ним-суммой равной нулю, что является проигрышным положением при вашей оптимальной игре.\n",
      "\n",
      "### Играем в крестики-нолики\n",
      "\n",
      "Что касается крестиков-ноликов, можно попробовать игру на расширенном поле 5x5 или 10x10, где для победы нужно выстроить ряд из 5 символов. Это добавит сложности и стратегической глубины.\n",
      "\n",
      "### 15 Puzzle (Пятнашки)\n",
      "\n",
      "15 Puzzle — это головоломка с плитками, которые нужно упорядочить по порядку, перемещая их в пустое пространство. \n",
      "\n",
      "Для 15 Puzzle существуют алгоритмы, которые позволяют определить решаемость пазла (не все начальные позиции решаемы) и выигрышная стратегия, если пазл решаем. Основной подход к решению:\n",
      "\n",
      "1. Разделите пазл на зоны и решайте поэтапно (например, сначала верхние две строки, затем левая половина и т.д.).\n",
      "2. Используйте алгоритмы для перестановки плиток, которые минимизируют количество нежелательных изменений (например, метод \"переворота угла\").\n",
      "3. Для каждого этапа запоминайте последовательность ходов, которая позволяет решать типичные задачи (например, как поменять местами две конкретные плитки).\n",
      "\n",
      "Сложность заключается в том, что без знания алгоритмов и последовательностей ходов решить пазл может быть довольно непросто, особенно если вы не имеете опыта с подобными головоломками. Но при наличии практики и понимания методов, пазл становится решаемым практически всегда. [SEP] </s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
      "✓ Данные корректны для обучения\n",
      "\n",
      "Пример 2:\n",
      "Длина: 563 токенов\n",
      "✓ Пользователь: True\n",
      "✓ Ассистент: True\n",
      "✓ [SEP]: True\n",
      "✓ Контент: True\n",
      "<s><s> Пользователь: слушай, у меня тут возникла задачка по архитектуре компьютера, и я не могу в ней разобраться. мне нужно разработать алгоритм, который оптимизирует доступ к кэш-памяти в многоядерном процессоре для параллельных вычислений. ты не мог бы помочь с этим? вот как я представляю задачу:\n",
      "\n",
      "1. имеется многоядерный процессор с общим кэшем второго уровня.\n",
      "2. необходимо минимизировать промахи кэша при параллельном выполнении нескольких интенсивных задач по обработке данных.\n",
      "3. алгоритм должен распределять данные таким образом, чтобы максимально использовать преимущества локальности данных и минимизировать конфликтные промахи.\n",
      "\n",
      "может есть идеи, как это можно организовать на уровне алгоритма? буду рад любым предложениям и советам! Ассистент: Ваша задача действительно интересная и актуальная в контексте современных многоядерных процессоров. Для оптимизации доступа к кэш-памяти важно учитывать такие аспекты, как пространственная и временная локальность данных, а также избегать конфликтов при кэшировании. Вот основные шаги, которые помогут в разработке алгоритма:\n",
      "\n",
      "### Шаг 1: Анализ задач\n",
      "Прежде всего, нужно проанализировать характеристики задач, которые будут выполняться параллельно. Важно понять, какие данные используются и как часто они запрашиваются.\n",
      "\n",
      "### Шаг 2: Разработка стратегии распределения данных\n",
      "Далее, необходимо разработать стратегию, которая позволит распределить данные таким образом, чтобы максимально использовать преимущества пространственной и временной локальности. Это может включать в себя:\n",
      "\n",
      "- **Группировка связанных данных**: чтобы при обращении к одному элементу данных рядом находились и другие часто используемые элементы.\n",
      "- **Разделение данных между ядрами**: чтобы каждое ядро работало с уникальным набором данных и минимизировать конфликтные промахи.\n",
      "\n",
      "### Шаг 3: Разбиение данных на блоки\n",
      "После того как стратегия распределения данных разработана, следует разбить данные на блоки оптимального размера для кэширования. В идеале, размер блока должен соответствовать размеру линейки кэша.\n",
      "\n",
      "### Шаг 4: Реализация алгоритма предвыборки (prefetching)\n",
      "Разработайте алгоритм предвыборки данных, который будет загружать данные в кэш заранее, основываясь на предсказании обращений к данным.\n",
      "\n",
      "### Шаг 5: Синхронизация доступа к данным\n",
      "Необходимо также обеспечить эффективную синхронизацию доступа к данным между ядрами, чтобы избежать ситуаций, когда несколько ядер одновременно обновляют данные в кэше.\n",
      "\n",
      "### Шаг 6: Тестирование и отладка\n",
      "Проведите тестирование алгоритма на различных наборах данных и рабочих нагрузках. Оцените эффективность алгоритма, подсчитывая количество промахов кэша и сравнивая с базовым случаем.\n",
      "\n",
      "### Шаг 7: Итерация и оптимизация\n",
      "На основе полученных результатов внесите коррективы в алгоритм и повторите тестирование. Ищите возможности для дальнейшей оптимизации.\n",
      "\n",
      "Эти шаги должны помочь вам в разработке эффективного алгоритма оптимизации доступа к кэш-памяти для параллельных вычислений. Успехов в работе! [SEP] </s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
      "✓ Данные корректны для обучения\n",
      "\n",
      "Пример 3:\n",
      "Длина: 940 токенов\n",
      "✓ Пользователь: True\n",
      "✓ Ассистент: True\n",
      "✓ [SEP]: True\n",
      "✓ Контент: True\n",
      "<s><s> Пользователь: Здравствуйте, помогите мне, пожалуйста, разобраться с одной тригонометрической функцией. Мне нужно найти основные значения арксинуса и арккосинуса, используя единичную окружность. Могли бы вы показать мне их на графике, и объяснить, как их можно использовать для решения уравнений? Кроме того, как применить эти функции для решения практических задач, например, в физике или инженерии? Буду очень признателен за подробный разбор с примерами. Ассистент: Здравствуйте! Давайте разберёмся с основными значениями арксинуса и арккосинуса на примере единичной окружности, а также рассмотрим их использование в уравнениях и практических задачах.\n",
      "\n",
      "### Основные значения арксинуса и арккосинуса на единичной окружности\n",
      "\n",
      "Единичная окружность — это окружность с радиусом равным 1, центр которой расположен в начале координат на координатной плоскости.\n",
      "\n",
      "#### Арксинус\n",
      "Функция арксинус (`arcsin`) — это обратная функция к синусу. Она позволяет определить угол по его синусу. Для арксинуса:\n",
      "- Определение: `arcsin(y) = x` ↔ `sin(x) = y`\n",
      "- Область значений функции арксинуса: `[-π/2, π/2]` или `[-90°, 90°]`\n",
      "\n",
      "#### Арккосинус\n",
      "Функция арккосинус (`arccos`) — это также обратная функция, но к косинусу. Она позволяет определить угол по его косинусу. Для арккосинуса:\n",
      "- Определение: `arccos(y) = x` ↔ `cos(x) = y`\n",
      "- Область значений функции арккосинуса: `[0, π]` или `[0°, 180°]`\n",
      "\n",
      "На графике единичной окружности значения арксинуса и арккосинуса можно представить как углы относительно оси X. К сожалению, я не могу предоставить вам изображение, но вы можете визуализировать это, нарисовав окружность и отметив на ней углы, соответствующие значениям из областей значений функций.\n",
      "\n",
      "### Использование арксинуса и арккосинуса в уравнениях\n",
      "\n",
      "Для решения уравнений вида `sin(x) = y` и `cos(x) = y` используются соответственно арксинус и арккосинус. Например:\n",
      "\n",
      "1. `sin(x) = 1/2`\n",
      "   Чтобы найти `x`, используем арксинус: `x = arcsin(1/2)`. Зная область значений арксинуса, получаем `x = π/6` или `x = 30°`.\n",
      "\n",
      "2. `cos(x) = -1`\n",
      "   Используем арккосинус: `x = arccos(-1)`. Зная область значений арккосинуса, получаем `x = π` или `x = 180°`.\n",
      "\n",
      "### Применение в практических задачах\n",
      "\n",
      "Арксинус и арккосинус могут использоваться в различных областях, включая физику и инженерию, для определения углов по известным отношениям сторон в треугольниках.\n",
      "\n",
      "#### Пример в физике:\n",
      "Рассмотрим задачу нахождения угла броска при движении тела по параболической траектории при известной начальной скорости `v` и дистанции `d` до точки падения.\n",
      "\n",
      "1. Уравнение для максимального расстояния, которое тело пролетит при угле броска `θ`, выглядит так: `d = (v^2 * sin(2θ)) / g`, где `g` — ускорение свободного падения.\n",
      "2. Выразим `sin(2θ)`: `sin(2θ) = d * g / v^2`.\n",
      "3. Для нахождения угла `θ` используем арксинус: `2θ = arcsin(d * g / v^2)`.\n",
      "4. Отсюда `θ = 1/2 * arcsin(d * g / v^2)`.\n",
      "\n",
      "#### Пример в инженерии:\n",
      "Пусть требуется определить угол наклона лестницы, опирающейся на стену, при известной высоте `h`, на которую она опирается, и длине лестницы `l`.\n",
      "\n",
      "1. Используя тригонометрические соотношения в прямоугольном треугольнике, определяем, что `cos(θ) = h / l`.\n",
      "2. Чтобы найти угол `θ`, используем арккосинус: `θ = arccos(h / l)`.\n",
      "\n",
      "Надеюсь, эти примеры помогли вам понять, как использовать арксинус и арккосинус для решения практических задач. Если у вас возникнут дополнительные вопросы, не стесняйтесь их задать! [SEP] </s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
      "✓ Данные корректны для обучения\n"
     ]
    }
   ],
   "source": [
    "verify_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff75ea-774d-4be8-aa63-3f6af330305c",
   "metadata": {},
   "source": [
    "### Подготовка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc59e55d-5244-4334-8099-df62f702708e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaee0e83-e509-46ed-a1c5-9ac4ebd80440",
   "metadata": {},
   "source": [
    "# Дообучение энкодера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b58575-aa3e-46f1-ab85-4c6668ea06c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
