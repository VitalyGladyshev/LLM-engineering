{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef538bfe-80e6-4d0a-84eb-103cabc635a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import torch, gc, os, math, random\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd6b96c5-c6b3-49ca-b6e2-61ae101a43d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "nvmlInit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe370538-ebcc-4bd7-9b42-04faafa20342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "904d2417-aae3-45a4-b185-b671e36d547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-09 17:10:30 [__init__.py:241] Automatically detected platform cuda.\n",
      "WARNING 09-09 17:10:30 [cuda.py:605] Detected different devices in the system: NVIDIA GeForce RTX 3090 Ti, NVIDIA GeForce RTX 3090. Please make sure to set `CUDA_DEVICE_ORDER=PCI_BUS_ID` to avoid unexpected behavior.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c940c92a-e77a-41bb-8da7-0d3705922198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, AutoTokenizer\n",
    "from trl import SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235d7e66-55cc-498f-a91d-fd84161c54b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aae08193-58ab-4ebb-878f-d13047002e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def gpu_mem(note=\"\"):\n",
    "    if not torch.cuda.is_available():\n",
    "        print(f\"[{note}] No CUDA available.\")\n",
    "        return\n",
    "    torch.cuda.synchronize()\n",
    "    alloc = torch.cuda.memory_allocated() / (1024**3)\n",
    "    resrv = torch.cuda.memory_reserved() / (1024**3)\n",
    "    peak = torch.cuda.max_memory_allocated() / (1024**3)\n",
    "    print(f\"[{note}] allocated={alloc:.2f}GB, reserved={resrv:.2f}GB, peak={peak:.2f}GB\")\n",
    "\n",
    "def nvidia_mem():\n",
    "    if not torch.cuda.is_available():\n",
    "        return\n",
    "\n",
    "    nvmlInit()\n",
    "    h = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(h)\n",
    "    print(f\"NVML used={info.used/(1024**3):.2f}GB / total={info.total/(1024**3):.2f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53310e3b-f80d-4703-8327-67cc9fea00dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fresh] allocated=0.00GB, reserved=0.00GB, peak=0.00GB\n",
      "NVML used=1.28GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "flush()\n",
    "gpu_mem(\"fresh\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f4099-b723-43af-8b0c-ad13de19e27c",
   "metadata": {},
   "source": [
    "## –ú–æ–¥–µ–ª—å Meta-Llama-3.1-8B-Instruct-bnb-4bit –æ—Ç Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67ed1d4a-0af9-4216-8d6c-33ee8a9c55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "063a7abe-3de6-423c-89b9-524263697962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ ¬´Llama-3.1-8B-Instruct¬ª...\n",
      "remote: Enumerating objects: 109, done.\u001b[K\n",
      "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
      "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
      "remote: Total 109 (delta 53), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
      "–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤: 100% (109/109), 2.28 –ú–∏–ë | 4.57 –ú–∏–ë/—Å, –≥–æ—Ç–æ–≤–æ.\n",
      "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π: 100% (53/53), –≥–æ—Ç–æ–≤–æ.\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://viv232:hf_xxxxx@huggingface.co/meta-llama/Llama-3.1-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b99b98b3-0693-4629-8b1b-b335b334031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"meta-llama/Llama-3.1-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70fef332-d529-4248-b804-52f43ef279e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ ¬´Meta-Llama-3.1-8B-Instruct-bnb-4bit¬ª...\n",
      "remote: Enumerating objects: 131, done.\u001b[K\n",
      "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
      "remote: Compressing objects: 100% (128/128), done.\u001b[K\n",
      "remote: Total 131 (delta 44), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
      "–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤: 100% (131/131), 2.30 –ú–∏–ë | 3.76 –ú–∏–ë/—Å, –≥–æ—Ç–æ–≤–æ.\n",
      "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π: 100% (44/44), –≥–æ—Ç–æ–≤–æ.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a947cca9-efef-4fff-bd48-df5455fe38a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b77bc1d-cb60-4a6f-8796-cc11c0f6dbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[before load QLoRA] allocated=0.00GB, reserved=0.00GB, peak=0.00GB\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 1024\n",
    "\n",
    "flush()\n",
    "gpu_mem(\"before load QLoRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "241ce030-458e-489f-9251-8738645afb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.1: Fast Llama patching. Transformers: 4.56.1. vLLM: 0.10.1.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090 Ti. Num GPUs = 2. Max memory: 23.536 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,    # QLoRA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d92c9bb0-b82d-44ae-9efb-2f1446b37e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.9.1 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c74494c0-c740-47c4-bda8-6ba576e544c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[after load QLoRA] allocated=5.50GB, reserved=5.52GB, peak=7.02GB\n",
      "NVML used=6.64GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"after load QLoRA\")\n",
    "nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cffbeac3-1aa3-4334-affb-3f56a43b3519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|eot_id|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78cd47d9-c4ef-4190-825e-6fe55aeb749e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ß–∞—Ç-—à–∞–±–ª–æ–Ω: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- set date_string = \"26 Jul 2024\" %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message + builtin tools #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if builtin_tools is defined or tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{%- if builtin_tools is defined %}\n",
      "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
      "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
      "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
      "                {%- if not loop.last %}\n",
      "                    {{- \", \" }}\n",
      "                {%- endif %}\n",
      "                {%- endfor %}\n",
      "            {{- \")\" }}\n",
      "        {%- else  %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "            {{- '\"parameters\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- \"}\" }}\n",
      "        {%- endif %}\n",
      "        {%- if builtin_tools is defined %}\n",
      "            {#- This means we're in ipython mode #}\n",
      "            {{- \"<|eom_id|>\" }}\n",
      "        {%- else %}\n",
      "            {{- \"<|eot_id|>\" }}\n",
      "        {%- endif %}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"–ß–∞—Ç-—à–∞–±–ª–æ–Ω: {tokenizer.chat_template}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a7642-4e04-4f9d-b021-850f17422119",
   "metadata": {},
   "source": [
    "### –û—Ü–µ–Ω–∫–∞ –¥–æ LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17984ca1-d489-4052-975a-2204a7946368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1193e7b9-9a9d-4049-9b1d-d5f156c506f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_for_test = [\n",
    "    '–ö–∞–∫ –≤–∫—É—Å–Ω–æ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –∏–Ω–¥–µ–π–∫—É –Ω–∞ –≥—Ä–∏–ª–µ?',\n",
    "    '–ö–∞–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ø—Ä–∏–±–ª–∏–∂–∞—é—â–∏–π—Å—è –∏–Ω—Å—É–ª—å—Ç?',\n",
    "    '–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–∞–Ω–æ–Ω—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥—Ä–µ–≤–Ω–∏—Ö —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–π',\n",
    "    '–û–±–ª–∞–≥–∞—Ç—å –ª–∏ —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏ —Å—É–º–º—ã –ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –¥–æ–ª–≥–∞ –ø–æ –∑–∞–π–º—É –æ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –≥–¥–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–Ω—ã–π?',\n",
    "    '–†–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ –ø—Ä–æ –ö—É—Ä—á–∞—Ç–æ–≤–∞'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a92eadf6-5744-4e0c-8fa8-f455409b518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(prompt):\n",
    "    dialog = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": prompt}], \n",
    "                                           tokenize=False, \n",
    "                                           add_generation_prompt=True)\n",
    "    inputs = tokenizer(dialog, return_tensors = \"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=300, use_cache=True)\n",
    "    return tokenizer.batch_decode(outputs)[0].split(\"assistant\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84e5b651-9400-4ff1-9ee8-7bf3d6b03690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|end_header_id|>\n",
      "\n",
      "–ß—Ç–æ–±—ã –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –≤–∫—É—Å–Ω—É—é –∏–Ω–¥–µ–π–∫—É –Ω–∞ –≥—Ä–∏–ª–µ, —Å–ª–µ–¥—É–π—Ç–µ —ç—Ç–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º:\n",
      "\n",
      "**–ü—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–π–∫–∏ –Ω–∞ –≥—Ä–∏–ª–µ:**\n",
      "\n",
      "–ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã:\n",
      "\n",
      "*   1 –∏–Ω–¥–µ–π–∫–∞ (–≤–µ—Å–æ–º 1,5-2 –∫–≥)\n",
      "*   2 —Å—Ç–æ–ª–æ–≤—ã–µ –ª–æ–∂–∫–∏ –æ–ª–∏–≤–∫–æ–≤–æ–≥–æ –º–∞—Å–ª–∞\n",
      "*   1 —á–∞–π–Ω–∞—è –ª–æ–∂–∫–∞ —Å–æ–ª–∏\n",
      "*   1 —á–∞–π–Ω–∞—è –ª–æ–∂–∫–∞ —á–µ—Ä–Ω–æ–≥–æ –ø–µ—Ä—Ü–∞\n",
      "*   1 —á–∞–π–Ω–∞—è –ª–æ–∂–∫–∞ –ø–∞–ø—Ä–∏–∫–∏\n",
      "*   1 —á–∞–π–Ω–∞—è –ª–æ–∂–∫–∞ —á–µ—Å–Ω–æ–∫–∞, –∏–∑–º–µ–ª—å—á–µ–Ω–Ω–æ–≥–æ\n",
      "*   1 –ª—É–∫–æ–≤–∏—Ü–∞, –∏–∑–º–µ–ª—å—á–µ–Ω–Ω–∞—è\n",
      "*   2 –≤–µ—Ç–æ—á–∫–∏ —Ä–æ–∑–º–∞—Ä–∏–Ω–∞ (–ø–æ –∂–µ–ª–∞–Ω–∏—é)\n",
      "*   1 –ª–∏–º–æ–Ω, –Ω–∞—Ä–µ–∑–∞–Ω–Ω—ã–π (–ø–æ –∂–µ–ª–∞–Ω–∏—é)\n",
      "\n",
      "**–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω–¥–µ–π–∫–∏:**\n",
      "\n",
      "1.  –ù–∞–ª–µ–π—Ç–µ –∏–Ω–¥–µ–π–∫—É –≤ —Ñ–æ—Ä–º—É –¥–ª—è –≥—Ä–∏–ª—è –∏–ª–∏ –Ω–∞ –ø—Ä–æ—Ç–∏–≤–µ–Ω—å.\n",
      "2.  –í –º–∏—Å–∫–µ —Å–º–µ—à–∞–π—Ç–µ –æ–ª–∏–≤–∫–æ–≤–æ–µ –º–∞—Å–ª–æ, —Å–æ–ª—å, —á–µ—Ä–Ω—ã–π –ø–µ—Ä–µ—Ü, –ø–∞–ø—Ä–∏–∫—É, —á–µ—Å–Ω–æ–∫ –∏ –ª—É–∫.\n",
      "3.  –ù–∞–Ω–µ—Å–∏—Ç–µ —Å–º–µ—Å—å –Ω–∞ –∏–Ω–¥–µ–π–∫—É, —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏–≤ –µ–µ –ø–æ –≤—Å–µ–π –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏.\n",
      "4.  –î–æ–±–∞–≤—å—Ç–µ —Ä–æ–∑–º–∞—Ä–∏–Ω –∏ –ª–∏–º–æ–Ω –ø–æ –∂–µ–ª–∞–Ω–∏—é.\n",
      "\n",
      "**–ì—Ä–∏–ª—è–Ω–∏–µ –∏–Ω–¥–µ–π–∫–∏:**\n",
      "\n",
      "1.  –†–∞–∑–æ–≥—Ä–µ–π—Ç–µ –≥—Ä–∏–ª—å –¥–æ —Å—Ä–µ–¥–Ω–µ–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã.\n",
      "2.  –ü\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "–ü—Ä–∏–±–ª–∏–∂–∞—é—â–∏–π—Å—è –∏–Ω—Å—É–ª—å—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–æ–∂–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –µ–≥–æ —Ä–∞–Ω–Ω–∏—Ö —Å—Ç–∞–¥–∏—è—Ö. –û–¥–Ω–∞–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Å–∏–º–ø—Ç–æ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –∏–Ω—Å—É–ª—å—Ç. –í–æ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∏–∑ –Ω–∏—Ö:\n",
      "\n",
      "1.  **–ù–∞—Ä—É—à–µ–Ω–∏–µ —Ä–µ—á–∏**: –ø—Ä–æ–±–ª–µ–º—ã —Å —Ä–µ—á—å—é, —Ç–∞–∫–∏–µ –∫–∞–∫ –∑–∞—Ç—Ä—É–¥–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è —Å–ª–æ–≤, —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∏–ª–∏ –Ω–µ–ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ä–µ—á–∏ –¥—Ä—É–≥–∏—Ö –ª—é–¥–µ–π.\n",
      "2.  **–ù–∞—Ä—É—à–µ–Ω–∏–µ –∑—Ä–µ–Ω–∏—è**: –ø–æ—Ç–µ—Ä—è –∑—Ä–µ–Ω–∏—è –≤ –æ–¥–Ω–æ–º –∏–ª–∏ –æ–±–æ–∏—Ö –≥–ª–∞–∑–∞—Ö, —Å–ª–µ–ø–æ—Ç–∞ –∏–ª–∏ –¥–≤–æ–µ–Ω–∏–µ –≤ –≥–ª–∞–∑–∞—Ö.\n",
      "3.  **–ù–∞—Ä—É—à–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏–π**: —Å–ª–∞–±–æ—Å—Ç—å –∏–ª–∏ –ø–∞—Ä–∞–ª–∏—á –≤ –æ–¥–Ω–æ–π –∏–ª–∏ –æ–±–µ–∏—Ö —Ä—É–∫–∞—Ö –∏–ª–∏ –Ω–æ–≥–∞—Ö, —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ —Å —Ö–æ–¥—å–±–æ–π –∏–ª–∏ –ø–æ—Ç–µ—Ä—è —Ä–∞–≤–Ω–æ–≤–µ—Å–∏—è.\n",
      "4.  **–ù–∞—Ä—É—à–µ–Ω–∏–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**: –ø–æ—Ç–µ—Ä—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –æ–¥–Ω–æ–π –∏–ª–∏ –æ–±–µ–∏—Ö —Ä—É–∫–∞—Ö –∏–ª–∏ –Ω–æ–≥–∞—Ö.\n",
      "5.  **–ì–æ–ª–æ–≤–Ω–∞—è –±–æ–ª—å**: —Å–∏–ª—å–Ω–∞—è –≥–æ–ª–æ–≤–Ω–∞—è –±–æ–ª—å, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω–µ –≥–æ–ª–æ–≤—ã.\n",
      "6.  **–°–∏–Ω—è—è –∫–æ–∂–∞**: —Å–∏–Ω—è—è –∫–æ–∂–∞ –Ω–∞ –ª–∏—Ü–µ –∏–ª–∏ –∫–æ–Ω–µ—á–Ω–æ—Å—Ç—è—Ö.\n",
      "7.  **–ù–∞—Ä—É—à–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏**: –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–∞–º—è—Ç—å—é –∏–ª–∏ –≤–Ω–∏–º–∞–Ω–∏–µ.\n",
      "8.  **–ù–∞—Ä—É—à–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è**: –ø–µ—Ä–µ–ø–∞–¥—ã –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –∏–ª–∏ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ.\n",
      "9.  **–ù–∞—Ä—É—à–µ–Ω–∏–µ –º—ã—à\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥—Ä–µ–≤–Ω–∏—Ö —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–π –≤–∫–ª—é—á–∞–ª–∞ –≤ —Å–µ–±—è —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ç–∏–ª–∏ –∏ –ø—Ä–∏–Ω—Ü–∏–ø—ã, –Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –æ–±—â–∏–µ –∫–∞–Ω–æ–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω—ã —Å—Ä–µ–¥–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫—É–ª—å—Ç—É—Ä. –í–æ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–∞–Ω–æ–Ω—ã:\n",
      "\n",
      "1. **–°–∏–º–º–µ—Ç—Ä–∏—è –∏ –±–∞–ª–∞–Ω—Å**: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥—Ä–µ–≤–Ω–∏—Ö —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–π —á–∞—Å—Ç–æ –≤–∫–ª—é—á–∞–ª–∞ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–µ –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–∑–¥–∞–≤–∞–ª–∏ —á—É–≤—Å—Ç–≤–æ –±–∞–ª–∞–Ω—Å–∞ –∏ –≥–∞—Ä–º–æ–Ω–∏–∏. –≠—Ç–æ –º–æ–≥–ª–æ –≤—ã—Ä–∞–∂–∞—Ç—å—Å—è –≤ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–π –ø–ª–∞–Ω–∏—Ä–æ–≤–∫–µ –∑–¥–∞–Ω–∏–π, —Ñ–∞—Å–∞–¥–æ–≤ –∏ –∏–Ω—Ç–µ—Ä—å–µ—Ä–æ–≤.\n",
      "2. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏—Ä–æ–¥–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤**: –î—Ä–µ–≤–Ω–∏–µ —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–∏ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –º–µ—Å—Ç–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã, —Ç–∞–∫–∏–µ –∫–∞–∫ –∫–∞–º–µ–Ω—å, –¥–µ—Ä–µ–≤–æ, –≥–ª–∏–Ω–∞ –∏ –∫–∏—Ä–ø–∏—á–∏, –¥–ª—è –ø–æ—Å—Ç—Ä–æ–π–∫–∏ –∑–¥–∞–Ω–∏–π –∏ —Å–æ–æ—Ä—É–∂–µ–Ω–∏–π.\n",
      "3. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º**: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥—Ä–µ–≤–Ω–∏—Ö —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–π —á–∞—Å—Ç–æ –≤–∫–ª—é—á–∞–ª–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º, —Ç–∞–∫–∏—Ö –∫–∞–∫ –∫—Ä—É–≥–∏, –∫–≤–∞–¥—Ä–∞—Ç—ã, —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–∏ –∏ —Ä–æ–º–±—ã, –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–º–ø–æ–∑–∏—Ü–∏–π –∏ –æ—Ä–Ω–∞–º–µ–Ω—Ç–æ–≤.\n",
      "4. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ—Ä–Ω–∞–º–µ–Ω—Ç–æ–≤**: –î—Ä–µ–≤–Ω–∏–µ —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–∏ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –æ—Ä–Ω–∞–º–µ–Ω—Ç—ã, —Ç–∞–∫–∏–µ –∫–∞–∫ —É–∑–æ—Ä—ã, –º–æ—Ç–∏–≤—ã –∏ —Å–∏–º–≤–æ–ª—ã, –¥–ª—è —É–∫—Ä–∞—à–µ–Ω–∏—è –∑–¥–∞–Ω–∏–π –∏ —Å–æ–æ—Ä—É–∂–µ–Ω–∏–π.\n",
      "5. **–°–≤—è–∑—å —Å –ø—Ä–∏—Ä–æ–¥–æ–π**: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "–í–æ–ø—Ä–æ—Å –æ –≤–∑–∏–º–∞–Ω–∏–∏ —Å—Ç—Ä–∞—Ö–æ–≤—ã—Ö –≤–∑–Ω–æ—Å–æ–≤ –Ω–∞ —Å—É–º–º—ã –ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –¥–æ–ª–≥–∞ –ø–æ –∑–∞–π–º—É –æ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, –≥–¥–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–Ω—ã–π, —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–∂–Ω—ã–º –∏ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä—è–¥–∞ —Ñ–∞–∫—Ç–æ—Ä–æ–≤. –í –†–æ—Å—Å–∏–∏ –¥–µ–π—Å—Ç–≤—É—é—Ç —Å–ª–µ–¥—É—é—â–∏–µ –ø—Ä–∞–≤–∏–ª–∞:\n",
      "\n",
      "1. **–ó–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ**: –°–æ–≥–ª–∞—Å–Ω–æ —Å—Ç–∞—Ç—å–µ 16.1 –ù–∞–ª–æ–≥–æ–≤–æ–≥–æ –∫–æ–¥–µ–∫—Å–∞ –†–§, —Å—Ç—Ä–∞—Ö–æ–≤—ã–µ –≤–∑–Ω–æ—Å—ã –≤–∑–∏–º–∞—é—Ç—Å—è –Ω–∞ –¥–æ—Ö–æ–¥—ã, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –æ—Ç –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å–∫–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –∞ —Ç–∞–∫–∂–µ –Ω–∞ —Å—É–º–º—ã, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –æ—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–º—É—â–µ—Å—Ç–≤–∞, –µ—Å–ª–∏ –æ–Ω–æ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—Å–Ω–æ–≤–Ω—ã–º –∏–º—É—â–µ—Å—Ç–≤–æ–º –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏. –û–¥–Ω–∞–∫–æ, –µ—Å–ª–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∑–∞–π–º—ã —Å–≤–æ–∏–º —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º, —Ç–æ —ç—Ç–∏ –∑–∞–π–º—ã –Ω–µ –¥–æ–ª–∂–Ω—ã —É—á–∏—Ç—ã–≤–∞—Ç—å—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –¥–æ—Ö–æ–¥–æ–≤, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –±—ã–ª–∏ –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã –≤ —Ç–µ—á–µ–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Å—Ä–æ–∫–∞.\n",
      "\n",
      "2. **–ü—Ä–∞–≤–∏–ª–æ \"–≤–æ–∑–≤—Ä–∞—Ç–Ω–æ—Å—Ç–∏\"**: –°–æ–≥–ª–∞—Å–Ω–æ –ø. 5.15 –ü–æ–ª–æ–∂–µ–Ω–∏—è –æ —Å—Ç—Ä–∞—Ö–æ–≤—ã—Ö –≤–∑–Ω–æ—Å–∞—Ö, –µ—Å–ª–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∑–∞–π–º—ã —Å–≤–æ–∏–º —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º –∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç–∞, —ç—Ç–∏ —Å—É–º–º—ã –Ω–µ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –¥–æ—Ö–æ–¥–æ–≤ –∏ –Ω–µ –æ–±–ª–∞–≥–∞—é—Ç—Å—è —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏. –û–¥–Ω–∞–∫–æ, –µ—Å–ª–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–±—É–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç–∞, —Ç–æ —ç—Ç–∏ —Å—É–º–º—ã —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –¥–æ—Ö–æ–¥–æ–≤ –∏ –æ–±–ª–∞–≥–∞—é—Ç—Å—è —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏.\n",
      "\n",
      "3. **–ü—Ä–æ–∫—Ä–µ–¥–∏—Ç–æ–≤–∞–Ω–∏–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤**: –ï—Å–ª–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å–≤–æ–∏–º —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º –∫—Ä–µ–¥–∏—Ç—ã –ø–æ–¥ –∑–∞–ª–æ–≥ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –∏–ª–∏ –¥—Ä—É–≥–æ–≥–æ –∏–º—É—â–µ—Å—Ç–≤–∞, —Ç–æ\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "–ö—É—Ä—á–∞—Ç–æ–≤ - —ç—Ç–æ —Ä—É—Å—Å–∫–∏–π —É—á—ë–Ω—ã–π –∏ –∏–∑–æ–±—Ä–µ—Ç–∞—Ç–µ–ª—å, –∫–æ—Ç–æ—Ä—ã–π –≤–Ω–µ—Å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –≤–∫–ª–∞–¥ –≤ —Ä–∞–∑–≤–∏—Ç–∏–µ —Ä–∞–¥–∏–æ—Ç–µ—Ö–Ω–∏–∫–∏ –∏ —Ä–∞–¥–∏–æ–ª–æ–∫–∞—Ü–∏–∏. –û–Ω —Ä–æ–¥–∏–ª—Å—è –≤ 1903 –≥–æ–¥—É –∏ —É–º–µ—Ä –≤ 1991 –≥–æ–¥—É.\n",
      "\n",
      "–í –≥–æ–¥—ã –í–µ–ª–∏–∫–æ–π –û—Ç–µ—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –≤–æ–π–Ω—ã –ö—É—Ä—á–∞—Ç–æ–≤ —Ä–∞–±–æ—Ç–∞–ª –≤ –æ–±–ª–∞—Å—Ç–∏ —Ä–∞–¥–∏–æ–ª–æ–∫–∞—Ü–∏–∏ –∏ —Ä–∞–¥–∏–æ—Ç–µ—Ö–Ω–∏–∫–∏, —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞—è —Å–∏—Å—Ç–µ–º—ã —Ä–∞–¥–∏–æ–ª–æ–∫–∞—Ü–∏–∏ –∏ —Ä–∞–¥–∏–æ–ø–µ—Ä–µ–¥–∞—á–∏. –ü–æ—Å–ª–µ –≤–æ–π–Ω—ã –æ–Ω –ø—Ä–æ–¥–æ–ª–∂–∏–ª —Å–≤–æ—é —Ä–∞–±–æ—Ç—É –≤ –æ–±–ª–∞—Å—Ç–∏ —Ä–∞–¥–∏–æ—Ç–µ—Ö–Ω–∏–∫–∏ –∏ —Ä–∞–¥–∏–æ–ª–æ–∫–∞—Ü–∏–∏, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, –≤ –æ–±–ª–∞—Å—Ç–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞–¥–∏–æ–ª–æ–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –¥–ª—è –≤–æ–µ–Ω–Ω—ã—Ö —Ü–µ–ª–µ–π.\n",
      "\n",
      "–ö—É—Ä—á–∞—Ç–æ–≤ —Ç–∞–∫–∂–µ —Ä–∞–±–æ—Ç–∞–ª –≤ –æ–±–ª–∞—Å—Ç–∏ —Ä–∞–¥–∏–æ–ª–æ–∫–∞—Ü–∏–∏ –∏ —Ä–∞–¥–∏–æ—Ç–µ—Ö–Ω–∏–∫–∏ –≤ –æ–±–ª–∞—Å—Ç–∏ –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–∏—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π, –Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ –æ–±–ª–∞—Å—Ç–∏ —Ç–µ–ª–µ–≤–∏–¥–µ–Ω–∏—è –∏ —Ä–∞–¥–∏–æ—Ç–µ–ª–µ—Ñ–æ–Ω–∏–∏. –û–Ω –±—ã–ª –æ–¥–Ω–∏–º –∏–∑ –ø–µ—Ä–≤—ã—Ö, –∫—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª —Ä–∞–¥–∏–æ–ª–æ–∫–∞—Ü–∏—é –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –≤ –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–º –≤–æ–∑–¥—É—Ö–æ–ø–ª–∞–≤–∞–Ω–∏–∏.\n",
      "\n",
      "–ö—É—Ä—á–∞—Ç–æ–≤ –±—ã–ª —Ç–∞–∫–∂–µ –∏–∑–≤–µ—Å—Ç–µ–Ω –∫–∞–∫ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä –Ω–∞—É—á–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Ç—Ä—É–¥–∞ –∏ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å. –û–Ω –ø—Ä–µ–ø–æ–¥–∞–≤–∞–ª –≤ –≤—ã—Å—à–∏—Ö —É—á–µ–±–Ω—ã—Ö –∑–∞–≤–µ–¥–µ–Ω–∏—è—Ö –∏ –±—ã–ª —Ä–µ–∫—Ç–æ—Ä–æ–º –ú–æ—Å–∫–æ–≤—Å–∫–æ–≥–æ –∏–Ω—Å—Ç–∏—Ç—É—Ç–∞ –∏–Ω–∂–µ–Ω–µ—Ä–æ–≤ —Ä–∞–¥–∏–æ—Ç–µ—Ö–Ω–∏–∫–∏, —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π —Ç–µ—Ö–Ω–∏–∫–∏ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∫–∏.\n",
      "\n",
      "–í 1951 –≥–æ–¥—É –ö—É—Ä—á–∞—Ç–æ–≤ –±—ã–ª —É–¥–æ—Å—Ç–æ–µ–Ω –°—Ç–∞–ª–∏–Ω—Å–∫–æ–π –ø—Ä–µ–º–∏–∏ –∑–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É —Ä–∞–¥–∏–æ–ª–æ–∫–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã \"–°–≤–µ–º–∞\". –í 1960 –≥–æ–¥—É\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for text in prompts_for_test:\n",
    "    print(generate_answer(text))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd757c80-f9bc-40eb-8332-f3ecbe8c9ee0",
   "metadata": {},
   "source": [
    "lm_eval --model hf \\\n",
    "    --model_args pretrained=unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit,dtype=\"float\" \\\n",
    "    --tasks truthfulqa_ru_mc1 \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size auto:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d58037e0-e997-4caf-a3f9-3ad54c1743ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "INFO 09-09 14:33:34 [__init__.py:241] Automatically detected platform cuda.\n",
      "WARNING 09-09 14:33:34 [cuda.py:605] Detected different devices in the system: NVIDIA GeForce RTX 3090 Ti, NVIDIA GeForce RTX 3090. Please make sure to set `CUDA_DEVICE_ORDER=PCI_BUS_ID` to avoid unexpected behavior.\n",
      "2025-09-09:14:33:36 INFO     [__main__:446] Selected Tasks: ['truthfulqa_ru_mc1']\n",
      "2025-09-09:14:33:36 WARNING  [evaluator:172] pretrained=pretrained=unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit,dtype=float appears to be an instruct or chat variant but chat template is\n",
      "        not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).\n",
      "2025-09-09:14:33:36 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-09-09:14:33:36 INFO     [evaluator:240] Initializing hf model, with arguments: {'pretrained': 'unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit', 'dtype': 'float'}\n",
      "2025-09-09:14:33:36 INFO     [models.huggingface:147] Using device 'cuda:0'\n",
      "2025-09-09:14:33:37 INFO     [models.huggingface:414] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/quantizers/auto.py:239: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "2025-09-09:14:33:42 INFO     [api.task:434] Building contexts for truthfulqa_ru_mc1 on rank 0...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 788/788 [00:00<00:00, 173706.39it/s]\n",
      "2025-09-09:14:33:42 INFO     [evaluator:574] Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|                  | 0/3961 [00:00<?, ?it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Determined largest batch size: 22\n",
      "Running loglikelihood requests:  24%|‚ñà‚ñâ      | 948/3961 [01:42<02:50, 17.65it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  24%|‚ñà‚ñâ      | 969/3961 [01:58<02:49, 17.65it/s]Determined largest batch size: 25\n",
      "Running loglikelihood requests:  49%|‚ñà‚ñà‚ñà‚ñç   | 1950/3961 [03:09<01:48, 18.51it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  50%|‚ñà‚ñà‚ñà‚ñç   | 1974/3961 [03:28<01:47, 18.51it/s]Determined largest batch size: 25\n",
      "Running loglikelihood requests:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2926/3961 [04:32<00:53, 19.41it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2950/3961 [04:48<00:52, 19.41it/s]Determined largest batch size: 25\n",
      "Running loglikelihood requests:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3930/3961 [05:54<00:01, 20.33it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3954/3961 [06:08<00:00, 20.33it/s]Determined largest batch size: 32\n",
      "Running loglikelihood requests: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3961/3961 [06:21<00:00, 10.39it/s]\n",
      "fatal: –Ω–µ –Ω–∞–π–¥–µ–Ω git —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π (–∏–ª–∏ –æ–¥–∏–Ω –∏–∑ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏—Ö –∫–∞—Ç–∞–ª–æ–≥–æ–≤): .git\n",
      "2025-09-09:14:40:06 INFO     [loggers.evaluation_tracker:280] Output path not provided, skipping saving results aggregated\n",
      "hf (pretrained=unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit,dtype=float), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto:4 (22,25,25,25,32)\n",
      "|      Tasks      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
      "|-----------------|------:|------|-----:|------|---|-----:|---|-----:|\n",
      "|truthfulqa_ru_mc1|      1|none  |     0|acc   |‚Üë  |0.3185|¬±  |0.0166|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash ./lm-evaluation-harness/run_lmesh.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319e902-0ec2-4033-9f46-323e7dd7ed15",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c95b763-6617-4602-be3b-86195ffcceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151822/151822 [00:00<00:00, 171669.37 examples/s]\n",
      "Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3291/3291 [00:00<00:00, 157742.95 examples/s]\n"
     ]
    }
   ],
   "source": [
    "vikhr_dataset = load_dataset(\"Vikhrmodels/GrandMaster-PRO-MAX\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6783cb38-5c5a-45fa-afcb-64aeccafa5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'conversation', 'prompt_tokens', 'answer_tokens', 'cluster', 'prompt_lang', 'answer_lang'],\n",
       "    num_rows: 151822\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vikhr_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6c4ae45-abb2-44e9-a5a7-7a9be64a368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_russian(example):\n",
    "    return example['prompt_lang'] == 'ru' and example['answer_lang'] == 'ru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "646cb801-adcc-4f5c-8f7f-97af3321defb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151822/151822 [00:01<00:00, 101434.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "vikhr_dataset = vikhr_dataset.filter(filter_russian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8322674c-7d75-4b69-a20c-9cae524c8f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86295"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vikhr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4033d046-bb07-41d3-bed5-8254711b520b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': '—Å–ª—É—à–∞–π, —É –º–µ–Ω—è —Ç—É—Ç –≤–æ–∑–Ω–∏–∫–ª–∞ –∑–∞–¥–∞—á–∫–∞ –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –∫–æ–º–ø—å—é—Ç–µ—Ä–∞, –∏ —è –Ω–µ –º–æ–≥—É –≤ –Ω–µ–π —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è. –º–Ω–µ –Ω—É–∂–Ω–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –¥–æ—Å—Ç—É–ø –∫ –∫—ç—à-–ø–∞–º—è—Ç–∏ –≤ –º–Ω–æ–≥–æ—è–¥–µ—Ä–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π. —Ç—ã –Ω–µ –º–æ–≥ –±—ã –ø–æ–º–æ—á—å —Å —ç—Ç–∏–º? –≤–æ—Ç –∫–∞–∫ —è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é –∑–∞–¥–∞—á—É:\\n\\n1. –∏–º–µ–µ—Ç—Å—è –º–Ω–æ–≥–æ—è–¥–µ—Ä–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –æ–±—â–∏–º –∫—ç—à–µ–º –≤—Ç–æ—Ä–æ–≥–æ —É—Ä–æ–≤–Ω—è.\\n2. –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º–∞—Ö–∏ –∫—ç—à–∞ –ø—Ä–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö.\\n3. –∞–ª–≥–æ—Ä–∏—Ç–º –¥–æ–ª–∂–µ–Ω —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—Ç—å –¥–∞–Ω–Ω—ã–µ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ª–æ–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–Ω—ã–µ –ø—Ä–æ–º–∞—Ö–∏.\\n\\n–º–æ–∂–µ—Ç –µ—Å—Ç—å –∏–¥–µ–∏, –∫–∞–∫ —ç—Ç–æ –º–æ–∂–Ω–æ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –Ω–∞ —É—Ä–æ–≤–Ω–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞? –±—É–¥—É —Ä–∞–¥ –ª—é–±—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º –∏ —Å–æ–≤–µ—Ç–∞–º!',\n",
       "  'role': 'user'},\n",
       " {'content': '–í–∞—à–∞ –∑–∞–¥–∞—á–∞ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –∏ –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–Ω–æ–≥–æ—è–¥–µ—Ä–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤. –î–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫—ç—à-–ø–∞–º—è—Ç–∏ –≤–∞–∂–Ω–æ —É—á–∏—Ç—ã–≤–∞—Ç—å —Ç–∞–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã, –∫–∞–∫ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∏ –≤—Ä–µ–º–µ–Ω–Ω–∞—è –ª–æ–∫–∞–ª—å–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö, –∞ —Ç–∞–∫–∂–µ –∏–∑–±–µ–≥–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –ø—Ä–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–∏. –í–æ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ —à–∞–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞:\\n\\n### –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á\\n–ü—Ä–µ–∂–¥–µ –≤—Å–µ–≥–æ, –Ω—É–∂–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∑–∞–¥–∞—á, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ. –í–∞–∂–Ω–æ –ø–æ–Ω—è—Ç—å, –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∏ –∫–∞–∫ —á–∞—Å—Ç–æ –æ–Ω–∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞—é—Ç—Å—è.\\n\\n### –®–∞–≥ 2: –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö\\n–î–∞–ª–µ–µ, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª–∏—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–æ–∫–∞–ª—å–Ω–æ—Å—Ç–∏. –≠—Ç–æ –º–æ–∂–µ—Ç –≤–∫–ª—é—á–∞—Ç—å –≤ —Å–µ–±—è:\\n\\n- **–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö**: —á—Ç–æ–±—ã –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –æ–¥–Ω–æ–º—É —ç–ª–µ–º–µ–Ω—Ç—É –¥–∞–Ω–Ω—ã—Ö —Ä—è–¥–æ–º –Ω–∞—Ö–æ–¥–∏–ª–∏—Å—å –∏ –¥—Ä—É–≥–∏–µ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã.\\n- **–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —è–¥—Ä–∞–º–∏**: —á—Ç–æ–±—ã –∫–∞–∂–¥–æ–µ —è–¥—Ä–æ —Ä–∞–±–æ—Ç–∞–ª–æ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö –∏ –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–Ω—ã–µ –ø—Ä–æ–º–∞—Ö–∏.\\n\\n### –®–∞–≥ 3: –†–∞–∑–±–∏–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –±–ª–æ–∫–∏\\n–ü–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–∞, —Å–ª–µ–¥—É–µ—Ç —Ä–∞–∑–±–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ –±–ª–æ–∫–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è. –í –∏–¥–µ–∞–ª–µ, —Ä–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ –¥–æ–ª–∂–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ä—É –ª–∏–Ω–µ–π–∫–∏ –∫—ç—à–∞.\\n\\n### –®–∞–≥ 4: –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ø—Ä–µ–¥–≤—ã–±–æ—Ä–∫–∏ (prefetching)\\n–†–∞–∑—Ä–∞–±–æ—Ç–∞–π—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º –ø—Ä–µ–¥–≤—ã–±–æ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à –∑–∞—Ä–∞–Ω–µ–µ, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ –æ–±—Ä–∞—â–µ–Ω–∏–π –∫ –¥–∞–Ω–Ω—ã–º.\\n\\n### –®–∞–≥ 5: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º\\n–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Ç–∞–∫–∂–µ –æ–±–µ—Å–ø–µ—á–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º –º–µ–∂–¥—É —è–¥—Ä–∞–º–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Å–∏—Ç—É–∞—Ü–∏–π, –∫–æ–≥–¥–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —è–¥–µ—Ä –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ–±–Ω–æ–≤–ª—è—é—Ç –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à–µ.\\n\\n### –®–∞–≥ 6: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ç–ª–∞–¥–∫–∞\\n–ü—Ä–æ–≤–µ–¥–∏—Ç–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞–±–æ—á–∏—Ö –Ω–∞–≥—Ä—É–∑–∫–∞—Ö. –û—Ü–µ–Ω–∏—Ç–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞, –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–º–∞—Ö–æ–≤ –∫—ç—à–∞ –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞—è —Å –±–∞–∑–æ–≤—ã–º —Å–ª—É—á–∞–µ–º.\\n\\n### –®–∞–≥ 7: –ò—Ç–µ—Ä–∞—Ü–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è\\n–ù–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–Ω–µ—Å–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–∏–≤—ã –≤ –∞–ª–≥–æ—Ä–∏—Ç–º –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ. –ò—â–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.\\n\\n–≠—Ç–∏ —à–∞–≥–∏ –¥–æ–ª–∂–Ω—ã –ø–æ–º–æ—á—å –≤–∞–º –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫—ç—à-–ø–∞–º—è—Ç–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π. –£—Å–ø–µ—Ö–æ–≤ –≤ —Ä–∞–±–æ—Ç–µ!',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vikhr_dataset[1][\"conversation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cb329e9-73fd-4731-b61c-7d9cc274eb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n—Å–ª—É—à–∞–π, —É –º–µ–Ω—è —Ç—É—Ç –≤–æ–∑–Ω–∏–∫–ª–∞ –∑–∞–¥–∞—á–∫–∞ –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –∫–æ–º–ø—å—é—Ç–µ—Ä–∞, –∏ —è –Ω–µ –º–æ–≥—É –≤ –Ω–µ–π —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è. –º–Ω–µ –Ω—É–∂–Ω–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –¥–æ—Å—Ç—É–ø –∫ –∫—ç—à-–ø–∞–º—è—Ç–∏ –≤ –º–Ω–æ–≥–æ—è–¥–µ—Ä–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π. —Ç—ã –Ω–µ –º–æ–≥ –±—ã –ø–æ–º–æ—á—å —Å —ç—Ç–∏–º? –≤–æ—Ç –∫–∞–∫ —è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é –∑–∞–¥–∞—á—É:\\n\\n1. –∏–º–µ–µ—Ç—Å—è –º–Ω–æ–≥–æ—è–¥–µ—Ä–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –æ–±—â–∏–º –∫—ç—à–µ–º –≤—Ç–æ—Ä–æ–≥–æ —É—Ä–æ–≤–Ω—è.\\n2. –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º–∞—Ö–∏ –∫—ç—à–∞ –ø—Ä–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö.\\n3. –∞–ª–≥–æ—Ä–∏—Ç–º –¥–æ–ª–∂–µ–Ω —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—Ç—å –¥–∞–Ω–Ω—ã–µ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ª–æ–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–Ω—ã–µ –ø—Ä–æ–º–∞—Ö–∏.\\n\\n–º–æ–∂–µ—Ç –µ—Å—Ç—å –∏–¥–µ–∏, –∫–∞–∫ —ç—Ç–æ –º–æ–∂–Ω–æ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –Ω–∞ —É—Ä–æ–≤–Ω–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞? –±—É–¥—É —Ä–∞–¥ –ª—é–±—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º –∏ —Å–æ–≤–µ—Ç–∞–º!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n–í–∞—à–∞ –∑–∞–¥–∞—á–∞ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –∏ –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–Ω–æ–≥–æ—è–¥–µ—Ä–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤. –î–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫—ç—à-–ø–∞–º—è—Ç–∏ –≤–∞–∂–Ω–æ —É—á–∏—Ç—ã–≤–∞—Ç—å —Ç–∞–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã, –∫–∞–∫ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∏ –≤—Ä–µ–º–µ–Ω–Ω–∞—è –ª–æ–∫–∞–ª—å–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö, –∞ —Ç–∞–∫–∂–µ –∏–∑–±–µ–≥–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –ø—Ä–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–∏. –í–æ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ —à–∞–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞:\\n\\n### –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á\\n–ü—Ä–µ–∂–¥–µ –≤—Å–µ–≥–æ, –Ω—É–∂–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∑–∞–¥–∞—á, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ. –í–∞–∂–Ω–æ –ø–æ–Ω—è—Ç—å, –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∏ –∫–∞–∫ —á–∞—Å—Ç–æ –æ–Ω–∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞—é—Ç—Å—è.\\n\\n### –®–∞–≥ 2: –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö\\n–î–∞–ª–µ–µ, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª–∏—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–æ–∫–∞–ª—å–Ω–æ—Å—Ç–∏. –≠—Ç–æ –º–æ–∂–µ—Ç –≤–∫–ª—é—á–∞—Ç—å –≤ —Å–µ–±—è:\\n\\n- **–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö**: —á—Ç–æ–±—ã –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –æ–¥–Ω–æ–º—É —ç–ª–µ–º–µ–Ω—Ç—É –¥–∞–Ω–Ω—ã—Ö —Ä—è–¥–æ–º –Ω–∞—Ö–æ–¥–∏–ª–∏—Å—å –∏ –¥—Ä—É–≥–∏–µ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã.\\n- **–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —è–¥—Ä–∞–º–∏**: —á—Ç–æ–±—ã –∫–∞–∂–¥–æ–µ —è–¥—Ä–æ —Ä–∞–±–æ—Ç–∞–ª–æ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö –∏ –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–Ω—ã–µ –ø—Ä–æ–º–∞—Ö–∏.\\n\\n### –®–∞–≥ 3: –†–∞–∑–±–∏–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –±–ª–æ–∫–∏\\n–ü–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–∞, —Å–ª–µ–¥—É–µ—Ç —Ä–∞–∑–±–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ –±–ª–æ–∫–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è. –í –∏–¥–µ–∞–ª–µ, —Ä–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ –¥–æ–ª–∂–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ä—É –ª–∏–Ω–µ–π–∫–∏ –∫—ç—à–∞.\\n\\n### –®–∞–≥ 4: –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ø—Ä–µ–¥–≤—ã–±–æ—Ä–∫–∏ (prefetching)\\n–†–∞–∑—Ä–∞–±–æ—Ç–∞–π—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º –ø—Ä–µ–¥–≤—ã–±–æ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à –∑–∞—Ä–∞–Ω–µ–µ, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ –æ–±—Ä–∞—â–µ–Ω–∏–π –∫ –¥–∞–Ω–Ω—ã–º.\\n\\n### –®–∞–≥ 5: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º\\n–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Ç–∞–∫–∂–µ –æ–±–µ—Å–ø–µ—á–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º –º–µ–∂–¥—É —è–¥—Ä–∞–º–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Å–∏—Ç—É–∞—Ü–∏–π, –∫–æ–≥–¥–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —è–¥–µ—Ä –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ–±–Ω–æ–≤–ª—è—é—Ç –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à–µ.\\n\\n### –®–∞–≥ 6: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ç–ª–∞–¥–∫–∞\\n–ü—Ä–æ–≤–µ–¥–∏—Ç–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞–±–æ—á–∏—Ö –Ω–∞–≥—Ä—É–∑–∫–∞—Ö. –û—Ü–µ–Ω–∏—Ç–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞, –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–º–∞—Ö–æ–≤ –∫—ç—à–∞ –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞—è —Å –±–∞–∑–æ–≤—ã–º —Å–ª—É—á–∞–µ–º.\\n\\n### –®–∞–≥ 7: –ò—Ç–µ—Ä–∞—Ü–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è\\n–ù–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–Ω–µ—Å–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–∏–≤—ã –≤ –∞–ª–≥–æ—Ä–∏—Ç–º –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ. –ò—â–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.\\n\\n–≠—Ç–∏ —à–∞–≥–∏ –¥–æ–ª–∂–Ω—ã –ø–æ–º–æ—á—å –≤–∞–º –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫—ç—à-–ø–∞–º—è—Ç–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π. –£—Å–ø–µ—Ö–æ–≤ –≤ —Ä–∞–±–æ—Ç–µ!<|eot_id|>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template(vikhr_dataset[1][\"conversation\"], tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44cbfa61-543a-4cf8-8dee-012caede6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    return {\"text\": tokenizer.apply_chat_template(example[\"conversation\"], tokenize=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c682408-5a64-4532-b028-c93af43236b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_prep = vikhr_dataset.select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36f54688-5540-48ca-bf28-1237e217f86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check_data_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5908bdd0-6305-4689-a454-e11d00f8ed44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 1229.86 examples/s]\n"
     ]
    }
   ],
   "source": [
    "check_data = check_data_prep.map(formatting_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e1ddf2d-2413-4daa-adcc-2b39c8618be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'conversation', 'prompt_tokens', 'answer_tokens', 'cluster', 'prompt_lang', 'answer_lang', 'text'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb4c4353-dbc3-4472-aee4-d72cf7da5706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'generated/saiga/tagengo/lmsys_pref',\n",
       " 'conversation': [{'content': '–º–Ω–µ –æ—á–µ–Ω—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –∏–≥—Ä—ã, –∏ —è –Ω–µ–¥–∞–≤–Ω–æ —É–∑–Ω–∞–ª –ø—Ä–æ –∏–≥—Ä—É –Ω–∏–º. –Ω–µ –º–æ–≥ –±—ã —Ç—ã –æ–±—ä—è—Å–Ω–∏—Ç—å –º–Ω–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä—ã –≤ –Ω–∏–º? –∏ –µ—â–µ, –µ—Å–ª–∏ –µ—Å—Ç—å, –ø–æ–¥–µ–ª–∏—Å—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º –∏–≥—Ä—ã –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏ –∏–ª–∏ –¥—Ä—É–≥–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∏, –≤ –∫–æ—Ç–æ—Ä—ã–µ –º—ã –º–æ–≥–ª–∏ –±—ã —Å—ã–≥—Ä–∞—Ç—å –≤–º–µ—Å—Ç–µ. –∫–∞–∫ –Ω–∞—Å—á–µ—Ç —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å 15 puzzle? –º–Ω–µ –±—ã —Ö–æ—Ç–µ–ª–æ—Å—å —É–∑–Ω–∞—Ç—å, –µ—Å—Ç—å –ª–∏ –¥–ª—è –Ω–µ—ë –∫–∞–∫–∞—è-—Ç–æ –≤—ã–∏–≥—Ä—ã—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–ª–∏ –ø–æ–¥—Ö–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –ø–æ–±–µ–¥—É.',\n",
       "   'role': 'user'},\n",
       "  {'content': '–†–∞—Å—Å–∫–∞–∂—É —Ç–µ–±–µ –æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è—Ö –∏–≥—Ä—ã –≤ –ù–∏–º –∏ –∑–∞—Ç—Ä–æ–Ω—É —Ç–µ–º—É 15 Puzzle.\\n\\n### –°—Ç—Ä–∞—Ç–µ–≥–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä—ã –≤ –ù–∏–º\\n\\n–ò–≥—Ä–∞ –ù–∏–º ‚Äî —ç—Ç–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–≥—Ä–∞, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–π —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —á—ë—Ç–∫–∞—è –≤—ã–∏–≥—Ä—ã—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è. –û—Å–Ω–æ–≤–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ª–µ–∂–∏—Ç –≤ –ø–æ–Ω—è—Ç–∏–∏ –Ω–∏–º-—Å—É–º–º—ã ‚Äî —ç—Ç–æ –ø–æ–±–∏—Ç–æ–≤–æ–µ –∏—Å–∫–ª—é—á–∞—é—â–µ–µ –ò–õ–ò (XOR) —Ä–∞–∑–º–µ—Ä–æ–≤ –∫—É—á–µ–∫.\\n\\n–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Å–ª–µ–¥—É—é—â–µ–º:\\n\\n1. –í—ã—á–∏—Å–ª–∏ –Ω–∏–º-—Å—É–º–º—É –≤—Å–µ—Ö –∫—É—á–µ–∫.\\n2. –ï—Å–ª–∏ –Ω–∏–º-—Å—É–º–º–∞ —Ä–∞–≤–Ω–∞ –Ω—É–ª—é, —Ç–æ –≤–∞—à–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–æ–∏–≥—Ä—ã—à–Ω–æ–µ –ø—Ä–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä–µ —Å–æ–ø–µ—Ä–Ω–∏–∫–∞. –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –ø—Ä–æ—Å—Ç–æ –¥–µ–ª–∞–π—Ç–µ —Ö–æ–¥ –∏ —Å—Ç–∞—Ä–∞–π—Ç–µ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–æ–ø–µ—Ä–Ω–∏–∫–∞.\\n3. –ï—Å–ª–∏ –Ω–∏–º-—Å—É–º–º–∞ –Ω–µ —Ä–∞–≤–Ω–∞ –Ω—É–ª—é, –≤–∞–º –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Ö–æ–¥, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–Ω—å—à–∏—Ç —Ä–∞–∑–º–µ—Ä –æ–¥–Ω–æ–π –∏–∑ –∫—É—á–µ–∫ —Ç–∞–∫, —á—Ç–æ–±—ã –Ω–æ–≤–∞—è –Ω–∏–º-—Å—É–º–º–∞ –≤—Å–µ—Ö –∫—É—á–µ–∫ –±—ã–ª–∞ —Ä–∞–≤–Ω–∞ –Ω—É–ª—é.\\n4. –ü–æ—Å–ª–µ –≤–∞—à–µ–≥–æ —Ö–æ–¥–∞ —Å–æ–ø–µ—Ä–Ω–∏–∫ –æ–∫–∞–∂–µ—Ç—Å—è –≤ –ø–æ–ª–æ–∂–µ–Ω–∏–∏ —Å –Ω–∏–º-—Å—É–º–º–æ–π —Ä–∞–≤–Ω–æ–π –Ω—É–ª—é, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ–∏–≥—Ä—ã—à–Ω—ã–º –ø–æ–ª–æ–∂–µ–Ω–∏–µ–º –ø—Ä–∏ –≤–∞—à–µ–π –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä–µ.\\n\\n### –ò–≥—Ä–∞–µ–º –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏\\n\\n–ß—Ç–æ –∫–∞—Å–∞–µ—Ç—Å—è –∫—Ä–µ—Å—Ç–∏–∫–æ–≤-–Ω–æ–ª–∏–∫–æ–≤, –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏–≥—Ä—É –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º –ø–æ–ª–µ 5x5 –∏–ª–∏ 10x10, –≥–¥–µ –¥–ª—è –ø–æ–±–µ–¥—ã –Ω—É–∂–Ω–æ –≤—ã—Å—Ç—Ä–æ–∏—Ç—å —Ä—è–¥ –∏–∑ 5 —Å–∏–º–≤–æ–ª–æ–≤. –≠—Ç–æ –¥–æ–±–∞–≤–∏—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–π –≥–ª—É–±–∏–Ω—ã.\\n\\n### 15 Puzzle (–ü—è—Ç–Ω–∞—à–∫–∏)\\n\\n15 Puzzle ‚Äî —ç—Ç–æ –≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∞ —Å –ø–ª–∏—Ç–∫–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —É–ø–æ—Ä—è–¥–æ—á–∏—Ç—å –ø–æ –ø–æ—Ä—è–¥–∫—É, –ø–µ—Ä–µ–º–µ—â–∞—è –∏—Ö –≤ –ø—É—Å—Ç–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ. \\n\\n–î–ª—è 15 Puzzle —Å—É—â–µ—Å—Ç–≤—É—é—Ç –∞–ª–≥–æ—Ä–∏—Ç–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ—à–∞–µ–º–æ—Å—Ç—å –ø–∞–∑–ª–∞ (–Ω–µ –≤—Å–µ –Ω–∞—á–∞–ª—å–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ —Ä–µ—à–∞–µ–º—ã) –∏ –≤—ã–∏–≥—Ä—ã—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è, –µ—Å–ª–∏ –ø–∞–∑–ª —Ä–µ—à–∞–µ–º. –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é:\\n\\n1. –†–∞–∑–¥–µ–ª–∏—Ç–µ –ø–∞–∑–ª –Ω–∞ –∑–æ–Ω—ã –∏ —Ä–µ—à–∞–π—Ç–µ –ø–æ—ç—Ç–∞–ø–Ω–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–Ω–∞—á–∞–ª–∞ –≤–µ—Ä—Ö–Ω–∏–µ –¥–≤–µ —Å—Ç—Ä–æ–∫–∏, –∑–∞—Ç–µ–º –ª–µ–≤–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ –∏ —Ç.–¥.).\\n2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –¥–ª—è –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–ª–∏—Ç–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –º–∏–Ω–∏–º–∏–∑–∏—Ä—É—é—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –º–µ—Ç–æ–¥ \"–ø–µ—Ä–µ–≤–æ—Ä–æ—Ç–∞ —É–≥–ª–∞\").\\n3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞ –∑–∞–ø–æ–º–∏–Ω–∞–π—Ç–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ö–æ–¥–æ–≤, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–µ—à–∞—Ç—å —Ç–∏–ø–∏—á–Ω—ã–µ –∑–∞–¥–∞—á–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–∞–∫ –ø–æ–º–µ–Ω—è—Ç—å –º–µ—Å—Ç–∞–º–∏ –¥–≤–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–ª–∏—Ç–∫–∏).\\n\\n–°–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –±–µ–∑ –∑–Ω–∞–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Ö–æ–¥–æ–≤ —Ä–µ—à–∏—Ç—å –ø–∞–∑–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–≤–æ–ª—å–Ω–æ –Ω–µ–ø—Ä–æ—Å—Ç–æ, –æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ –≤—ã –Ω–µ –∏–º–µ–µ—Ç–µ –æ–ø—ã—Ç–∞ —Å –ø–æ–¥–æ–±–Ω—ã–º–∏ –≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∞–º–∏. –ù–æ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤, –ø–∞–∑–ª —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Ä–µ—à–∞–µ–º—ã–º –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤—Å–µ–≥–¥–∞.',\n",
       "   'role': 'assistant'}],\n",
       " 'prompt_tokens': 185,\n",
       " 'answer_tokens': 894,\n",
       " 'cluster': 21,\n",
       " 'prompt_lang': 'ru',\n",
       " 'answer_lang': 'ru',\n",
       " 'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–º–Ω–µ –æ—á–µ–Ω—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –∏–≥—Ä—ã, –∏ —è –Ω–µ–¥–∞–≤–Ω–æ —É–∑–Ω–∞–ª –ø—Ä–æ –∏–≥—Ä—É –Ω–∏–º. –Ω–µ –º–æ–≥ –±—ã —Ç—ã –æ–±—ä—è—Å–Ω–∏—Ç—å –º–Ω–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä—ã –≤ –Ω–∏–º? –∏ –µ—â–µ, –µ—Å–ª–∏ –µ—Å—Ç—å, –ø–æ–¥–µ–ª–∏—Å—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º –∏–≥—Ä—ã –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏ –∏–ª–∏ –¥—Ä—É–≥–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∏, –≤ –∫–æ—Ç–æ—Ä—ã–µ –º—ã –º–æ–≥–ª–∏ –±—ã —Å—ã–≥—Ä–∞—Ç—å –≤–º–µ—Å—Ç–µ. –∫–∞–∫ –Ω–∞—Å—á–µ—Ç —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å 15 puzzle? –º–Ω–µ –±—ã —Ö–æ—Ç–µ–ª–æ—Å—å —É–∑–Ω–∞—Ç—å, –µ—Å—Ç—å –ª–∏ –¥–ª—è –Ω–µ—ë –∫–∞–∫–∞—è-—Ç–æ –≤—ã–∏–≥—Ä—ã—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–ª–∏ –ø–æ–¥—Ö–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –ø–æ–±–µ–¥—É.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n–†–∞—Å—Å–∫–∞–∂—É —Ç–µ–±–µ –æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è—Ö –∏–≥—Ä—ã –≤ –ù–∏–º –∏ –∑–∞—Ç—Ä–æ–Ω—É —Ç–µ–º—É 15 Puzzle.\\n\\n### –°—Ç—Ä–∞—Ç–µ–≥–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä—ã –≤ –ù–∏–º\\n\\n–ò–≥—Ä–∞ –ù–∏–º ‚Äî —ç—Ç–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–≥—Ä–∞, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–π —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —á—ë—Ç–∫–∞—è –≤—ã–∏–≥—Ä—ã—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è. –û—Å–Ω–æ–≤–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ª–µ–∂–∏—Ç –≤ –ø–æ–Ω—è—Ç–∏–∏ –Ω–∏–º-—Å—É–º–º—ã ‚Äî —ç—Ç–æ –ø–æ–±–∏—Ç–æ–≤–æ–µ –∏—Å–∫–ª—é—á–∞—é—â–µ–µ –ò–õ–ò (XOR) —Ä–∞–∑–º–µ—Ä–æ–≤ –∫—É—á–µ–∫.\\n\\n–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Å–ª–µ–¥—É—é—â–µ–º:\\n\\n1. –í—ã—á–∏—Å–ª–∏ –Ω–∏–º-—Å—É–º–º—É –≤—Å–µ—Ö –∫—É—á–µ–∫.\\n2. –ï—Å–ª–∏ –Ω–∏–º-—Å—É–º–º–∞ —Ä–∞–≤–Ω–∞ –Ω—É–ª—é, —Ç–æ –≤–∞—à–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–æ–∏–≥—Ä—ã—à–Ω–æ–µ –ø—Ä–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä–µ —Å–æ–ø–µ—Ä–Ω–∏–∫–∞. –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –ø—Ä–æ—Å—Ç–æ –¥–µ–ª–∞–π—Ç–µ —Ö–æ–¥ –∏ —Å—Ç–∞—Ä–∞–π—Ç–µ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–æ–ø–µ—Ä–Ω–∏–∫–∞.\\n3. –ï—Å–ª–∏ –Ω–∏–º-—Å—É–º–º–∞ –Ω–µ —Ä–∞–≤–Ω–∞ –Ω—É–ª—é, –≤–∞–º –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Ö–æ–¥, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–Ω—å—à–∏—Ç —Ä–∞–∑–º–µ—Ä –æ–¥–Ω–æ–π –∏–∑ –∫—É—á–µ–∫ —Ç–∞–∫, —á—Ç–æ–±—ã –Ω–æ–≤–∞—è –Ω–∏–º-—Å—É–º–º–∞ –≤—Å–µ—Ö –∫—É—á–µ–∫ –±—ã–ª–∞ —Ä–∞–≤–Ω–∞ –Ω—É–ª—é.\\n4. –ü–æ—Å–ª–µ –≤–∞—à–µ–≥–æ —Ö–æ–¥–∞ —Å–æ–ø–µ—Ä–Ω–∏–∫ –æ–∫–∞–∂–µ—Ç—Å—è –≤ –ø–æ–ª–æ–∂–µ–Ω–∏–∏ —Å –Ω–∏–º-—Å—É–º–º–æ–π —Ä–∞–≤–Ω–æ–π –Ω—É–ª—é, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ–∏–≥—Ä—ã—à–Ω—ã–º –ø–æ–ª–æ–∂–µ–Ω–∏–µ–º –ø—Ä–∏ –≤–∞—à–µ–π –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä–µ.\\n\\n### –ò–≥—Ä–∞–µ–º –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏\\n\\n–ß—Ç–æ –∫–∞—Å–∞–µ—Ç—Å—è –∫—Ä–µ—Å—Ç–∏–∫–æ–≤-–Ω–æ–ª–∏–∫–æ–≤, –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏–≥—Ä—É –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º –ø–æ–ª–µ 5x5 –∏–ª–∏ 10x10, –≥–¥–µ –¥–ª—è –ø–æ–±–µ–¥—ã –Ω—É–∂–Ω–æ –≤—ã—Å—Ç—Ä–æ–∏—Ç—å —Ä—è–¥ –∏–∑ 5 —Å–∏–º–≤–æ–ª–æ–≤. –≠—Ç–æ –¥–æ–±–∞–≤–∏—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–π –≥–ª—É–±–∏–Ω—ã.\\n\\n### 15 Puzzle (–ü—è—Ç–Ω–∞—à–∫–∏)\\n\\n15 Puzzle ‚Äî —ç—Ç–æ –≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∞ —Å –ø–ª–∏—Ç–∫–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —É–ø–æ—Ä—è–¥–æ—á–∏—Ç—å –ø–æ –ø–æ—Ä—è–¥–∫—É, –ø–µ—Ä–µ–º–µ—â–∞—è –∏—Ö –≤ –ø—É—Å—Ç–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ. \\n\\n–î–ª—è 15 Puzzle —Å—É—â–µ—Å—Ç–≤—É—é—Ç –∞–ª–≥–æ—Ä–∏—Ç–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ—à–∞–µ–º–æ—Å—Ç—å –ø–∞–∑–ª–∞ (–Ω–µ –≤—Å–µ –Ω–∞—á–∞–ª—å–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ —Ä–µ—à–∞–µ–º—ã) –∏ –≤—ã–∏–≥—Ä—ã—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è, –µ—Å–ª–∏ –ø–∞–∑–ª —Ä–µ—à–∞–µ–º. –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é:\\n\\n1. –†–∞–∑–¥–µ–ª–∏—Ç–µ –ø–∞–∑–ª –Ω–∞ –∑–æ–Ω—ã –∏ —Ä–µ—à–∞–π—Ç–µ –ø–æ—ç—Ç–∞–ø–Ω–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–Ω–∞—á–∞–ª–∞ –≤–µ—Ä—Ö–Ω–∏–µ –¥–≤–µ —Å—Ç—Ä–æ–∫–∏, –∑–∞—Ç–µ–º –ª–µ–≤–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ –∏ —Ç.–¥.).\\n2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –¥–ª—è –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–ª–∏—Ç–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –º–∏–Ω–∏–º–∏–∑–∏—Ä—É—é—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –º–µ—Ç–æ–¥ \"–ø–µ—Ä–µ–≤–æ—Ä–æ—Ç–∞ —É–≥–ª–∞\").\\n3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞ –∑–∞–ø–æ–º–∏–Ω–∞–π—Ç–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ö–æ–¥–æ–≤, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–µ—à–∞—Ç—å —Ç–∏–ø–∏—á–Ω—ã–µ –∑–∞–¥–∞—á–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–∞–∫ –ø–æ–º–µ–Ω—è—Ç—å –º–µ—Å—Ç–∞–º–∏ –¥–≤–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–ª–∏—Ç–∫–∏).\\n\\n–°–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –±–µ–∑ –∑–Ω–∞–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Ö–æ–¥–æ–≤ —Ä–µ—à–∏—Ç—å –ø–∞–∑–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–≤–æ–ª—å–Ω–æ –Ω–µ–ø—Ä–æ—Å—Ç–æ, –æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ –≤—ã –Ω–µ –∏–º–µ–µ—Ç–µ –æ–ø—ã—Ç–∞ —Å –ø–æ–¥–æ–±–Ω—ã–º–∏ –≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∞–º–∏. –ù–æ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤, –ø–∞–∑–ª —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Ä–µ—à–∞–µ–º—ã–º –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤—Å–µ–≥–¥–∞.<|eot_id|>'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "708343a9-a718-4c84-81d5-032b6fd02c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–º–Ω–µ –æ—á–µ–Ω—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –∏–≥—Ä—ã, –∏ —è –Ω–µ–¥–∞–≤–Ω–æ —É–∑–Ω–∞–ª –ø—Ä–æ –∏–≥—Ä—É –Ω–∏–º. –Ω–µ –º–æ–≥ –±—ã —Ç—ã –æ–±—ä—è—Å–Ω–∏—Ç—å –º–Ω–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä—ã –≤ –Ω–∏–º? –∏ –µ—â–µ, –µ—Å–ª–∏ –µ—Å—Ç—å, –ø–æ–¥–µ–ª–∏—Å—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º –∏–≥—Ä—ã –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏ –∏–ª–∏ –¥—Ä—É–≥–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∏, –≤ –∫–æ—Ç–æ—Ä—ã–µ –º—ã –º–æ–≥–ª–∏ –±—ã —Å—ã–≥—Ä–∞—Ç—å –≤–º–µ—Å—Ç–µ. –∫–∞–∫ –Ω–∞—Å—á–µ—Ç —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å 15 puzzle? –º–Ω–µ –±—ã —Ö–æ—Ç–µ–ª–æ—Å—å —É–∑–Ω–∞—Ç—å, –µ—Å—Ç—å –ª–∏ –¥–ª—è –Ω–µ—ë –∫–∞–∫–∞—è-—Ç–æ –≤—ã–∏–≥—Ä—ã—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–ª–∏ –ø–æ–¥—Ö–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –ø–æ–±–µ–¥—É.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n–†–∞—Å—Å–∫–∞–∂—É —Ç–µ–±–µ –æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è—Ö –∏–≥—Ä—ã –≤ –ù–∏–º –∏ –∑–∞—Ç—Ä–æ–Ω—É —Ç–µ–º—É 15 Puzzle.\\n\\n### –°—Ç—Ä–∞—Ç–µ–≥–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä—ã –≤ –ù–∏–º\\n\\n–ò–≥—Ä–∞ –ù–∏–º ‚Äî —ç—Ç–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–≥—Ä–∞, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–π —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —á—ë—Ç–∫–∞—è –≤—ã–∏–≥—Ä—ã—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è. –û—Å–Ω–æ–≤–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ª–µ–∂–∏—Ç –≤ –ø–æ–Ω—è—Ç–∏–∏ –Ω–∏–º-—Å—É–º–º—ã ‚Äî —ç—Ç–æ –ø–æ–±–∏—Ç–æ–≤–æ–µ –∏—Å–∫–ª—é—á–∞—é—â–µ–µ –ò–õ–ò (XOR) —Ä–∞–∑–º–µ—Ä–æ–≤ –∫—É—á–µ–∫.\\n\\n–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Å–ª–µ–¥—É—é—â–µ–º:\\n\\n1. –í—ã—á–∏—Å–ª–∏ –Ω–∏–º-—Å—É–º–º—É –≤—Å–µ—Ö –∫—É—á–µ–∫.\\n2. –ï—Å–ª–∏ –Ω–∏–º-—Å—É–º–º–∞ —Ä–∞–≤–Ω–∞ –Ω—É–ª—é, —Ç–æ –≤–∞—à–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–æ–∏–≥—Ä—ã—à–Ω–æ–µ –ø—Ä–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä–µ —Å–æ–ø–µ—Ä–Ω–∏–∫–∞. –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –ø—Ä–æ—Å—Ç–æ –¥–µ–ª–∞–π—Ç–µ —Ö–æ–¥ –∏ —Å—Ç–∞—Ä–∞–π—Ç–µ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–æ–ø–µ—Ä–Ω–∏–∫–∞.\\n3. –ï—Å–ª–∏ –Ω–∏–º-—Å—É–º–º–∞ –Ω–µ —Ä–∞–≤–Ω–∞ –Ω—É–ª—é, –≤–∞–º –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Ö–æ–¥, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–Ω—å—à–∏—Ç —Ä–∞–∑–º–µ—Ä –æ–¥–Ω–æ–π –∏–∑ –∫—É—á–µ–∫ —Ç–∞–∫, —á—Ç–æ–±—ã –Ω–æ–≤–∞—è –Ω–∏–º-—Å—É–º–º–∞ –≤—Å–µ—Ö –∫—É—á–µ–∫ –±—ã–ª–∞ —Ä–∞–≤–Ω–∞ –Ω—É–ª—é.\\n4. –ü–æ—Å–ª–µ –≤–∞—à–µ–≥–æ —Ö–æ–¥–∞ —Å–æ–ø–µ—Ä–Ω–∏–∫ –æ–∫–∞–∂–µ—Ç—Å—è –≤ –ø–æ–ª–æ–∂–µ–Ω–∏–∏ —Å –Ω–∏–º-—Å—É–º–º–æ–π —Ä–∞–≤–Ω–æ–π –Ω—É–ª—é, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ–∏–≥—Ä—ã—à–Ω—ã–º –ø–æ–ª–æ–∂–µ–Ω–∏–µ–º –ø—Ä–∏ –≤–∞—à–µ–π –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä–µ.\\n\\n### –ò–≥—Ä–∞–µ–º –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏\\n\\n–ß—Ç–æ –∫–∞—Å–∞–µ—Ç—Å—è –∫—Ä–µ—Å—Ç–∏–∫–æ–≤-–Ω–æ–ª–∏–∫–æ–≤, –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏–≥—Ä—É –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º –ø–æ–ª–µ 5x5 –∏–ª–∏ 10x10, –≥–¥–µ –¥–ª—è –ø–æ–±–µ–¥—ã –Ω—É–∂–Ω–æ –≤—ã—Å—Ç—Ä–æ–∏—Ç—å —Ä—è–¥ –∏–∑ 5 —Å–∏–º–≤–æ–ª–æ–≤. –≠—Ç–æ –¥–æ–±–∞–≤–∏—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–π –≥–ª—É–±–∏–Ω—ã.\\n\\n### 15 Puzzle (–ü—è—Ç–Ω–∞—à–∫–∏)\\n\\n15 Puzzle ‚Äî —ç—Ç–æ –≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∞ —Å –ø–ª–∏—Ç–∫–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —É–ø–æ—Ä—è–¥–æ—á–∏—Ç—å –ø–æ –ø–æ—Ä—è–¥–∫—É, –ø–µ—Ä–µ–º–µ—â–∞—è –∏—Ö –≤ –ø—É—Å—Ç–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ. \\n\\n–î–ª—è 15 Puzzle —Å—É—â–µ—Å—Ç–≤—É—é—Ç –∞–ª–≥–æ—Ä–∏—Ç–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ—à–∞–µ–º–æ—Å—Ç—å –ø–∞–∑–ª–∞ (–Ω–µ –≤—Å–µ –Ω–∞—á–∞–ª—å–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ —Ä–µ—à–∞–µ–º—ã) –∏ –≤—ã–∏–≥—Ä—ã—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è, –µ—Å–ª–∏ –ø–∞–∑–ª —Ä–µ—à–∞–µ–º. –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é:\\n\\n1. –†–∞–∑–¥–µ–ª–∏—Ç–µ –ø–∞–∑–ª –Ω–∞ –∑–æ–Ω—ã –∏ —Ä–µ—à–∞–π—Ç–µ –ø–æ—ç—Ç–∞–ø–Ω–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–Ω–∞—á–∞–ª–∞ –≤–µ—Ä—Ö–Ω–∏–µ –¥–≤–µ —Å—Ç—Ä–æ–∫–∏, –∑–∞—Ç–µ–º –ª–µ–≤–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ –∏ —Ç.–¥.).\\n2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –¥–ª—è –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–ª–∏—Ç–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –º–∏–Ω–∏–º–∏–∑–∏—Ä—É—é—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –º–µ—Ç–æ–¥ \"–ø–µ—Ä–µ–≤–æ—Ä–æ—Ç–∞ —É–≥–ª–∞\").\\n3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞ –∑–∞–ø–æ–º–∏–Ω–∞–π—Ç–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ö–æ–¥–æ–≤, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–µ—à–∞—Ç—å —Ç–∏–ø–∏—á–Ω—ã–µ –∑–∞–¥–∞—á–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–∞–∫ –ø–æ–º–µ–Ω—è—Ç—å –º–µ—Å—Ç–∞–º–∏ –¥–≤–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–ª–∏—Ç–∫–∏).\\n\\n–°–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –±–µ–∑ –∑–Ω–∞–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Ö–æ–¥–æ–≤ —Ä–µ—à–∏—Ç—å –ø–∞–∑–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–≤–æ–ª—å–Ω–æ –Ω–µ–ø—Ä–æ—Å—Ç–æ, –æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ –≤—ã –Ω–µ –∏–º–µ–µ—Ç–µ –æ–ø—ã—Ç–∞ —Å –ø–æ–¥–æ–±–Ω—ã–º–∏ –≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∞–º–∏. –ù–æ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤, –ø–∞–∑–ª —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Ä–µ—à–∞–µ–º—ã–º –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤—Å–µ–≥–¥–∞.<|eot_id|>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b77849b-b3e2-45f6-802a-2c7f2cbcb4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 86295/86295 [00:10<00:00, 8503.30 examples/s] \n"
     ]
    }
   ],
   "source": [
    "train_data = vikhr_dataset.map(formatting_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c3f7a9-bd87-4613-a9da-22946c77b31d",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8406e941-3d1e-439e-82e2-4f39fbbdee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=24): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 86295/86295 [00:07<00:00, 11717.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_data,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = SFTConfig(\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=30,\n",
    "        num_train_epochs=1,\n",
    "        max_steps=100,\n",
    "        learning_rate=2e-3,\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51a93a66-43b4-446f-bacf-81aeac3de5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA before train] allocated=5.50GB, reserved=5.52GB, peak=7.02GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA before train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5225d2b-b300-4353-a2c7-28bd8738cfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "2.7.1+cu126\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(torch.__version__); print(torch.cuda.is_available())\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7027802-6562-42f6-a909-fd7b2e703939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccd7ad18-187c-4576-b33d-d3aa8d870d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device count: 2\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 3090 Ti\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd6254b7-d7ca-48c3-9175-fb4448247d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 86,295 | Num Epochs = 1 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 35:15, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.319000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.439800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.394200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.206600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.215700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.084200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.080200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.121300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.140200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.992200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.944200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.955500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.963900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.985900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.056100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.995500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.080800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.988700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.975700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.972800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.940700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.907100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.980400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.089000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.071900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.979400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.971400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.987300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.990700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.983900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.941500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.083600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.989900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.930900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.021200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.963200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.920500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.871800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.969800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.924000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.866200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.949600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.955300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.998600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.834200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.976500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.980300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.954400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.916600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.964500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.943100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.968700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.992100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.948800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.943900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.982300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.906900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.983300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.897900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.984300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.903100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.873400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.871100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.940300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.866000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>1.014100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.842600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.977100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.924700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.950700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.966900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.873500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.954800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.995800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "554314e2-af7a-4ca1-a9e9-d1de5e0ce21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=5.77GB, reserved=10.22GB, peak=11.74GB\n",
      "NVML used=11.35GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41e70f11-0c48-47bf-b93b-1929813862f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_model/tokenizer_config.json',\n",
       " 'lora_model/special_tokens_map.json',\n",
       " 'lora_model/chat_template.jinja',\n",
       " 'lora_model/tokenizer.json')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"lora_model\")\n",
    "tokenizer.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba60ed9a-3cf3-407c-be79-d6a0b42bbc57",
   "metadata": {},
   "source": [
    "### –û—Ü–µ–Ω–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d2e4c5c-ae46-4290-af66-3ce2e17b6e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.1: Fast Llama patching. Transformers: 4.56.1. vLLM: 0.10.1.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090 Ti. Num GPUs = 2. Max memory: 23.536 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.9.1 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"lora_model\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,    # QLoRA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "397e307f-b719-4b2b-961d-d39c2187c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found HuggingFace hub cache directory: /home/viv232/.cache/huggingface/hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking cache directory for required files...\n",
      "Cache check failed: model-00001-of-00004.safetensors not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [36:15<00:00, 543.96s/it]\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(\"llama-3.1-8B-instruct_lora_ru\", tokenizer, save_method=\"merged_16bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07160058-de60-4d8d-8943-35e156fcc7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|end_header_id|>\n",
      "\n",
      "–ö–æ–Ω–µ—á–Ω–æ, –¥–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º—Å—è, –∫–∞–∫ –º–æ–∂–Ω–æ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –≤–∫—É—Å–Ω—É—é –∏–Ω–¥–µ–π–∫—É –Ω–∞ –≥—Ä–∏–ª–µ.\n",
      "\n",
      "### –®–∞–≥–∏ –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è –∏–Ω–¥–µ–π–∫–∏ –Ω–∞ –≥—Ä–∏–ª–µ:\n",
      "\n",
      "#### –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω–¥–µ–π–∫–∏\n",
      "–ü—Ä–µ–∂–¥–µ –≤—Å–µ–≥–æ, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å —Å–≤–µ–∂–∞—è –∏–Ω–¥–µ–π–∫–∞. –ï—Å–ª–∏ –∏–Ω–¥–µ–π–∫–∞ –∑–∞–º–æ—Ä–æ–∂–µ–Ω–∞, –µ—ë –Ω—É–∂–Ω–æ —Ä–∞–∑–º–æ—Ä–æ–∑–∏—Ç—å.\n",
      "\n",
      "#### –®–∞–≥ 2: –ú–∞—Ä–∏–Ω–∞–¥\n",
      "–ú–∞—Ä–∏–Ω–∞–¥ –ø–æ–º–æ–≥–∞–µ—Ç –∏–Ω–¥–µ–π–∫–µ —Å—Ç–∞—Ç—å –±–æ–ª–µ–µ —Å–æ—á–Ω–æ–π –∏ –∞—Ä–æ–º–∞—Ç–Ω–æ–π. –í –±–ª–µ–Ω–¥–µ—Ä–µ —Å–º–µ—à–∞–π—Ç–µ:\n",
      "- 1/2 —Å—Ç–∞–∫–∞–Ω–∞ –æ–ª–∏–≤–∫–æ–≤–æ–≥–æ –º–∞—Å–ª–∞\n",
      "- 2 —Å—Ç–æ–ª–æ–≤—ã–µ –ª–æ–∂–∫–∏ –ª–∏–º–æ–Ω–Ω–æ–≥–æ —Å–æ–∫–∞\n",
      "- 1 —Å—Ç–æ–ª–æ–≤–∞—è –ª–æ–∂–∫–∞ —Å–æ–ª–∏\n",
      "- 1 —Å—Ç–æ–ª–æ–≤–∞—è –ª–æ–∂–∫–∞ —Å–∞—Ö–∞—Ä–∞\n",
      "- 2 –∑—É–±—á–∏–∫–∞ —á–µ—Å–Ω–æ–∫–∞, –∏–∑–º–µ–ª—å—á–µ–Ω–Ω–æ–≥–æ\n",
      "- 1 —á–∞–π–Ω—É—é –ª–æ–∂–∫—É –º–æ–ª–æ—Ç–æ–≥–æ —á–µ—Ä–Ω–æ–≥–æ –ø–µ—Ä—Ü–∞\n",
      "- 1 —á–∞–π–Ω—É—é –ª–æ–∂–∫—É –º–æ–ª–æ—Ç–æ–≥–æ –æ—Ä–µ–≥–∞–Ω–æ\n",
      "- 1 —á–∞–π–Ω—É—é –ª–æ–∂–∫—É –º–æ–ª–æ—Ç–æ–≥–æ —Ä–æ–∑–º–∞—Ä–∏–Ω–∞\n",
      "\n",
      "#### –®–∞–≥ 3: –ù–∞—Ä–µ–∑–∫–∞ –∏–Ω–¥–µ–π–∫–∏\n",
      "–ù–∞—Ä–µ–∂—å—Ç–µ –∏–Ω–¥–µ–π–∫—É –Ω–∞ –ø–æ—Ä—Ü–∏–∏. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –≥—Ä—É–¥–∫–∞, —Ä–µ–∂—å—Ç–µ –µ—ë –ø–æ–ø–µ—Ä—ë–∫ –≤–æ–ª–æ–∫–æ–Ω –Ω–∞ –ø–æ—Ä—Ü–∏–∏. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –Ω–æ–∂–∫–∞, —Ä–µ–∂—å—Ç–µ –µ—ë –Ω–∞ –ø–æ—Ä—Ü–∏–∏ –ø–æ 1-2 —Å—Ç–µ–±–µ–ª—å—Ü–∞–º. –ï—Å–ª–∏ —É\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "–ò—Å—Ö–æ–¥—è –∏–∑ –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞, –º–æ–∂–Ω–æ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç—å, —á—Ç–æ –≤—ã –∏—â–µ—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –ø—Ä–∏–±–ª–∏–∂–∞—é—â–µ–≥–æ—Å—è –∏–Ω—Å—É–ª—å—Ç–∞. –ò–Ω—Å—É–ª—å—Ç ‚Äì —ç—Ç–æ –æ—Å—Ç—Ä–æ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ –º–æ–∑–≥–æ–≤–æ–≥–æ –∫—Ä–æ–≤–æ–æ–±—Ä–∞—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—é –º–æ–∑–≥–æ–≤—ã—Ö —Ç–∫–∞–Ω–µ–π. –ü—Ä–æ–±–ª–µ–º—ã —Å –∫—Ä–æ–≤–æ–æ–±—Ä–∞—â–µ–Ω–∏–µ–º –≤ –º–æ–∑–≥–µ –º–æ–≥—É—Ç –≤–æ–∑–Ω–∏–∫–∞—Ç—å –∏–∑-–∑–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø—Ä–∏—á–∏–Ω, –≤–∫–ª—é—á–∞—è –≤—ã—Å–æ–∫–æ–µ –∫—Ä–æ–≤—è–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ, –∞—Ç–µ—Ä–æ—Å–∫–ª–µ—Ä–æ–∑, –¥–∏–∞–±–µ—Ç, –∫—É—Ä–µ–Ω–∏–µ –∏ –¥—Ä—É–≥–∏–µ.\n",
      "\n",
      "–ß—Ç–æ–±—ã —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ø—Ä–∏–±–ª–∏–∂–∞—é—â–∏–π—Å—è –∏–Ω—Å—É–ª—å—Ç, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:\n",
      "\n",
      "1. **–¢–æ—à–Ω–æ—Ç–∞ –∏ —Ä–≤–æ—Ç–∞**: –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–¥–Ω–∏–º –∏–∑ –ø–µ—Ä–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–∏–±–ª–∏–∂–∞—é—â–µ–≥–æ—Å—è –∏–Ω—Å—É–ª—å—Ç–∞, –æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ –æ–Ω–∏ –ø–æ—è–≤–ª—è—é—Ç—Å—è –±–µ–∑ –≤–∏–¥–∏–º–æ–π –ø—Ä–∏—á–∏–Ω—ã.\n",
      "2. **–ì–æ–ª–æ–≤–Ω–∞—è –±–æ–ª—å**: –û—Å—Ç—Ä–∞—è –≥–æ–ª–æ–≤–Ω–∞—è –±–æ–ª—å, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –ª–µ–≤–æ–º –∏–ª–∏ –ø—Ä–∞–≤–æ–º –∑–∞—Ç—ã–ª–∫–µ, –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–º –ø—Ä–∏–±–ª–∏–∂–∞—é—â–µ–≥–æ—Å—è –∏–Ω—Å—É–ª—å—Ç–∞.\n",
      "3. **–î–µ–∑–æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è –∏ –Ω–∞—Ä—É—à–µ–Ω–∏—è —Å–æ–∑–Ω–∞–Ω–∏—è**: –£ –ª—é–¥–µ–π —Å –ø—Ä–∏–±–ª–∏–∂–∞—é—â–∏–º—Å—è –∏–Ω—Å—É–ª—å—Ç–æ–º –º–æ–∂–µ—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å –æ—â—É—â–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—è–Ω–Ω–æ—Å—Ç–∏, –Ω–µ–¥–æ—É–º–µ–Ω–∏–µ –∏–ª–∏ –ø–æ—Ç–µ—Ä—è —Å–æ–∑–Ω–∞–Ω–∏—è.\n",
      "4. **–ù–∞—Ä—É—à–µ–Ω–∏—è —Ä–µ—á–∏**: –°–ª–æ–∂–Ω–æ—Å—Ç–∏ —Å —Ä–µ—á—å—é, –≤–∫–ª—é—á–∞—è –±–æ—Ä–º–æ—Ç–∞–Ω–∏–µ, –∑–∞–º–∏–Ω–∫–∏ –∏–ª–∏ –ø–æ–ª–Ω–æ–µ –æ—Ç—Å—É—Ç—Å—Ç–≤\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "–ö–∞–Ω–æ–Ω—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥—Ä–µ–≤–Ω–∏—Ö —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–π –≤–∫–ª—é—á–∞—é—Ç –≤ —Å–µ–±—è —Ä—è–¥ –æ–±—â–∏—Ö –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ –∏ –ø—Ä–∞–≤–∏–ª, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–º–µ–Ω—è–ª–∏—Å—å –ø—Ä–∏ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–µ –∑–¥–∞–Ω–∏–π, —Å–æ–æ—Ä—É–∂–µ–Ω–∏–π –∏ –≥–æ—Ä–æ–¥–æ–≤ –≤ –¥—Ä–µ–≤–Ω–æ—Å—Ç–∏. –í–æ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –∏–∑ –Ω–∏—Ö:\n",
      "\n",
      "### 1. –ü—Ä–∏–Ω—Ü–∏–ø—ã —Å–∏–º–º–µ—Ç—Ä–∏–∏\n",
      "- **–ê—Å–∏–º–º–µ—Ç—Ä–∏—è**: –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –¥—Ä–µ–≤–Ω–∏–µ —Å—Ç–∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –∞—Å–∏–º–º–µ—Ç—Ä–∏—é, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞–≤–∞—Ç—å –æ—â—É—â–µ–Ω–∏–µ –¥–∏–Ω–∞–º–∏–∫–∏ –∏ –¥–≤–∏–∂–µ–Ω–∏—è.\n",
      "- **–°–∏–º–º–µ—Ç—Ä–∏—è**: –°–∏–º–º–µ—Ç—Ä–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —á—É–≤—Å—Ç–≤–∞ –≥–∞—Ä–º–æ–Ω–∏–∏ –∏ –±–∞–ª–∞–Ω—Å–∞.\n",
      "\n",
      "### 2. –ü—Ä–∏–Ω—Ü–∏–ø—ã –ø—Ä–æ–ø–æ—Ä—Ü–∏–π\n",
      "- **–ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º –∏ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥–∞—Ä–º–æ–Ω–∏—á–Ω—ã—Ö –∫–æ–º–ø–æ–∑–∏—Ü–∏–π.\n",
      "- **–ü—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å**: –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∑–¥–∞–Ω–∏—è, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞–≤–∞—Ç—å —á—É–≤—Å—Ç–≤–æ –µ–¥–∏–Ω—Å—Ç–≤–∞ –∏ –±–∞–ª–∞–Ω—Å–∞.\n",
      "\n",
      "### 3. –£—á–∞—Å—Ç–∏–µ –ø—Ä–∏—Ä–æ–¥—ã\n",
      "- **–ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥–µ**: –ó–¥–∞–Ω–∏—è —á–∞—Å—Ç–æ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–ª–∏—Å—å —Å —É—á–µ—Ç–æ–º –º–µ—Å—Ç–Ω—ã—Ö –∫–ª–∏–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∏ –≥–µ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —É—Å–ª–æ–≤–∏–π.\n",
      "- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏—Ä–æ–¥–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤**: –ú–∞—Ç–µ—Ä–∏–∞–ª—ã, —Ç–∞–∫–∏–µ –∫–∞–∫ –∫–∞–º–µ–Ω—å, –¥–µ—Ä–µ–≤–æ, –±—ã–ª–∏ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–Ω–µ—à–Ω–µ–≥–æ –≤–∏–¥–∞.\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "–û–±–ª–∞–≥–∞—Ç—å —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏ —Å—É–º–º—ã –ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –¥–æ–ª–≥–∞ –ø–æ –∑–∞–π–º—É –æ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, –≥–¥–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–Ω—ã–π, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ–±—ã—á–Ω–æ–π –ø—Ä–∞–∫—Ç–∏–∫–æ–π. –í –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å—Ç—Ä–∞–Ω –∏ —Ä–µ–≥–∏–æ–Ω–æ–≤ —Å—Ç—Ä–∞—Ö–æ–≤—ã–µ –≤–∑–Ω–æ—Å—ã —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã –∑–∞—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–Ω–æ–≥–æ –∏ –Ω–µ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –µ–≥–æ –ª–∏—á–Ω—ã—Ö –¥–æ–ª–≥–æ–≤ –∏–ª–∏ –≤–∑–∞–∏–º–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–π —Å —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—è–º–∏.\n",
      "\n",
      "### –û–±—â–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã —Å—Ç—Ä–∞—Ö–æ–≤—ã—Ö –≤–∑–Ω–æ—Å–æ–≤:\n",
      "\n",
      "1. **–°—Ç—Ä–∞—Ö–æ–≤—ã–µ –≤–∑–Ω–æ—Å—ã** ‚Äì —ç—Ç–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –≤–∑–Ω–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª–∏ –≤–Ω–æ—Å—è—Ç –Ω–∞ —Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ —Å–≤–æ–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.\n",
      "2. **–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å** ‚Äì —Å—Ç—Ä–∞—Ö–æ–≤—ã–µ –≤–∑–Ω–æ—Å—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã –¥–ª—è —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏–ª–∏ –ø—Ä–µ–≤—ã—à–∞—é—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–æ—Ö–æ–¥–æ–≤.\n",
      "3. **–°—Ç—Ä–∞—Ö–æ–≤—ã–µ –≤–∑–Ω–æ—Å—ã** –Ω–µ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –ª–∏—á–Ω—ã—Ö —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –æ–±—Å—Ç–æ—è—Ç–µ–ª—å–∏–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤. –û–Ω–∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤, –∞ –Ω–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö –¥–æ–ª–≥–æ–≤ –∏–ª–∏ –ª–∏—á–Ω—ã—Ö —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π.\n",
      "\n",
      "### –í–æ–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å:\n",
      "\n",
      "- **–°–ª—É—á–∞–π, –∫–æ–≥–¥–∞ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å —è–≤–ª—è–µ—Ç—Å—è –∫—Ä–µ–¥–∏—Ç–æ—Ä–æ–º:** –ï—Å–ª–∏ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å —è–≤–ª—è–µ—Ç—Å—è –∫—Ä–µ–¥–∏—Ç–æ—Ä–æ–º –∏ –ø—Ä–æ—â–∞–µ—Ç –¥–æ–ª–≥ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫—É, –æ–Ω –º–æ–∂–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—é –æ—Ç —Å—Ç—Ä–∞—Ö–æ–≤–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞ —Å—Ç—Ä–∞—Ö–æ–≤—ã–µ –≤–∑–Ω–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –æ–Ω —É–∂–µ —É–ø–ª–∞—Ç–∏–ª –∑–∞ —ç—Ç–æ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –≤ —Ç–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏, –∫–æ–≥–¥–∞ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –±—ã–ª –µ–≥–æ –∫\n",
      "--------------------------------------------------\n",
      "<|end_header_id|>\n",
      "\n",
      "–ö—É—Ä—á–∞—Ç–æ–≤, –ò–≥–æ—Ä—å –í–∞—Å–∏–ª—å–µ–≤–∏—á ‚Äî —ç—Ç–æ –∏–º—è, –∫–æ—Ç–æ—Ä–æ–µ –∞—Å—Å–æ—Ü–∏–∏—Ä—É–µ—Ç—Å—è —Å –º–Ω–æ–≥–∏–º–∏ –≤–µ—â–∞–º–∏, –≤–∫–ª—é—á–∞—è —Ñ–∏–∑–∏–∫—É, –∞—Ç–æ–º–Ω—É—é —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫—É –∏ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ. –í–æ—Ç –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —ç—Ç–∏–º –∏–º–µ–Ω–µ–º:\n",
      "\n",
      "### –ë–∏–æ–≥—Ä–∞—Ñ–∏—è\n",
      "–ò–≥–æ—Ä—å –í–∞—Å–∏–ª—å–µ–≤–∏—á –ö—É—Ä—á–∞—Ç–æ–≤ —Ä–æ–¥–∏–ª—Å—è 12 —è–Ω–≤–∞—Ä—è 1902 –≥–æ–¥–∞ –≤ –¥–µ—Ä–µ–≤–Ω–µ –°–æ–ª–¥–∞—Ç—Å–∫–æ–µ, –≤ —Å–µ–º—å–µ —Å–ª—É–∂–∞—â–µ–≥–æ –∂–µ–ª–µ–∑–Ω–æ–¥–æ—Ä–æ–∂–Ω–æ–π —Å—Ç–∞–Ω—Ü–∏–∏. –£–º–µ—Ä 26 —Ñ–µ–≤—Ä–∞–ª—è 1960 –≥–æ–¥–∞ –≤ –ú–æ—Å–∫–≤–µ.\n",
      "\n",
      "### –ù–∞—É—á–Ω–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
      "–ö—É—Ä—á–∞—Ç–æ–≤ –±—ã–ª –≤—ã–¥–∞—é—â–∏–º—Å—è —Å–æ–≤–µ—Ç—Å–∫–∏–º —É—á–µ–Ω—ã–º-—Ç–µ–æ—Ä–µ—Ç–∏–∫–æ–º –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ç–æ—Ä–æ–º, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–ª –≤ –æ–±–ª–∞—Å—Ç–∏ —è–¥–µ—Ä–Ω–æ–π —Ñ–∏–∑–∏–∫–∏. –û–Ω –ø–æ–ª—É—á–∏–ª –∏–∑–≤–µ—Å—Ç–Ω–æ—Å—Ç—å –±–ª–∞–≥–æ–¥–∞—Ä—è —Å–≤–æ–∏–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º –≤ –æ–±–ª–∞—Å—Ç–∏ —è–¥–µ—Ä–Ω—ã—Ö —Ä–µ–∞–∫—Ü–∏–π –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∞—Ç–æ–º–Ω–æ–π –±–æ–º–±—ã. –ö—É—Ä—á–∞—Ç–æ–≤ –±—ã–ª –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º –ò–Ω—Å—Ç–∏—Ç—É—Ç–∞ –∞—Ç–æ–º–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–∏ (–Ω—ã–Ω–µ –ò–Ω—Å—Ç–∏—Ç—É—Ç –ö—É—Ä—á–∞—Ç–æ–≤–∞), –∫–æ—Ç–æ—Ä—ã–π –æ–Ω –æ—Å–Ω–æ–≤–∞–ª –≤ 1943 –≥–æ–¥—É.\n",
      "\n",
      "### –û—Å–Ω–æ–≤–Ω—ã–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è\n",
      "- **–Ø–¥–µ—Ä–Ω–∞—è —Ñ–∏–∑–∏–∫–∞**: –ö—É—Ä—á–∞—Ç–æ–≤ —Å–¥–µ–ª–∞–ª –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –≤–∫–ª–∞–¥ –≤ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —è–¥–µ—Ä–Ω—ã—Ö —Ä–µ–∞–∫—Ü–∏–π –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É —è–¥–µ—Ä–Ω–æ–≥–æ –æ—Ä—É–∂–∏—è. –û–Ω –ø—Ä–µ–¥–ª–æ–∂–∏–ª –ø—Ä–∏–Ω—Ü–∏–ø—ã –∏ –º–µ—Ç–æ–¥—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞—Ç–æ–º–Ω–æ–π –±–æ–º–±—ã.\n",
      "- **–ò–Ω—Å—Ç–∏—Ç—É—Ç –∞—Ç–æ–º–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–∏**: –ö—É—Ä—á–∞—Ç–æ–≤ –æ—Å–Ω–æ–≤–∞–ª –ò–Ω—Å—Ç–∏—Ç—É—Ç –∞—Ç–æ–º–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–∏, –∫–æ—Ç–æ—Ä—ã–π —Å—Ç–∞–ª –æ–¥–Ω–∏–º –∏–∑\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for text in prompts_for_test:\n",
    "    print(generate_answer(text))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf00683b-ed7d-4a5a-b964-e6139ed2f521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA before train] allocated=5.69GB, reserved=5.84GB, peak=7.08GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA before train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a988d7c8-ae50-4cc2-9067-a5ffd42da3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVML used=7.19GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5f92b01-c24d-4535-a0cd-fadf415a02cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# del tokenizer\n",
    "# del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ff541d1-ea0d-4154-9075-3a966ec0348f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44949"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11fe3896-3872-4e28-a469-47f4bcf3eafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA before train] allocated=0.12GB, reserved=5.84GB, peak=7.08GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA before train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f44d68ad-499d-49d9-8d8d-e09a8b384824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVML used=7.28GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da2ed3c3-24fb-4085-94fe-b8c6c83295f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "162a2c5c-3d63-4781-be4c-808c95a68c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA before train] allocated=0.12GB, reserved=0.16GB, peak=7.08GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA before train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7651a35-ce50-40ea-aa22-2ebc0f666daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVML used=1.58GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0377618-8833-4384-bf17-f26b5fb62406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVML used=1.57GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30e370e0-8269-4ee9-9abf-420560e2a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "INFO 09-09 18:16:51 [__init__.py:241] Automatically detected platform cuda.\n",
      "WARNING 09-09 18:16:51 [cuda.py:605] Detected different devices in the system: NVIDIA GeForce RTX 3090 Ti, NVIDIA GeForce RTX 3090. Please make sure to set `CUDA_DEVICE_ORDER=PCI_BUS_ID` to avoid unexpected behavior.\n",
      "2025-09-09:18:16:53 INFO     [__main__:446] Selected Tasks: ['truthfulqa_ru_mc1']\n",
      "2025-09-09:18:16:53 WARNING  [evaluator:172] pretrained=pretrained=llama-3.1-8B-instruct_lora_ru,dtype=float appears to be an instruct or chat variant but chat template is not applied.\n",
      "        Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).\n",
      "2025-09-09:18:16:53 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-09-09:18:16:53 INFO     [evaluator:240] Initializing hf model, with arguments: {'pretrained': 'llama-3.1-8B-instruct_lora_ru', 'dtype': 'float'}\n",
      "2025-09-09:18:16:53 INFO     [models.huggingface:147] Using device 'cuda:0'\n",
      "2025-09-09:18:16:53 INFO     [models.huggingface:414] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 2/4 [00:01<00:01,  1.72it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/viv232/anaconda3/envs/peft/bin/lm_eval\", line 7, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/llm-eng/12 PEFT/lm-evaluation-harness/lm_eval/__main__.py\", line 455, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/llm-eng/12 PEFT/lm-evaluation-harness/lm_eval/utils.py\", line 456, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/llm-eng/12 PEFT/lm-evaluation-harness/lm_eval/evaluator.py\", line 245, in simple_evaluate\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/llm-eng/12 PEFT/lm-evaluation-harness/lm_eval/api/model.py\", line 155, in create_from_arg_string\n",
      "    return cls(**args, **args2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/llm-eng/12 PEFT/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 210, in __init__\n",
      "    self._create_model(\n",
      "  File \"/home/viv232/llm-eng/12 PEFT/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 622, in _create_model\n",
      "    self._model = self.AUTO_MODEL_CLASS.from_pretrained(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py\", line 604, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 288, in _wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 5176, in from_pretrained\n",
      "    ) = cls._load_pretrained_model(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 5639, in _load_pretrained_model\n",
      "    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)\n",
      "                                                         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 946, in load_shard_file\n",
      "    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 815, in _load_state_dict_into_meta_model\n",
      "    param = param.to(casting_dtype)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 23.54 GiB of which 167.88 MiB is free. Process 7515 has 500.00 MiB memory in use. Including non-PyTorch memory, this process has 22.25 GiB memory in use. Of the allocated memory 21.80 GiB is allocated by PyTorch, and 161.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "!bash ./lm-evaluation-harness/run_lmesh_lora.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cced6b79-a881-4963-b416-487064b32aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.1: Fast Llama patching. Transformers: 4.56.1. vLLM: 0.10.1.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090 Ti. Num GPUs = 2. Max memory: 23.536 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"lora_model\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,    # QLoRA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cc2448b-95f3-4cbb-8c2a-59bcb7ef0e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging LoRA weights into 4bit model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging finished.\n",
      "Unsloth: Found skipped modules: ['lm_head']. Updating config.\n",
      "Unsloth: Saving merged 4bit model to llama-3.1-8B-instruct_lora_ru-4bit...\n",
      "Unsloth: Merged 4bit model saved.\n",
      "Unsloth: Merged 4bit model process completed.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(\"llama-3.1-8B-instruct_lora_ru-4bit\", tokenizer, save_method=\"merged_4bit_forced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d314208-e911-447f-ae7f-685e34f19a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "INFO 09-09 18:28:38 [__init__.py:241] Automatically detected platform cuda.\n",
      "WARNING 09-09 18:28:38 [cuda.py:605] Detected different devices in the system: NVIDIA GeForce RTX 3090 Ti, NVIDIA GeForce RTX 3090. Please make sure to set `CUDA_DEVICE_ORDER=PCI_BUS_ID` to avoid unexpected behavior.\n",
      "2025-09-09:18:28:40 INFO     [__main__:446] Selected Tasks: ['truthfulqa_ru_mc1']\n",
      "2025-09-09:18:28:40 WARNING  [evaluator:172] pretrained=pretrained=llama-3.1-8B-instruct_lora_ru-4bit,dtype=float appears to be an instruct or chat variant but chat template is not\n",
      "        applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).\n",
      "2025-09-09:18:28:40 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-09-09:18:28:40 INFO     [evaluator:240] Initializing hf model, with arguments: {'pretrained': 'llama-3.1-8B-instruct_lora_ru-4bit', 'dtype': 'float'}\n",
      "2025-09-09:18:28:40 INFO     [models.huggingface:147] Using device 'cuda:0'\n",
      "2025-09-09:18:28:40 INFO     [models.huggingface:414] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "/home/viv232/anaconda3/envs/peft/lib/python3.12/site-packages/transformers/quantizers/auto.py:239: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  3.12it/s]\n",
      "README.md: 3.45kB [00:00, 8.66MB/s]\n",
      "data/ru/val.jsonl: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.84M/2.84M [00:01<00:00, 1.71MB/s]\n",
      "Generating val split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 788/788 [00:00<00:00, 21785.72 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 788/788 [00:00<00:00, 25013.14 examples/s]\n",
      "2025-09-09:18:28:48 INFO     [api.task:434] Building contexts for truthfulqa_ru_mc1 on rank 0...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 788/788 [00:00<00:00, 204031.83it/s]\n",
      "2025-09-09:18:28:48 INFO     [evaluator:574] Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|                  | 0/3961 [00:00<?, ?it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Determined largest batch size: 19\n",
      "Running loglikelihood requests:  24%|‚ñà‚ñâ      | 952/3961 [01:50<03:06, 16.14it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  24%|‚ñà‚ñâ      | 970/3961 [02:02<03:05, 16.14it/s]Determined largest batch size: 22\n",
      "Running loglikelihood requests:  49%|‚ñà‚ñà‚ñà‚ñç   | 1944/3961 [03:21<01:52, 17.88it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  50%|‚ñà‚ñà‚ñà‚ñç   | 1965/3961 [03:32<01:51, 17.88it/s]Determined largest batch size: 22\n",
      "Running loglikelihood requests:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2935/3961 [04:50<00:56, 18.23it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2956/3961 [05:02<00:55, 18.23it/s]Determined largest batch size: 25\n",
      "Running loglikelihood requests:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3911/3961 [06:10<00:02, 19.59it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3935/3961 [06:22<00:01, 19.59it/s]Determined largest batch size: 28\n",
      "Running loglikelihood requests: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3961/3961 [06:38<00:00,  9.93it/s]\n",
      "fatal: –Ω–µ –Ω–∞–π–¥–µ–Ω git —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π (–∏–ª–∏ –æ–¥–∏–Ω –∏–∑ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏—Ö –∫–∞—Ç–∞–ª–æ–≥–æ–≤): .git\n",
      "2025-09-09:18:35:30 INFO     [loggers.evaluation_tracker:280] Output path not provided, skipping saving results aggregated\n",
      "hf (pretrained=llama-3.1-8B-instruct_lora_ru-4bit,dtype=float), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto:4 (19,22,22,25,28)\n",
      "|      Tasks      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
      "|-----------------|------:|------|-----:|------|---|-----:|---|-----:|\n",
      "|truthfulqa_ru_mc1|      1|none  |     0|acc   |‚Üë  |0.3261|¬±  |0.0167|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash ./lm-evaluation-harness/run_lmesh_lora.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a74cfc-a2fa-4c9a-8617-8314572915ac",
   "metadata": {},
   "source": [
    "## –ú–æ–¥–µ–ª—å YandexGPT-5-Lite-8B-instruct LoRA PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad27aa7f-ae2b-4804-88b8-8cf2bc14aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8335045-7154-4588-91e0-78abe3bc7adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['UNSLOTH_DISABLE'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48402818-de99-48c2-9bbb-ce5725dcf9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"yandex/YandexGPT-5-Lite-8B-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a1736cc-4219-4a83-945e-9209814ab2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è 4-–±–∏—Ç–Ω–æ–π –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è QLoRA\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f899d234-1873-445d-8859-844285e44657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    use_fast=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a5fa8de-525a-42df-aeb5-5739ee73db16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92f95eec-96ba-4643-ab14-c57ee026ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ae34ff7-b26c-4521-a3f3-463dbf56e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffd019d8-1eac-4eed-a21c-5a81afcecb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:50<00:00, 12.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    dtype=torch.float16,  # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö\n",
    "    trust_remote_code=True,\n",
    "    use_cache=False,  # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å False –ø—Ä–∏ gradient checkpointing\n",
    "    low_cpu_mem_usage=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41f51aaf-5bec-495d-b20d-3683cc7aa6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è k-bit –æ–±—É—á–µ–Ω–∏—è\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2238779c-a2c0-4f64-8826-8198d26bef58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA before train] allocated=2.81GB, reserved=4.11GB, peak=3.79GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA before train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be6d42f9-dedc-4343-9876-800eb09e79b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVML used=5.38GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c3e3798-b614-41a4-901c-0f51ef09c950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a6c4932-82b1-480a-9f2c-0c5e39730fba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0.self_attn.q_proj\n",
      "model.layers.0.self_attn.k_proj\n",
      "model.layers.0.self_attn.v_proj\n",
      "model.layers.0.self_attn.o_proj\n",
      "model.layers.0.mlp.gate_proj\n",
      "model.layers.0.mlp.up_proj\n",
      "model.layers.0.mlp.down_proj\n",
      "model.layers.1.self_attn.q_proj\n",
      "model.layers.1.self_attn.k_proj\n",
      "model.layers.1.self_attn.v_proj\n",
      "model.layers.1.self_attn.o_proj\n",
      "model.layers.1.mlp.gate_proj\n",
      "model.layers.1.mlp.up_proj\n",
      "model.layers.1.mlp.down_proj\n",
      "model.layers.2.self_attn.q_proj\n",
      "model.layers.2.self_attn.k_proj\n",
      "model.layers.2.self_attn.v_proj\n",
      "model.layers.2.self_attn.o_proj\n",
      "model.layers.2.mlp.gate_proj\n",
      "model.layers.2.mlp.up_proj\n",
      "model.layers.2.mlp.down_proj\n",
      "model.layers.3.self_attn.q_proj\n",
      "model.layers.3.self_attn.k_proj\n",
      "model.layers.3.self_attn.v_proj\n",
      "model.layers.3.self_attn.o_proj\n",
      "model.layers.3.mlp.gate_proj\n",
      "model.layers.3.mlp.up_proj\n",
      "model.layers.3.mlp.down_proj\n",
      "model.layers.4.self_attn.q_proj\n",
      "model.layers.4.self_attn.k_proj\n",
      "model.layers.4.self_attn.v_proj\n",
      "model.layers.4.self_attn.o_proj\n",
      "model.layers.4.mlp.gate_proj\n",
      "model.layers.4.mlp.up_proj\n",
      "model.layers.4.mlp.down_proj\n",
      "model.layers.5.self_attn.q_proj\n",
      "model.layers.5.self_attn.k_proj\n",
      "model.layers.5.self_attn.v_proj\n",
      "model.layers.5.self_attn.o_proj\n",
      "model.layers.5.mlp.gate_proj\n",
      "model.layers.5.mlp.up_proj\n",
      "model.layers.5.mlp.down_proj\n",
      "model.layers.6.self_attn.q_proj\n",
      "model.layers.6.self_attn.k_proj\n",
      "model.layers.6.self_attn.v_proj\n",
      "model.layers.6.self_attn.o_proj\n",
      "model.layers.6.mlp.gate_proj\n",
      "model.layers.6.mlp.up_proj\n",
      "model.layers.6.mlp.down_proj\n",
      "model.layers.7.self_attn.q_proj\n",
      "model.layers.7.self_attn.k_proj\n",
      "model.layers.7.self_attn.v_proj\n",
      "model.layers.7.self_attn.o_proj\n",
      "model.layers.7.mlp.gate_proj\n",
      "model.layers.7.mlp.up_proj\n",
      "model.layers.7.mlp.down_proj\n",
      "model.layers.8.self_attn.q_proj\n",
      "model.layers.8.self_attn.k_proj\n",
      "model.layers.8.self_attn.v_proj\n",
      "model.layers.8.self_attn.o_proj\n",
      "model.layers.8.mlp.gate_proj\n",
      "model.layers.8.mlp.up_proj\n",
      "model.layers.8.mlp.down_proj\n",
      "model.layers.9.self_attn.q_proj\n",
      "model.layers.9.self_attn.k_proj\n",
      "model.layers.9.self_attn.v_proj\n",
      "model.layers.9.self_attn.o_proj\n",
      "model.layers.9.mlp.gate_proj\n",
      "model.layers.9.mlp.up_proj\n",
      "model.layers.9.mlp.down_proj\n",
      "model.layers.10.self_attn.q_proj\n",
      "model.layers.10.self_attn.k_proj\n",
      "model.layers.10.self_attn.v_proj\n",
      "model.layers.10.self_attn.o_proj\n",
      "model.layers.10.mlp.gate_proj\n",
      "model.layers.10.mlp.up_proj\n",
      "model.layers.10.mlp.down_proj\n",
      "model.layers.11.self_attn.q_proj\n",
      "model.layers.11.self_attn.k_proj\n",
      "model.layers.11.self_attn.v_proj\n",
      "model.layers.11.self_attn.o_proj\n",
      "model.layers.11.mlp.gate_proj\n",
      "model.layers.11.mlp.up_proj\n",
      "model.layers.11.mlp.down_proj\n",
      "model.layers.12.self_attn.q_proj\n",
      "model.layers.12.self_attn.k_proj\n",
      "model.layers.12.self_attn.v_proj\n",
      "model.layers.12.self_attn.o_proj\n",
      "model.layers.12.mlp.gate_proj\n",
      "model.layers.12.mlp.up_proj\n",
      "model.layers.12.mlp.down_proj\n",
      "model.layers.13.self_attn.q_proj\n",
      "model.layers.13.self_attn.k_proj\n",
      "model.layers.13.self_attn.v_proj\n",
      "model.layers.13.self_attn.o_proj\n",
      "model.layers.13.mlp.gate_proj\n",
      "model.layers.13.mlp.up_proj\n",
      "model.layers.13.mlp.down_proj\n",
      "model.layers.14.self_attn.q_proj\n",
      "model.layers.14.self_attn.k_proj\n",
      "model.layers.14.self_attn.v_proj\n",
      "model.layers.14.self_attn.o_proj\n",
      "model.layers.14.mlp.gate_proj\n",
      "model.layers.14.mlp.up_proj\n",
      "model.layers.14.mlp.down_proj\n",
      "model.layers.15.self_attn.q_proj\n",
      "model.layers.15.self_attn.k_proj\n",
      "model.layers.15.self_attn.v_proj\n",
      "model.layers.15.self_attn.o_proj\n",
      "model.layers.15.mlp.gate_proj\n",
      "model.layers.15.mlp.up_proj\n",
      "model.layers.15.mlp.down_proj\n",
      "model.layers.16.self_attn.q_proj\n",
      "model.layers.16.self_attn.k_proj\n",
      "model.layers.16.self_attn.v_proj\n",
      "model.layers.16.self_attn.o_proj\n",
      "model.layers.16.mlp.gate_proj\n",
      "model.layers.16.mlp.up_proj\n",
      "model.layers.16.mlp.down_proj\n",
      "model.layers.17.self_attn.q_proj\n",
      "model.layers.17.self_attn.k_proj\n",
      "model.layers.17.self_attn.v_proj\n",
      "model.layers.17.self_attn.o_proj\n",
      "model.layers.17.mlp.gate_proj\n",
      "model.layers.17.mlp.up_proj\n",
      "model.layers.17.mlp.down_proj\n",
      "model.layers.18.self_attn.q_proj\n",
      "model.layers.18.self_attn.k_proj\n",
      "model.layers.18.self_attn.v_proj\n",
      "model.layers.18.self_attn.o_proj\n",
      "model.layers.18.mlp.gate_proj\n",
      "model.layers.18.mlp.up_proj\n",
      "model.layers.18.mlp.down_proj\n",
      "model.layers.19.self_attn.q_proj\n",
      "model.layers.19.self_attn.k_proj\n",
      "model.layers.19.self_attn.v_proj\n",
      "model.layers.19.self_attn.o_proj\n",
      "model.layers.19.mlp.gate_proj\n",
      "model.layers.19.mlp.up_proj\n",
      "model.layers.19.mlp.down_proj\n",
      "model.layers.20.self_attn.q_proj\n",
      "model.layers.20.self_attn.k_proj\n",
      "model.layers.20.self_attn.v_proj\n",
      "model.layers.20.self_attn.o_proj\n",
      "model.layers.20.mlp.gate_proj\n",
      "model.layers.20.mlp.up_proj\n",
      "model.layers.20.mlp.down_proj\n",
      "model.layers.21.self_attn.q_proj\n",
      "model.layers.21.self_attn.k_proj\n",
      "model.layers.21.self_attn.v_proj\n",
      "model.layers.21.self_attn.o_proj\n",
      "model.layers.21.mlp.gate_proj\n",
      "model.layers.21.mlp.up_proj\n",
      "model.layers.21.mlp.down_proj\n",
      "model.layers.22.self_attn.q_proj\n",
      "model.layers.22.self_attn.k_proj\n",
      "model.layers.22.self_attn.v_proj\n",
      "model.layers.22.self_attn.o_proj\n",
      "model.layers.22.mlp.gate_proj\n",
      "model.layers.22.mlp.up_proj\n",
      "model.layers.22.mlp.down_proj\n",
      "model.layers.23.self_attn.q_proj\n",
      "model.layers.23.self_attn.k_proj\n",
      "model.layers.23.self_attn.v_proj\n",
      "model.layers.23.self_attn.o_proj\n",
      "model.layers.23.mlp.gate_proj\n",
      "model.layers.23.mlp.up_proj\n",
      "model.layers.23.mlp.down_proj\n",
      "model.layers.24.self_attn.q_proj\n",
      "model.layers.24.self_attn.k_proj\n",
      "model.layers.24.self_attn.v_proj\n",
      "model.layers.24.self_attn.o_proj\n",
      "model.layers.24.mlp.gate_proj\n",
      "model.layers.24.mlp.up_proj\n",
      "model.layers.24.mlp.down_proj\n",
      "model.layers.25.self_attn.q_proj\n",
      "model.layers.25.self_attn.k_proj\n",
      "model.layers.25.self_attn.v_proj\n",
      "model.layers.25.self_attn.o_proj\n",
      "model.layers.25.mlp.gate_proj\n",
      "model.layers.25.mlp.up_proj\n",
      "model.layers.25.mlp.down_proj\n",
      "model.layers.26.self_attn.q_proj\n",
      "model.layers.26.self_attn.k_proj\n",
      "model.layers.26.self_attn.v_proj\n",
      "model.layers.26.self_attn.o_proj\n",
      "model.layers.26.mlp.gate_proj\n",
      "model.layers.26.mlp.up_proj\n",
      "model.layers.26.mlp.down_proj\n",
      "model.layers.27.self_attn.q_proj\n",
      "model.layers.27.self_attn.k_proj\n",
      "model.layers.27.self_attn.v_proj\n",
      "model.layers.27.self_attn.o_proj\n",
      "model.layers.27.mlp.gate_proj\n",
      "model.layers.27.mlp.up_proj\n",
      "model.layers.27.mlp.down_proj\n",
      "model.layers.28.self_attn.q_proj\n",
      "model.layers.28.self_attn.k_proj\n",
      "model.layers.28.self_attn.v_proj\n",
      "model.layers.28.self_attn.o_proj\n",
      "model.layers.28.mlp.gate_proj\n",
      "model.layers.28.mlp.up_proj\n",
      "model.layers.28.mlp.down_proj\n",
      "model.layers.29.self_attn.q_proj\n",
      "model.layers.29.self_attn.k_proj\n",
      "model.layers.29.self_attn.v_proj\n",
      "model.layers.29.self_attn.o_proj\n",
      "model.layers.29.mlp.gate_proj\n",
      "model.layers.29.mlp.up_proj\n",
      "model.layers.29.mlp.down_proj\n",
      "model.layers.30.self_attn.q_proj\n",
      "model.layers.30.self_attn.k_proj\n",
      "model.layers.30.self_attn.v_proj\n",
      "model.layers.30.self_attn.o_proj\n",
      "model.layers.30.mlp.gate_proj\n",
      "model.layers.30.mlp.up_proj\n",
      "model.layers.30.mlp.down_proj\n",
      "model.layers.31.self_attn.q_proj\n",
      "model.layers.31.self_attn.k_proj\n",
      "model.layers.31.self_attn.v_proj\n",
      "model.layers.31.self_attn.o_proj\n",
      "model.layers.31.mlp.gate_proj\n",
      "model.layers.31.mlp.up_proj\n",
      "model.layers.31.mlp.down_proj\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if \"proj\" in name:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa44f7eb-93c8-4aac-a211-a23ffda0b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # –†–∞–Ω–≥\n",
    "    lora_alpha=16,  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13af1229-281c-4e09-8f2e-437248af34dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 41,943,040 || all params: 8,078,495,744 || trainable%: 0.5192\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ LoRA –∫ –º–æ–¥–µ–ª–∏\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbafa494-1a1e-4c05-993e-18d71f91175b",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e70aed06-3b42-48fc-9c52-30133d475301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae4251c2-b033-4cec-81c1-22309ed6134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vikhr_dataset = load_dataset(\"Vikhrmodels/GrandMaster-PRO-MAX\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21da9545-8296-431d-ade5-dd487c5f3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(vikhr_dataset) > 10000:\n",
    "    vikhr_dataset = vikhr_dataset.select(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "640af3c9-97f0-4e02-8fb0-629058a50c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vikhr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46028e73-3fa8-435e-9121-cf20075e2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_russian(example):\n",
    "    return example['prompt_lang'] == 'ru' and example['answer_lang'] == 'ru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42bccd2b-c8f5-4377-929b-96917849877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vikhr_dataset = vikhr_dataset.filter(filter_russian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6b8c9d7-022d-4c66-838f-e419144b2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(vikhr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce501657-d6c2-40d7-a3a5-78dfab97fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "\n",
    "    conversation = example[\"conversation\"]\n",
    "    \n",
    "    # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º —á–∞—Ç-—à–∞–±–ª–æ–Ω–∞\n",
    "    # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —á–∞—Ç-—à–∞–±–ª–æ–Ω–∞\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        conversation,\n",
    "        tokenize=False,  # –ù–µ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º, –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "        padding=False,  # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º –ø–∞–¥–¥–∏–Ω–≥ –∑–¥–µ—Å—å\n",
    "    )\n",
    "    \n",
    "    # –¢–µ–ø–µ—Ä—å —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –æ–±—ã—á–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º\n",
    "    tokenized = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    # print(f'input_ids: {tokenized[\"input_ids\"][:10]}...')  # –ü–µ—Ä–≤—ã–µ 10 —Ç–æ–∫–µ–Ω–æ–≤\n",
    "    # print(f'attention_mask: {tokenized[\"attention_mask\"][:10]}...')\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": tokenized[\"input_ids\"],\n",
    "        \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "        \"labels\": tokenized[\"input_ids\"].copy()  # –ö–æ–ø–∏—Ä—É–µ–º –¥–ª—è labels\n",
    "    }\n",
    "    \n",
    "    # # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º —á–∞—Ç-—à–∞–±–ª–æ–Ω–∞\n",
    "    # tokenized = tokenizer.apply_chat_template(\n",
    "    #     example[\"conversation\"],\n",
    "    #     # tokenize=True,\n",
    "    #     truncation=True,\n",
    "    #     max_length=1024,\n",
    "    #     padding=\"max_length\",  # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–¥–¥–∏–Ω–≥ –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã\n",
    "    #     return_tensors=None\n",
    "    # )\n",
    "\n",
    "    # # –°–æ–∑–¥–∞–µ–º attention_mask\n",
    "    # # attention_masks = []\n",
    "    # # mask = [token_id != tokenizer.pad_token_id for token_id in input_ids]\n",
    "    # # attention_masks.append(mask)\n",
    "\n",
    "    # print(tokenized)\n",
    "    # print(f'input_ids: {tokenized[\"input_ids\"]}')\n",
    "    # print(f'attention_mask: {tokenized[\"attention_mask\"]}')\n",
    "    \n",
    "    # return {\n",
    "    #     \"input_ids\": tokenized[\"input_ids\"],\n",
    "    #     \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "    #     \"labels\": tokenized[\"input_ids\"].copy()  # –ö–æ–ø–∏—Ä—É–µ–º –¥–ª—è labels\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75316b10-a8aa-453a-9145-7a60d8626102",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_prep = dataset.select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b40d5204-5620-49aa-a867-98cf74b381fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 323.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "check_data = check_data_prep.map(formatting_func,\n",
    "                                 batched=False,\n",
    "                                 # batch_size=1000,\n",
    "                                 remove_columns=check_data_prep.column_names  # –£–¥–∞–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c291a78-5a83-4ecb-a85c-de9517e7d4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b17570a-4dfa-4355-9fbb-65fda833037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9906/9906 [00:04<00:00, 2268.72 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    formatting_func,\n",
    "    batched=False,\n",
    "    remove_columns=dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d662a07-e8b0-47bf-8e50-98cd1170b448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: [1, 1, 16861, 125851, 1759, 1403, 52612, 26900, 2019, 5386]\n",
      "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Length: 1024\n"
     ]
    }
   ],
   "source": [
    "print(\"Input IDs:\", tokenized_dataset[0][\"input_ids\"][:10])\n",
    "print(\"Attention mask:\", tokenized_dataset[0][\"attention_mask\"][:10])\n",
    "print(\"Length:\", len(tokenized_dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "347e78fd-5955-4d99-8185-7db52016b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_for_test = [\n",
    "    '–ö–∞–∫ –≤–∫—É—Å–Ω–æ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –∏–Ω–¥–µ–π–∫—É –Ω–∞ –≥—Ä–∏–ª–µ?',\n",
    "    '–ö–∞–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ø—Ä–∏–±–ª–∏–∂–∞—é—â–∏–π—Å—è –∏–Ω—Å—É–ª—å—Ç?',\n",
    "    '–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–∞–Ω–æ–Ω—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥—Ä–µ–≤–Ω–∏—Ö —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–π',\n",
    "    '–û–±–ª–∞–≥–∞—Ç—å –ª–∏ —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏ —Å—É–º–º—ã –ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –¥–æ–ª–≥–∞ –ø–æ –∑–∞–π–º—É –æ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –≥–¥–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–Ω—ã–π?',\n",
    "    '–†–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ –ø—Ä–æ –ö—É—Ä—á–∞—Ç–æ–≤–∞'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec33f9d4-8890-4011-9a00-b292d170bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(prompt):\n",
    "    dialog = tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": prompt}], \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    inputs = tokenizer(dialog, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=300,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞\n",
    "    if \"assistant\" in response:\n",
    "        return response.split(\"assistant\")[-1].strip()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca8e8770-8aec-4675-9e60-c23770e3339d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –ö–∞–∫ –≤–∫—É—Å–Ω–æ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –∏–Ω–¥–µ–π–∫—É –Ω–∞ –≥—Ä–∏–ª–µ?\n",
      "\n",
      " –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –ß—Ç–æ–±—ã –≤–∫—É—Å–Ω–æ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –∏–Ω–¥–µ–π–∫—É –Ω–∞ –≥—Ä–∏–ª–µ, –º–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Å–ª–µ–¥—É—é—â–∏–º —Ä–µ—Ü–µ–ø—Ç–æ–º:\n",
      "\n",
      "**–ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã:**\n",
      "* –∏–Ω–¥–µ–π–∫–∞ (–ª—é–±—ã–µ —á–∞—Å—Ç–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, –∫—Ä—ã–ª—å—è, –≥—Ä—É–¥–∫–∞ –∏–ª–∏ –Ω–æ–∂–∫–∏) ‚Äî 1 –∫–≥;\n",
      "* –æ–ª–∏–≤–∫–æ–≤–æ–µ –º–∞—Å–ª–æ ‚Äî 2 —Å—Ç. –ª.;\n",
      "* —á–µ—Å–Ω–æ–∫ ‚Äî 3‚Äì4 –∑—É–±—á–∏–∫–∞;\n",
      "* —Å–≤–µ–∂–∏–π —Ä–æ–∑–º–∞—Ä–∏–Ω ‚Äî 1 –≤–µ—Ç–æ—á–∫–∞;\n",
      "* —Å–≤–µ–∂–∏–π —Ç–∏–º—å—è–Ω ‚Äî 1 –≤–µ—Ç–æ—á–∫–∞;\n",
      "* —Å–≤–µ–∂–∏–π –æ—Ä–µ–≥–∞–Ω–æ (–∏–ª–∏ –¥—Ä—É–≥–∏–µ —Ç—Ä–∞–≤—ã –ø–æ –≤–∫—É—Å—É) ‚Äî 1 –≤–µ—Ç–æ—á–∫–∞;\n",
      "* —Å–æ–ª—å ‚Äî –ø–æ –≤–∫—É—Å—É;\n",
      "* —á—ë—Ä–Ω—ã–π –ø–µ—Ä–µ—Ü (–º–æ–ª–æ—Ç—ã–π) ‚Äî –ø–æ –≤–∫—É—Å—É;\n",
      "* –ª–∏–º–æ–Ω–Ω—ã–π —Å–æ–∫ ‚Äî 2 —Å—Ç. –ª. (–ø–æ –∂–µ–ª–∞–Ω–∏—é).\n",
      "\n",
      "**–ü—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏–µ:**\n",
      "1. –†–∞–∑–æ–≥—Ä–µ–π—Ç–µ –≥—Ä–∏–ª—å –¥–æ —Å—Ä–µ–¥–Ω–µ–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã.\n",
      "2. –°–º–µ—à–∞–π—Ç–µ –æ–ª–∏–≤–∫–æ–≤–æ–µ –º–∞—Å–ª–æ, –∏–∑–º–µ–ª—å—á—ë–Ω–Ω—ã–π —á–µ—Å–Ω–æ–∫, —Ç—Ä–∞–≤—ã, —Å–æ–ª—å –∏ –ø–µ—Ä–µ—Ü –≤ –º–∏—Å–∫–µ.\n",
      "3. –ù–∞—Ç—Ä–∏—Ç–µ —ç—Ç–æ–π —Å–º–µ—Å—å—é –∫—É—Å–æ—á–∫–∏ –∏–Ω–¥–µ–π–∫–∏ —Å–æ –≤—Å–µ—Ö —Å—Ç–æ—Ä–æ–Ω.\n",
      "4. –û—Å—Ç–∞–≤—å—Ç–µ –º–∞—Ä–∏–Ω–æ–≤–∞—Ç—å—Å—è –Ω–∞ 30‚Äì60 –º–∏–Ω—É—Ç (–∏–ª–∏ –Ω–∞ –Ω–æ—á—å, –µ—Å–ª–∏ –µ—Å—Ç—å –≤—Ä–µ–º—è).\n",
      "5. –í—ã–ª–æ–∂–∏—Ç–µ –∏–Ω–¥–µ–π–∫—É –Ω–∞ –≥—Ä–∏–ª—å –∏ –∂–∞—Ä—å—Ç–µ, –ø–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞—è, –¥–æ –∑–æ–ª–æ—Ç–∏—Å—Ç–æ–π –∫–æ—Ä–æ—á–∫–∏ –∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏.\n",
      "6. –í—Ä–µ–º—è –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –∏ —Ç–æ–ª—â–∏–Ω—ã –∫—É—Å–æ—á–∫–æ–≤ –∏–Ω–¥–µ–π–∫–∏. –û–±—ã—á–Ω–æ —ç—Ç–æ –∑–∞–Ω–∏–º–∞–µ—Ç –æ—Ç 8 –¥–æ 15 –º–∏–Ω—É—Ç —Å –∫–∞–∂–¥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã.\n",
      "7. –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –ø—Ä–æ—Ç–∫–Ω—É–≤ –º—è—Å–æ –≤–∏–ª–∫–æ–π –∏–ª–∏ –Ω–æ–∂–æ–º ‚Äî –≤—ã—Ç–µ–∫–∞—é—â–∏–π —Å–æ–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º.\n",
      "8. –ü–æ–¥–∞–≤–∞–π—Ç–µ –∏–Ω–¥–µ–π–∫—É —Å –ª—é–±–∏–º—ã–º–∏ –≥–∞—Ä–Ω–∏—Ä–∞–º–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å –æ–≤–æ—â–∞–º–∏-\n",
      "--------------------------------------------------\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –ö–∞–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ø—Ä–∏–±–ª–∏–∂–∞—é—â–∏–π—Å—è –∏–Ω—Å—É–ª—å—Ç?\n",
      "\n",
      " –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –ü—Ä–∏ –ø–æ–¥–æ–∑—Ä–µ–Ω–∏–∏ –Ω–∞ –∏–Ω—Å—É–ª—å—Ç –≤–∞–∂–Ω–æ –∫–∞–∫ –º–æ–∂–Ω–æ —Å–∫–æ—Ä–µ–µ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∑–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –ø–æ–º–æ—â—å—é. **–†–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ø—Ä–∏–±–ª–∏–∂–∞—é—â–∏–π—Å—è –∏–Ω—Å—É–ª—å—Ç –º–æ–∂–Ω–æ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º —Å–∏–º–ø—Ç–æ–º–∞–º:**\n",
      "\n",
      "1. **–°–ª–∞–±–æ—Å—Ç—å –∏–ª–∏ –æ–Ω–µ–º–µ–Ω–∏–µ –≤ –ª–∏—Ü–µ, —Ä—É–∫–µ –∏–ª–∏ –Ω–æ–≥–µ —Å –æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã.** –≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–æ—è–≤–ª—è—Ç—å—Å—è –≤ –≤–∏–¥–µ –≤–Ω–µ–∑–∞–ø–Ω–æ–π —Å–ª–∞–±–æ—Å—Ç–∏ –≤ –æ–¥–Ω–æ–π –ø–æ–ª–æ–≤–∏–Ω–µ —Ç–µ–ª–∞, –æ–Ω–µ–º–µ–Ω–∏—è –∏–ª–∏ –ø–æ—Ç–µ—Ä–∏ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
      "\n",
      "2. **–ü—Ä–æ–±–ª–µ–º—ã —Å —Ä–µ—á—å—é.** –ß–µ–ª–æ–≤–µ–∫ –º–æ–∂–µ—Ç –∏—Å–ø—ã—Ç—ã–≤–∞—Ç—å —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º —Ä–µ—á–∏, –≥–æ–≤–æ—Ä–∏—Ç—å –Ω–µ–≤–Ω—è—Ç–Ω–æ –∏–ª–∏ –Ω–µ –º–æ–∂–µ—Ç –≤—ã—Ä–∞–∑–∏—Ç—å —Å–≤–æ–∏ –º—ã—Å–ª–∏.\n",
      "\n",
      "3. **–ù–∞—Ä—É—à–µ–Ω–∏–µ –∑—Ä–µ–Ω–∏—è.** –ú–æ–∂–µ—Ç –ø–æ—è–≤–∏—Ç—å—Å—è –≤–Ω–µ–∑–∞–ø–Ω–æ–µ —É—Ö—É–¥—à–µ–Ω–∏–µ –∑—Ä–µ–Ω–∏—è, –¥–≤–æ–µ–Ω–∏–µ –≤ –≥–ª–∞–∑–∞—Ö, –ø–æ—Ç–µ—Ä—è –∑—Ä–µ–Ω–∏—è –≤ –æ–¥–Ω–æ–º –∏–ª–∏ –æ–±–æ–∏—Ö –≥–ª–∞–∑–∞—Ö.\n",
      "\n",
      "4. **–ì–æ–ª–æ–≤–Ω–∞—è –±–æ–ª—å.** –í–Ω–µ–∑–∞–ø–Ω–∞—è –∏ —Å–∏–ª—å–Ω–∞—è –≥–æ–ª–æ–≤–Ω–∞—è –±–æ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–ø–∏—Å–∞–Ω–∞ –∫–∞–∫ ¬´—Å–∞–º–∞—è —Å–∏–ª—å–Ω–∞—è –≤ –∂–∏–∑–Ω–∏¬ª, –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–º –∏–Ω—Å—É–ª—å—Ç–∞.\n",
      "\n",
      "5. **–ü—Ä–æ–±–ª–µ–º—ã —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–µ–π –∏ —Ä–∞–≤–Ω–æ–≤–µ—Å–∏–µ–º.** –ß–µ–ª–æ–≤–µ–∫ –º–æ–∂–µ—Ç —á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å –≥–æ–ª–æ–≤–æ–∫—Ä—É–∂–µ–Ω–∏–µ, —à–∞—Ç–∞—Ç—å—Å—è –ø—Ä–∏ —Ö–æ–¥—å–±–µ, —Ç–µ—Ä—è—Ç—å —Ä–∞–≤–Ω–æ–≤–µ—Å–∏–µ.\n",
      "\n",
      "6. **–û–Ω–µ–º–µ–Ω–∏–µ –∏–ª–∏ –ø–æ–∫–∞–ª—ã–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω–µ—á–Ω–æ—Å—Ç—è—Ö.** –û–Ω–µ–º–µ–Ω–∏–µ –∏–ª–∏ –ø–æ–∫–∞–ª—ã–≤–∞–Ω–∏–µ –≤ —Ä—É–∫–∞—Ö, –Ω–æ–≥–∞—Ö –∏–ª–∏ –ª–∏—Ü–µ, –æ—Å–æ–±–µ–Ω–Ω–æ —Å –æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã —Ç–µ–ª–∞.\n",
      "\n",
      "7. **–°–ø—É—Ç–∞–Ω–Ω–æ—Å—Ç—å —Å–æ–∑–Ω–∞–Ω–∏—è.** –ß–µ–ª–æ–≤–µ–∫ –º–æ–∂–µ—Ç –∏—Å–ø—ã—Ç—ã–≤–∞—Ç—å –¥–µ–∑–æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é, –±—ã—Ç—å —Ä–∞—Å—Ç–µ—Ä—è–Ω–Ω—ã–º –∏–ª–∏ –Ω–µ –ø–æ–Ω–∏–º–∞—Ç—å, —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç.\n",
      "\n",
      "8. **–¢–æ—à–Ω–æ—Ç–∞ –∏ —Ä–≤–æ—Ç–∞.** –û–Ω–∏ –º–æ–≥—É—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω—ã —Å –≥–æ–ª–æ–≤–Ω–æ–π –±–æ–ª—å—é –∏–ª–∏ –≥–æ–ª–æ–≤–æ–∫—Ä—É–∂–µ–Ω–∏–µ–º.\n",
      "\n",
      "**–í–∞–∂–Ω–æ –ø–æ–º–Ω–∏—Ç—å, —á—Ç–æ –∏–Ω—Å—É–ª—å—Ç ‚Äî —ç—Ç–æ –Ω–µ–æ—Ç–ª–æ–∂–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, —Ç—Ä–µ–±—É—é—â–µ–µ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –ø–æ–º–æ—â–∏.** –ï—Å–ª–∏ –≤—ã –∑–∞–º–µ—Ç–∏–ª–∏ —É —Å–µ–±—è\n",
      "--------------------------------------------------\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–∞–Ω–æ–Ω—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥—Ä–µ–≤–Ω–∏—Ö —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–π\n",
      "\n",
      " –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –û—Å–Ω–æ–≤–Ω—ã–µ –∫–∞–Ω–æ–Ω—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥—Ä–µ–≤–Ω–∏—Ö —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–π –º–æ–≥—É—Ç —Ä–∞–∑–ª–∏—á–∞—Ç—å—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–≥–∏–æ–Ω–∞ –∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞. –í–æ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –æ–±—â–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –∏ –∫–∞–Ω–æ–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å:\n",
      "\n",
      "1. **–°–∏–º–º–µ—Ç—Ä–∏—è –∏ –≥–∞—Ä–º–æ–Ω–∏—è.** –ú–Ω–æ–≥–∏–µ –¥—Ä–µ–≤–Ω–∏–µ —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–∏, —Ç–∞–∫–∏–µ –∫–∞–∫ –î—Ä–µ–≤–Ω–∏–π –ï–≥–∏–ø–µ—Ç, –ì—Ä–µ—Ü–∏—è –∏ –†–∏–º, –ø—Ä–∏–¥–∞–≤–∞–ª–∏ –±–æ–ª—å—à–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–∏–º–º–µ—Ç—Ä–∏–∏ –∏ –≥–∞—Ä–º–æ–Ω–∏–∏ –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ. –ó–¥–∞–Ω–∏—è —Å—Ç—Ä–æ–∏–ª–∏—Å—å —Å —É—á—ë—Ç–æ–º —Å—Ç—Ä–æ–≥–∏—Ö –ø—Ä–æ–ø–æ—Ä—Ü–∏–π –∏ —Å–∏–º–º–µ—Ç—Ä–∏–∏, —á—Ç–æ —Å–æ–∑–¥–∞–≤–∞–ª–æ –æ—â—É—â–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞ –∏ –≥–∞—Ä–º–æ–Ω–∏–∏.\n",
      "\n",
      "2. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.** –í —Ä–∞–∑–Ω—ã—Ö —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏—è—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å —Ä–∞–∑–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–ª—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ –î—Ä–µ–≤–Ω–µ–º –ï–≥–∏–ø—Ç–µ –æ—Å–Ω–æ–≤–Ω—ã–º —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–º –º–∞—Ç–µ—Ä–∏–∞–ª–æ–º –±—ã–ª –∫–∞–º–µ–Ω—å, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –≤ –î—Ä–µ–≤–Ω–µ–π –ì—Ä–µ—Ü–∏–∏ —à–∏—Ä–æ–∫–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –º—Ä–∞–º–æ—Ä –∏ –∏–∑–≤–µ—Å—Ç–Ω—è–∫.\n",
      "\n",
      "3. **–†–µ–ª–∏–≥–∏–æ–∑–Ω–∞—è —Å–∏–º–≤–æ–ª–∏–∫–∞.** –ú–Ω–æ–≥–∏–µ –¥—Ä–µ–≤–Ω–∏–µ –∑–¥–∞–Ω–∏—è, —Ç–∞–∫–∏–µ –∫–∞–∫ —Ö—Ä–∞–º—ã –∏ –ø–∏—Ä–∞–º–∏–¥—ã, –±—ã–ª–∏ —Ç–µ—Å–Ω–æ —Å–≤—è–∑–∞–Ω—ã —Å —Ä–µ–ª–∏–≥–∏–æ–∑–Ω—ã–º–∏ –≤–µ—Ä–æ–≤–∞–Ω–∏—è–º–∏ –∏ –ø—Ä–∞–∫—Ç–∏–∫–∞–º–∏. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ñ–æ—Ä–º—ã –∏ –¥–µ—Ç–∞–ª–∏ —á–∞—Å—Ç–æ –∏–º–µ–ª–∏ —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.\n",
      "\n",
      "4. **–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å.** –î—Ä–µ–≤–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä—ã —É–¥–µ–ª—è–ª–∏ –±–æ–ª—å—à–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–∞–Ω–∏–π. –ó–¥–∞–Ω–∏—è —Å—Ç—Ä–æ–∏–ª–∏—Å—å —Å —É—á—ë—Ç–æ–º –∏—Ö –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è ‚Äî —Ö—Ä–∞–º—ã –¥–ª—è —Ä–µ–ª–∏–≥–∏–æ–∑–Ω—ã—Ö –æ–±—Ä—è–¥–æ–≤, –¥–≤–æ—Ä—Ü—ã –¥–ª—è –ø—Ä–∞–≤–∏—Ç–µ–ª–µ–π, –∂–∏–ª—ã–µ –¥–æ–º–∞ –¥–ª—è –æ–±—ã—á–Ω—ã—Ö –ª—é–¥–µ–π.\n",
      "\n",
      "5. **–ú–∞—Å—à—Ç–∞–± –∏ –º–æ–Ω—É–º–µ–Ω—Ç–∞–ª—å–Ω–æ—Å—Ç—å.** –ú–Ω–æ–≥–∏–µ –¥—Ä–µ–≤–Ω–∏–µ —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–∏ —Å—Ç—Ä–æ–∏–ª–∏ –º–æ–Ω—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Å–æ–æ—Ä—É–∂–µ–Ω–∏—è, —Ç–∞–∫–∏–µ –∫–∞–∫ –ø–∏—Ä–∞–º–∏–¥—ã, —Ö—Ä–∞–º—ã –∏ –¥–≤–æ—Ä—Ü—ã, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã–ª–∏ –≤–ø–µ—á–∞—Ç–ª—è—Ç—å —Å–≤–æ–µ–π –º–∞—Å—à—Ç–∞–±–Ω–æ—Å—Ç—å—é –∏ –≤–µ–ª–∏—á–∏–µ–º.\n",
      "\n",
      "6. **–°—Ç–∏–ª–∏–∑–∞—Ü–∏—è –∏ –æ—Ä–Ω–∞–º–µ–Ω—Ç–∏–∫–∞.** –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã, —Ç–∞–∫–∏–µ –∫–∞–∫ –∫–æ–ª–æ–Ω–Ω—ã, –∞—Ä–∫–∏ –∏ —Ñ—Ä–æ–Ω—Ç–æ–Ω—ã, —á–∞—Å—Ç–æ —É–∫—Ä–∞—à–∞–ª–∏—Å—å —Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –∏ –æ—Ä–Ω–∞–º–µ–Ω—Ç–∞–º–∏\n",
      "--------------------------------------------------\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –û–±–ª–∞–≥–∞—Ç—å –ª–∏ —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏ —Å—É–º–º—ã –ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –¥–æ–ª–≥–∞ –ø–æ –∑–∞–π–º—É –æ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –≥–¥–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–Ω—ã–π?\n",
      "\n",
      " –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –°–æ–≥–ª–∞—Å–Ω–æ –ù–∞–ª–æ–≥–æ–≤–æ–º—É –∫–æ–¥–µ–∫—Å—É –†–§, —Å—Ç—Ä–∞—Ö–æ–≤—ã–µ –≤–∑–Ω–æ—Å—ã –Ω–∞—á–∏—Å–ª—è—é—Ç—Å—è –Ω–∞ –≤—ã–ø–ª–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –≤ –ø–æ–ª—å–∑—É —Ä–∞–±–æ—Ç–Ω–∏–∫–∞ –≤ —Ä–∞–º–∫–∞—Ö —Ç—Ä—É–¥–æ–≤—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π. \n",
      "\n",
      "–í —Å–ª—É—á–∞–µ –ø—Ä–æ—â–µ–Ω–∏—è –¥–æ–ª–≥–∞ –ø–æ –∑–∞–π–º—É –º–µ–∂–¥—É –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–µ–π –∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–º –≤–æ–ø—Ä–æ—Å –æ –Ω–∞—á–∏—Å–ª–µ–Ω–∏–∏ —Å—Ç—Ä–∞—Ö–æ–≤—ã—Ö –≤–∑–Ω–æ—Å–æ–≤ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–æ–≥–æ, –∫–∞–∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∞ —ç—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏—è –∏ –µ—ë —Å—É—Ç—å. –ï—Å–ª–∏ –ø—Ä–æ—â–µ–Ω–∏–µ –¥–æ–ª–≥–∞ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –∫–∞–∫ –ø–æ–¥–∞—Ä–æ–∫ –∏–ª–∏ –∏–Ω–æ–π –¥–æ—Ö–æ–¥ —Ä–∞–±–æ—Ç–Ω–∏–∫–∞, —Ç–æ —Ç–∞–∫–∏–µ —Å—É–º–º—ã –º–æ–≥—É—Ç –æ–±–ª–∞–≥–∞—Ç—å—Å—è —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏.\n",
      "\n",
      "–ß—Ç–æ–±—ã —Ç–æ—á–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –æ–±–ª–∞–≥–∞—é—Ç—Å—è –ª–∏ —Å—Ç—Ä–∞—Ö–æ–≤—ã–µ –≤–∑–Ω–æ—Å—ã —Å—É–º–º—ã –ø—Ä–æ—â—ë–Ω–Ω–æ–≥–æ –¥–æ–ª–≥–∞, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É—á–∏—Ç—ã–≤–∞—Ç—å –Ω–æ—Ä–º—ã –ù–∞–ª–æ–≥–æ–≤–æ–≥–æ –∫–æ–¥–µ–∫—Å–∞ –†–§ –∏ —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É—é—â–∏—Ö –æ—Ä–≥–∞–Ω–æ–≤, –∞ —Ç–∞–∫–∂–µ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏–∑—É—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã, –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –∫–æ—Ç–æ—Ä—ã—Ö –±—ã–ª–∞ –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∞ –ø—Ä–æ—â–µ–Ω–∏–µ –¥–æ–ª–≥–∞.\n",
      "\n",
      "–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É –ø–æ –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–º—É —É—á—ë—Ç—É –∏ –Ω–∞–ª–æ–≥–æ–æ–±–ª–æ–∂–µ–Ω–∏—é –∏–ª–∏ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ä–≥–∞–Ω.\n",
      "--------------------------------------------------\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –†–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ –ø—Ä–æ –ö—É—Ä—á–∞—Ç–æ–≤–∞\n",
      "\n",
      " –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] **–ö—É—Ä—á–∞—Ç–æ–≤ –ò–≥–æ—Ä—å –í–∞—Å–∏–ª—å–µ–≤–∏—á** (1902‚Äì1960) ‚Äî —Å–æ–≤–µ—Ç—Å–∫–∏–π —Ñ–∏–∑–∏–∫, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä –∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Ä–∞–±–æ—Ç –ø–æ –∞—Ç–æ–º–Ω–æ–π –Ω–∞—É–∫–µ –∏ —Ç–µ—Ö–Ω–∏–∫–µ –≤ –°–°–°–†. –û—Å–Ω–æ–≤–∞—Ç–µ–ª—å –∏ –ø–µ—Ä–≤—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –ò–Ω—Å—Ç–∏—Ç—É—Ç–∞ –∞—Ç–æ–º–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–∏. –ê–∫–∞–¥–µ–º–∏–∫ –ê–ù –°–°–°–† (1943).\n",
      "\n",
      "–ò–≥–æ—Ä—å –ö—É—Ä—á–∞—Ç–æ–≤ —Ä–æ–¥–∏–ª—Å—è –≤ 1902 –≥–æ–¥—É –≤ –ø–æ—Å—ë–ª–∫–µ –°–∏–º—Å–∫–∏–π –∑–∞–≤–æ–¥ (–Ω—ã–Ω–µ –≥. –°–∏–º, –ß–µ–ª—è–±–∏–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å). –í 1923 –≥–æ–¥—É –æ–∫–æ–Ω—á–∏–ª —Ñ–∏–∑–∏–∫–æ-–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ—Ç–¥–µ–ª–µ–Ω–∏–µ —Ñ–∏–∑–∏–∫–æ-–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ñ–∞–∫—É–ª—å—Ç–µ—Ç–∞ –†–æ—Å—Ç–æ–≤—Å–∫–æ–≥–æ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞. –ó–∞—Ç–µ–º —É—á–∏–ª—Å—è –≤ –ü–µ—Ç—Ä–æ–≥—Ä–∞–¥—Å–∫–æ–º –ø–æ–ª–∏—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º –∏–Ω—Å—Ç–∏—Ç—É—Ç–µ (–Ω—ã–Ω–µ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥—Å–∫–∏–π –ø–æ–ª–∏—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ü–µ—Ç—Ä–∞ –í–µ–ª–∏–∫–æ–≥–æ).\n",
      "\n",
      "–ö—É—Ä—á–∞—Ç–æ–≤ –∏–∑–≤–µ—Å—Ç–µ–Ω —Å–≤–æ–∏–º–∏ —Ä–∞–±–æ—Ç–∞–º–∏ –≤ –æ–±–ª–∞—Å—Ç–∏ —è–¥–µ—Ä–Ω–æ–π —Ñ–∏–∑–∏–∫–∏ –∏ —Å–æ–∑–¥–∞–Ω–∏—è —è–¥–µ—Ä–Ω–æ–≥–æ –æ—Ä—É–∂–∏—è –≤ –°–°–°–†. –ü–æ–¥ –µ–≥–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º –±—ã–ª–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω—ã –∏ —Å–æ–∑–¥–∞–Ω—ã –ø–µ—Ä–≤—ã–µ —Å–æ–≤–µ—Ç—Å–∫–∏–µ –∞—Ç–æ–º–Ω–∞—è –∏ –≤–æ–¥–æ—Ä–æ–¥–Ω–∞—è –±–æ–º–±—ã. –¢–∞–∫–∂–µ –ö—É—Ä—á–∞—Ç–æ–≤ –≤–Ω—ë—Å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –≤–∫–ª–∞–¥ –≤ —Ä–∞–∑–≤–∏—Ç–∏–µ –º–∏—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∞—Ç–æ–º–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–∏, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, –≤ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–µ—Ä–≤–æ–π –≤ –ï–≤—Ä–∞–∑–∏–∏ –∞—Ç–æ–º–Ω–æ–π —ç–ª–µ–∫—Ç—Ä–æ—Å—Ç–∞–Ω—Ü–∏–∏ –≤ –û–±–Ω–∏–Ω—Å–∫–µ.\n",
      "\n",
      "–ó–∞ —Å–≤–æ–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –ö—É—Ä—á–∞—Ç–æ–≤ –±—ã–ª –Ω–∞–≥—Ä–∞–∂–¥—ë–Ω –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º –Ω–∞–≥—Ä–∞–¥ –∏ –∑–≤–∞–Ω–∏–π, –≤–∫–ª—é—á–∞—è –∑–≤–∞–Ω–∏–µ –ì–µ—Ä–æ—è –°–æ—Ü–∏–∞–ª–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –¢—Ä—É–¥–∞ –∏ –°—Ç–∞–ª–∏–Ω—Å–∫—É—é –ø—Ä–µ–º–∏—é.\n",
      "\n",
      "–ò–º—è –ö—É—Ä—á–∞—Ç–æ–≤–∞ –Ω–æ—Å–∏—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –Ω–∞—É—á–Ω—ã—Ö –∏ —É—á–µ–±–Ω—ã—Ö –∑–∞–≤–µ–¥–µ–Ω–∏–π, –≤ —Ç–æ–º —á–∏—Å–ª–µ –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —è–¥–µ—Ä–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ú–ò–§–ò –≤ –ú–æ—Å–∫–≤–µ.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for text in prompts_for_test:\n",
    "    print(generate_answer(text))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c53495-8e6c-4a4c-9484-df5348e92df4",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c96d7ef-6b18-4fd7-bb06-00809638f990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs type: <class 'int'>\n",
      "Attention mask type: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Input IDs type:\", type(tokenized_dataset[0][\"input_ids\"][0]))\n",
    "print(\"Attention mask type:\", type(tokenized_dataset[0][\"attention_mask\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ca6eeff-24ad-4405-b985-32055226c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # –ö–∞—Å—Ç–æ–º–Ω—ã–π data collator –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "# class CustomDataCollator(DataCollatorForLanguageModeling):\n",
    "#     def __call__(self, features):\n",
    "#         batch = super().__call__(features)\n",
    "        \n",
    "#         # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º attention_mask –≤ bool\n",
    "#         if 'attention_mask' in batch:\n",
    "#             batch['attention_mask'] = batch['attention_mask'].bool()\n",
    "        \n",
    "#         return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6093fd76-288c-4930-9fe5-ece8b6a1fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "eval_dataset = dataset_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83f5c4ac-4d38-410a-aa1a-f20bf0c473ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./yandexgpt-lora-finetuned\",\n",
    "    per_device_train_batch_size=1, #2,\n",
    "    per_device_eval_batch_size=1, #2,\n",
    "    gradient_accumulation_steps=8, #4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=1, #3,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",  # –û—Ü–µ–Ω–∫–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    optim=\"paged_adamw_8bit\",       # –í–∞–∂–Ω–æ –¥–ª—è QLoRA\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3212ed16-84c2-4175-96c3-7f52c476a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False), # CustomDataCollator(tokenizer, mlm=False), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1695151e-b299-45fb-b176-09f54be3c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º eager attention –≤–º–µ—Å—Ç–æ SDPA\n",
    "model.config._attn_implementation = \"eager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d05ce3c-c4b7-4d39-99eb-2c3165337b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=2.86GB, reserved=4.18GB, peak=3.79GB\n",
      "NVML used=5.29GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddf347b3-4480-454f-8e59-4ab5904ab868",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f684c50-f242-48c4-809c-a55dee6e169c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=2.86GB, reserved=4.15GB, peak=3.79GB\n",
      "NVML used=5.27GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9115d1f-00db-4f8a-8102-63767d287e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1115' max='1115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1115/1115 3:43:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.510600</td>\n",
       "      <td>1.981060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1115, training_loss=1.7642043417344713, metrics={'train_runtime': 13406.1206, 'train_samples_per_second': 0.665, 'train_steps_per_second': 0.083, 'total_flos': 4.135426241593344e+17, 'train_loss': 1.7642043417344713, 'epoch': 1.0})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "474c0231-09d7-41dc-b738-f9646bae6371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=2.87GB, reserved=4.32GB, peak=3.79GB\n",
      "NVML used=5.54GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6611ae3-5cfc-4ed4-88e1-7e340de90c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./yandexgpt-lora-finetuned/tokenizer_config.json',\n",
       " './yandexgpt-lora-finetuned/special_tokens_map.json',\n",
       " './yandexgpt-lora-finetuned/chat_template.jinja',\n",
       " './yandexgpt-lora-finetuned/tokenizer.model',\n",
       " './yandexgpt-lora-finetuned/added_tokens.json')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(\"./yandexgpt-lora-finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bab3f0-0b3f-4839-8637-f3e68340df04",
   "metadata": {},
   "source": [
    "### –û—Ü–µ–Ω–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "950a5b14-c2c9-40c2-8120-6d157d1be946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2024024-cfdd-4119-94b6-500609dee322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è 4-–±–∏—Ç–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ (—Ç–∞–∫–∞—è –∂–µ –∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50d58e25-453c-432d-9f73-f4fdf8c91f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —Å –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–µ–π\n",
    "model_name = \"yandex/YandexGPT-5-Lite-8B-instruct\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "656153aa-c59a-41a7-ba7e-5e0dd8076078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    use_fast=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ccf35b92-eb7f-40ed-9d90-3c1154229f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–¥–¥–∏–Ω–≥ —Ç–æ–∫–µ–Ω –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a63ac2f-3ecd-4e5d-8ca7-29e967e8f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞\n",
    "lora_adapter_path = \"./yandexgpt-lora-finetuned\"  # –ø—É—Ç—å –∫ –≤–∞—à–µ–º—É –∞–¥–∞–ø—Ç–µ—Ä—É\n",
    "model = PeftModel.from_pretrained(base_model, lora_adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d30aab0-62cb-40ae-8bb0-f9fc544589ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(129024, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=129024, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d13e2117-3b59-4c72-9b3a-adf2e131f8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –ö–∞–∫ –≤–∫—É—Å–Ω–æ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –∏–Ω–¥–µ–π–∫—É –Ω–∞ –≥—Ä–∏–ª–µ?\n",
      "\n",
      " –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –¢—ã –Ω–µ –º–æ–≥ –±—ã –ø–æ–¥–µ–ª–∏—Ç—å—Å—è —Ä–µ—Ü–µ–ø—Ç–æ–º –≤–∫—É—Å–Ω–æ–≥–æ –º–∞—Ä–∏–Ω–∞–¥–∞ –¥–ª—è –∏–Ω–¥–µ–π–∫–∏? –Ø —Ö–æ—á—É –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –µ—ë –Ω–∞ –≥—Ä–∏–ª–µ, –Ω–æ –Ω–µ –∑–Ω–∞—é, –∫–∞–∫–∏–µ —Å–ø–µ—Ü–∏–∏ –∏ –ø—Ä–∏–ø—Ä–∞–≤—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å.\n",
      "--------------------------------------------------\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –ö–∞–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ø—Ä–∏–±–ª–∏–∂–∞—é—â–∏–π—Å—è –∏–Ω—Å—É–ª—å—Ç?\n",
      "\n",
      " –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏\n",
      "--------------------------------------------------\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–∞–Ω–æ–Ω—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥—Ä–µ–≤–Ω–∏—Ö —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–π\n",
      "\n",
      " –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç\n",
      "--------------------------------------------------\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –û–±–ª–∞–≥–∞—Ç—å –ª–∏ —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏ —Å—É–º–º—ã –ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –¥–æ–ª–≥–∞ –ø–æ –∑–∞–π–º—É –æ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –≥–¥–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–Ω—ã–π?\n",
      "\n",
      " –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –°—É–º–º–∞ –ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –¥–æ–ª–≥–∞ –ø–æ –∑–∞–π–º—É –æ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, –≥–¥–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–Ω—ã–π, –Ω–µ –æ–±–ª–∞–≥–∞–µ—Ç—Å—è —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –¥–æ—Ö–æ–¥–æ–º –∑–∞—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–Ω–æ–≥–æ –ª–∏—Ü–∞.\n",
      "\n",
      "–ï—Å–ª–∏ —Å—É–º–º–∞ –ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –¥–æ–ª–≥–∞ —è–≤–ª—è–µ—Ç—Å—è –¥–æ—Ö–æ–¥–æ–º, —Ç–æ –æ–Ω–∞ –æ–±–ª–∞–≥–∞–µ—Ç—Å—è —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏ –≤ –æ–±—â–µ–º –ø–æ—Ä—è–¥–∫–µ.\n",
      "--------------------------------------------------\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –†–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ –ø—Ä–æ –ö—É—Ä—á–∞—Ç–æ–≤–∞\n",
      "\n",
      " –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: [SEP] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ò–≥–æ—Ä—å –í–∞—Å–∏–ª—å–µ–≤–∏—á –ö—É—Ä—á–∞—Ç–æ–≤ –±—ã–ª –≤—ã–¥–∞—é—â–∏–º—Å—è —Å–æ–≤–µ—Ç—Å–∫–∏–º —Ñ–∏–∑–∏–∫–æ–º, –∞–∫–∞–¥–µ–º–∏–∫–æ–º –ê–ù –°–°–°–†, –æ–¥–Ω–∏–º –∏–∑ –æ—Å–Ω–æ–≤–∞—Ç–µ–ª–µ–π –∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π –∞—Ç–æ–º–Ω–æ–π –Ω–∞—É–∫–∏ –≤ –°–°–°–†. –û–Ω —Ä–æ–¥–∏–ª—Å—è 12 —è–Ω–≤–∞—Ä—è 1902 –≥–æ–¥–∞ –∏ —É–º–µ—Ä 7 —Ñ–µ–≤—Ä–∞–ª—è 1960 –≥–æ–¥–∞.\n",
      "\n",
      "–ö—É—Ä—á–∞—Ç–æ–≤ –≤–Ω–µ—Å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –≤–∫–ª–∞–¥ –≤ —Ä–∞–∑–≤–∏—Ç–∏–µ —è–¥–µ—Ä–Ω–æ–π —Ñ–∏–∑–∏–∫–∏ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —è–¥–µ—Ä–Ω–æ–≥–æ –æ—Ä—É–∂–∏—è –≤ –°–°–°–†. –û–Ω —Ä—É–∫–æ–≤–æ–¥–∏–ª —Å–æ–∑–¥–∞–Ω–∏–µ–º –ø–µ—Ä–≤–æ–π —Å–æ–≤–µ—Ç—Å–∫–æ–π –∞—Ç–æ–º–Ω–æ–π –±–æ–º–±—ã –∏ –∞—Ç–æ–º–Ω–æ–π —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏. –ü–æ–¥ –µ–≥–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º –±—ã–ª–∏ –ø—Ä–æ–≤–µ–¥–µ–Ω—ã –≤–∞–∂–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ —Ñ–∏–∑–∏–∫–∏ –∞—Ç–æ–º–Ω–æ–≥–æ —è–¥—Ä–∞, –∞ —Ç–∞–∫–∂–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω—ã –º–µ—Ç–æ–¥—ã —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∏–∑–æ—Ç–æ–ø–æ–≤.\n",
      "\n",
      "–ö—É—Ä—á–∞—Ç–æ–≤ —Ç–∞–∫–∂–µ –∑–∞–Ω–∏–º–∞–ª—Å—è —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–º–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º–∏ –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–º–∏ —Å —è–¥–µ—Ä–Ω–æ–π —Ñ–∏–∑–∏–∫–æ–π, –∏ –±—ã–ª –æ–¥–Ω–∏–º –∏–∑ –ø–µ—Ä–≤—ã—Ö, –∫—Ç–æ –∏–∑—É—á–∞–ª —Å–≤–æ–π—Å—Ç–≤–∞ —è–¥–µ—Ä–Ω–æ–≥–æ –¥–µ–ª–µ–Ω–∏—è. –ï–≥–æ —Ä–∞–±–æ—Ç—ã –æ–∫–∞–∑–∞–ª–∏ –æ–≥—Ä–æ–º–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–∞–∑–≤–∏—Ç–∏–µ –∞—Ç–æ–º–Ω–æ–π –Ω–∞—É–∫–∏ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –≤ –°–°–°–† –∏ –≤–æ –≤—Å–µ–º –º–∏—Ä–µ.\n",
      "\n",
      "–í —á–µ—Å—Ç—å –ö—É—Ä—á–∞—Ç–æ–≤–∞ –Ω–∞–∑–≤–∞–Ω –≥–æ—Ä–æ–¥ –ö—É—Ä—á–∞—Ç–æ–≤ –≤ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–µ –∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–∞—É—á–Ω—ã—Ö —É—á—Ä–µ–∂–¥–µ–Ω–∏–π –∏ –æ–±—ä–µ–∫—Ç–æ–≤, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –∞—Ç–æ–º–Ω–æ–π –Ω–∞—É–∫–æ–π –∏ —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–æ–π.\n",
      "\n",
      " –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ò–≥–æ—Ä—å –í–∞—Å–∏–ª—å–µ–≤–∏—á –ö—É—Ä—á–∞—Ç–æ–≤ (1902‚Äì1960) ‚Äî –≤—ã–¥–∞—é—â–∏–π—Å—è —Å–æ–≤–µ—Ç—Å–∫–∏–π —Ñ–∏–∑–∏–∫, –∞–∫–∞–¥–µ–º–∏–∫ –ê–ù –°–°–°–†, –æ–¥–∏–Ω –∏–∑ –æ—Å–Ω–æ–≤–∞—Ç–µ–ª–µ–π –∞—Ç–æ–º–Ω–æ–π –Ω–∞—É–∫–∏ –≤ –°–°–°–†. –†–æ–¥–∏–ª—Å—è 12 —è–Ω–≤–∞—Ä—è 1902 –≥–æ–¥–∞, —É–º–µ—Ä 7 —Ñ–µ–≤—Ä–∞–ª—è 1960 –≥–æ–¥–∞.\n",
      "\n",
      "–í–Ω—ë—Å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –≤–∫–ª–∞–¥ –≤ —Ä–∞–∑–≤–∏—Ç–∏–µ —è–¥–µ—Ä–Ω–æ–π —Ñ–∏–∑–∏–∫–∏, —Ä—É–∫–æ–≤–æ–¥–∏–ª —Å–æ–∑–¥–∞–Ω–∏–µ–º –ø–µ—Ä–≤–æ–π —Å–æ–≤–µ—Ç—Å–∫–æ–π –∞—Ç–æ–º–Ω–æ–π –±–æ–º–±—ã –∏ –∞—Ç–æ–º–Ω–æ–π —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏. –ü–æ–¥ –µ–≥–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º –±—ã–ª–∏ –ø—Ä–æ–≤–µ–¥–µ–Ω—ã –≤–∞–∂–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ —Ñ–∏–∑–∏–∫–∏ –∞—Ç–æ–º–Ω–æ–≥–æ —è–¥—Ä–∞ –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω—ã –º–µ—Ç–æ–¥—ã —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∏–∑–æ—Ç–æ–ø–æ–≤\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for text in prompts_for_test:\n",
    "    print(generate_answer(text))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f72ccdea-ce67-45a0-8ddb-164f59139d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=6.38GB, reserved=8.95GB, peak=7.31GB\n",
      "NVML used=10.26GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf1d64-0916-4c50-ae82-51548a76b480",
   "metadata": {},
   "source": [
    "–ë—É–¥—É –±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω –µ—Å–ª–∏ –ø–æ–¥—Å–∫–∞–∂–µ—Ç–µ –≥–¥–µ —è –Ω–∞–∫–æ—Å—è—á–∏–ª —Å —à–∞–±–ª–æ–Ω–æ–º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda2450-466a-4988-a5bd-2448ef5aa85e",
   "metadata": {},
   "source": [
    ":("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60844011-2648-4e0b-8782-a7bf537b26ad",
   "metadata": {},
   "source": [
    "## –†–∞–±–æ—Ç–∞ –Ω–∞–¥ –æ—à–∏–±–∫–∞–º–∏ - –≤—Ç–æ—Ä–æ–π –∑–∞—Ö–æ–¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe8dca53-4ac6-41e8-b02b-d8abdfbaaaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    conversation = example[\"conversation\"]\n",
    "    \n",
    "    # –ü—Ä–∏–º–µ–Ω—è–µ–º —á–∞—Ç-—à–∞–±–ª–æ–Ω —Å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π\n",
    "    tokenized = tokenizer.apply_chat_template(\n",
    "        conversation,\n",
    "        tokenize=True,  # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Å—Ä–∞–∑—É!\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    # –î–ª—è causal LM –º–µ—Ç–∫–∏ —Ç–∞–∫–∏–µ –∂–µ –∫–∞–∫ input_ids\n",
    "    return {\n",
    "        \"input_ids\": tokenized,\n",
    "        \"attention_mask\": [1] * len(tokenized),  # –í—Å–µ —Ç–æ–∫–µ–Ω—ã –∑–Ω–∞—á–∏–º—ã–µ\n",
    "        \"labels\": tokenized.copy()  # –ö–æ–ø–∏—Ä—É–µ–º –¥–ª—è labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ee404-24b0-4755-bea1-7d681a7f43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_prep = dataset.select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cfa906c2-a766-4dbf-85de-08bcd80b2d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 821.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "check_data = check_data_prep.map(formatting_func,\n",
    "                                 batched=False,\n",
    "                                 # batch_size=1000,\n",
    "                                 remove_columns=check_data_prep.column_names  # –£–¥–∞–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c21d06f-75d5-437a-b254-d79785c0694e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: [1, 1, 16861, 125851, 1759, 1403, 52612, 26900, 2019, 5386]\n",
      "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Length: 1024\n"
     ]
    }
   ],
   "source": [
    "print(\"Input IDs:\", tokenized_dataset[0][\"input_ids\"][:10])\n",
    "print(\"Attention mask:\", tokenized_dataset[0][\"attention_mask\"][:10])\n",
    "print(\"Length:\", len(tokenized_dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f9b9728-e7db-4946-b374-e2546b049bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    conversation = example[\"conversation\"]\n",
    "    \n",
    "    # –ü—Ä–∏–º–µ–Ω—è–µ–º —á–∞—Ç-—à–∞–±–ª–æ–Ω –ë–ï–ó –æ–±—Ä–µ–∑–∫–∏\n",
    "    tokenized = tokenizer.apply_chat_template(\n",
    "        conversation,\n",
    "        tokenize=True,\n",
    "        truncation=False,  # –û—Ç–∫–ª—é—á–∞–µ–º –æ–±—Ä–µ–∑–∫—É!\n",
    "        max_length=None,   # –ë–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª–∏–Ω—ã\n",
    "        padding=False,     # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º –ø–∞–¥–¥–∏–Ω–≥ –∑–¥–µ—Å—å\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    # –¢–µ–ø–µ—Ä—å –¥–æ–±–∞–≤–ª—è–µ–º –ø–∞–¥–¥–∏–Ω–≥ –æ—Ç–¥–µ–ª—å–Ω–æ\n",
    "    if len(tokenized) < 1024:\n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–¥–¥–∏–Ω–≥\n",
    "        padded = tokenized + [tokenizer.pad_token_id] * (1024 - len(tokenized))\n",
    "        attention_mask = [1] * len(tokenized) + [0] * (1024 - len(tokenized))\n",
    "    else:\n",
    "        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã\n",
    "        padded = tokenized[:1024]\n",
    "        attention_mask = [1] * 1024\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": padded,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": padded.copy()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d78f6d62-3879-4403-8e1b-3bac6bbf281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func_final(example):\n",
    "    conversation = example[\"conversation\"]\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –¥–∏–∞–ª–æ–≥\n",
    "    full_dialog = \"<s>\"\n",
    "    for message in conversation:\n",
    "        if message[\"role\"] == \"user\":\n",
    "            full_dialog += f\" –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {message['content']}\"\n",
    "        elif message[\"role\"] == \"assistant\":\n",
    "            full_dialog += f\" –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: {message['content']}[SEP]\"\n",
    "    \n",
    "    # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º\n",
    "    tokenized = tokenizer(\n",
    "        full_dialog,\n",
    "        truncation=True,\n",
    "        max_length=2048,  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –ø–æ–ª–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": tokenized[\"input_ids\"],\n",
    "        \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "        \"labels\": tokenized[\"input_ids\"].copy()  # –î–ª—è simple causal LM\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1abc8a27-fd3f-4909-8758-0610a17f5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_training_data():\n",
    "    print(\"–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i in range(min(3, len(dataset))):\n",
    "        sample = dataset[i]\n",
    "        tokenized = formatting_func_final(sample)\n",
    "        decoded = tokenizer.decode(tokenized[\"input_ids\"])\n",
    "        \n",
    "        print(f\"\\n–ü—Ä–∏–º–µ—Ä {i+1}:\")\n",
    "        print(f\"–î–ª–∏–Ω–∞: {len([x for x in tokenized['input_ids'] if x != tokenizer.pad_token_id])} —Ç–æ–∫–µ–Ω–æ–≤\")\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã\n",
    "        has_user = \"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:\" in decoded\n",
    "        has_assistant = \"–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:\" in decoded\n",
    "        has_sep = \"[SEP]\" in decoded\n",
    "        has_content = any(word in decoded for word in [\"—Å—Ç—Ä–∞—Ç–µ\", \"–∏–≥—Ä\", \"–æ—Ç–≤–µ—Ç\"])\n",
    "        \n",
    "        print(f\"‚úì –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {has_user}\")\n",
    "        print(f\"‚úì –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: {has_assistant}\")\n",
    "        print(f\"‚úì [SEP]: {has_sep}\")\n",
    "        print(f\"‚úì –ö–æ–Ω—Ç–µ–Ω—Ç: {has_content}\")\n",
    "        print(decoded)\n",
    "        \n",
    "        if all([has_user, has_assistant, has_sep, has_content]):\n",
    "            print(\"‚úì –î–∞–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\")\n",
    "        else:\n",
    "            print(\"‚úó –ü—Ä–æ–±–ª–µ–º–∞ —Å –¥–∞–Ω–Ω—ã–º–∏\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4a41e259-4d6b-4dc9-993f-b9e378156635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:\n",
      "============================================================\n",
      "\n",
      "–ü—Ä–∏–º–µ—Ä 1:\n",
      "–î–ª–∏–Ω–∞: 569 —Ç–æ–∫–µ–Ω–æ–≤\n",
      "‚úì –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: True\n",
      "‚úì –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: True\n",
      "‚úì [SEP]: True\n",
      "‚úì –ö–æ–Ω—Ç–µ–Ω—Ç: True\n",
      "<s><s> –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –º–Ω–µ –æ—á–µ–Ω—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –∏–≥—Ä—ã, –∏ —è –Ω–µ–¥–∞–≤–Ω–æ —É–∑–Ω–∞–ª –ø—Ä–æ –∏–≥—Ä—É –Ω–∏–º. –Ω–µ –º–æ–≥ –±—ã —Ç—ã –æ–±—ä—è—Å–Ω–∏—Ç—å –º–Ω–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä—ã –≤ –Ω–∏–º? –∏ –µ—â–µ, –µ—Å–ª–∏ –µ—Å—Ç—å, –ø–æ–¥–µ–ª–∏—Å—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º –∏–≥—Ä—ã –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏ –∏–ª–∏ –¥—Ä—É–≥–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∏, –≤ –∫–æ—Ç–æ—Ä—ã–µ –º—ã –º–æ–≥–ª–∏ –±—ã —Å—ã–≥—Ä–∞—Ç—å –≤–º–µ—Å—Ç–µ. –∫–∞–∫ –Ω–∞—Å—á–µ—Ç —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å 15 puzzle? –º–Ω–µ –±—ã —Ö–æ—Ç–µ–ª–æ—Å—å —É–∑–Ω–∞—Ç—å, –µ—Å—Ç—å –ª–∏ –¥–ª—è –Ω–µ—ë –∫–∞–∫–∞—è-—Ç–æ –≤—ã–∏–≥—Ä—ã—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–ª–∏ –ø–æ–¥—Ö–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –ø–æ–±–µ–¥—É. –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –†–∞—Å—Å–∫–∞–∂—É —Ç–µ–±–µ –æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è—Ö –∏–≥—Ä—ã –≤ –ù–∏–º –∏ –∑–∞—Ç—Ä–æ–Ω—É —Ç–µ–º—É 15 Puzzle.\n",
      "\n",
      "### –°—Ç—Ä–∞—Ç–µ–≥–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä—ã –≤ –ù–∏–º\n",
      "\n",
      "–ò–≥—Ä–∞ –ù–∏–º ‚Äî —ç—Ç–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–≥—Ä–∞, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–π —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —á—ë—Ç–∫–∞—è –≤—ã–∏–≥—Ä—ã—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è. –û—Å–Ω–æ–≤–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ª–µ–∂–∏—Ç –≤ –ø–æ–Ω—è—Ç–∏–∏ –Ω–∏–º-—Å—É–º–º—ã ‚Äî —ç—Ç–æ –ø–æ–±–∏—Ç–æ–≤–æ–µ –∏—Å–∫–ª—é—á–∞—é—â–µ–µ –ò–õ–ò (XOR) —Ä–∞–∑–º–µ—Ä–æ–≤ –∫—É—á–µ–∫.\n",
      "\n",
      "–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Å–ª–µ–¥—É—é—â–µ–º:\n",
      "\n",
      "1. –í—ã—á–∏—Å–ª–∏ –Ω–∏–º-—Å—É–º–º—É –≤—Å–µ—Ö –∫—É—á–µ–∫.\n",
      "2. –ï—Å–ª–∏ –Ω–∏–º-—Å—É–º–º–∞ —Ä–∞–≤–Ω–∞ –Ω—É–ª—é, —Ç–æ –≤–∞—à–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–æ–∏–≥—Ä—ã—à–Ω–æ–µ –ø—Ä–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä–µ —Å–æ–ø–µ—Ä–Ω–∏–∫–∞. –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –ø—Ä–æ—Å—Ç–æ –¥–µ–ª–∞–π—Ç–µ —Ö–æ–¥ –∏ —Å—Ç–∞—Ä–∞–π—Ç–µ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–æ–ø–µ—Ä–Ω–∏–∫–∞.\n",
      "3. –ï—Å–ª–∏ –Ω–∏–º-—Å—É–º–º–∞ –Ω–µ —Ä–∞–≤–Ω–∞ –Ω—É–ª—é, –≤–∞–º –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Ö–æ–¥, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–Ω—å—à–∏—Ç —Ä–∞–∑–º–µ—Ä –æ–¥–Ω–æ–π –∏–∑ –∫—É—á–µ–∫ —Ç–∞–∫, —á—Ç–æ–±—ã –Ω–æ–≤–∞—è –Ω–∏–º-—Å—É–º–º–∞ –≤—Å–µ—Ö –∫—É—á–µ–∫ –±—ã–ª–∞ —Ä–∞–≤–Ω–∞ –Ω—É–ª—é.\n",
      "4. –ü–æ—Å–ª–µ –≤–∞—à–µ–≥–æ —Ö–æ–¥–∞ —Å–æ–ø–µ—Ä–Ω–∏–∫ –æ–∫–∞–∂–µ—Ç—Å—è –≤ –ø–æ–ª–æ–∂–µ–Ω–∏–∏ —Å –Ω–∏–º-—Å—É–º–º–æ–π —Ä–∞–≤–Ω–æ–π –Ω—É–ª—é, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ–∏–≥—Ä—ã—à–Ω—ã–º –ø–æ–ª–æ–∂–µ–Ω–∏–µ–º –ø—Ä–∏ –≤–∞—à–µ–π –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–≥—Ä–µ.\n",
      "\n",
      "### –ò–≥—Ä–∞–µ–º –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏\n",
      "\n",
      "–ß—Ç–æ –∫–∞—Å–∞–µ—Ç—Å—è –∫—Ä–µ—Å—Ç–∏–∫–æ–≤-–Ω–æ–ª–∏–∫–æ–≤, –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏–≥—Ä—É –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º –ø–æ–ª–µ 5x5 –∏–ª–∏ 10x10, –≥–¥–µ –¥–ª—è –ø–æ–±–µ–¥—ã –Ω—É–∂–Ω–æ –≤—ã—Å—Ç—Ä–æ–∏—Ç—å —Ä—è–¥ –∏–∑ 5 —Å–∏–º–≤–æ–ª–æ–≤. –≠—Ç–æ –¥–æ–±–∞–≤–∏—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–π –≥–ª—É–±–∏–Ω—ã.\n",
      "\n",
      "### 15 Puzzle (–ü—è—Ç–Ω–∞—à–∫–∏)\n",
      "\n",
      "15 Puzzle ‚Äî —ç—Ç–æ –≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∞ —Å –ø–ª–∏—Ç–∫–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —É–ø–æ—Ä—è–¥–æ—á–∏—Ç—å –ø–æ –ø–æ—Ä—è–¥–∫—É, –ø–µ—Ä–µ–º–µ—â–∞—è –∏—Ö –≤ –ø—É—Å—Ç–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ. \n",
      "\n",
      "–î–ª—è 15 Puzzle —Å—É—â–µ—Å—Ç–≤—É—é—Ç –∞–ª–≥–æ—Ä–∏—Ç–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ—à–∞–µ–º–æ—Å—Ç—å –ø–∞–∑–ª–∞ (–Ω–µ –≤—Å–µ –Ω–∞—á–∞–ª—å–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ —Ä–µ—à–∞–µ–º—ã) –∏ –≤—ã–∏–≥—Ä—ã—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è, –µ—Å–ª–∏ –ø–∞–∑–ª —Ä–µ—à–∞–µ–º. –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é:\n",
      "\n",
      "1. –†–∞–∑–¥–µ–ª–∏—Ç–µ –ø–∞–∑–ª –Ω–∞ –∑–æ–Ω—ã –∏ —Ä–µ—à–∞–π—Ç–µ –ø–æ—ç—Ç–∞–ø–Ω–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–Ω–∞—á–∞–ª–∞ –≤–µ—Ä—Ö–Ω–∏–µ –¥–≤–µ —Å—Ç—Ä–æ–∫–∏, –∑–∞—Ç–µ–º –ª–µ–≤–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ –∏ —Ç.–¥.).\n",
      "2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –¥–ª—è –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–ª–∏—Ç–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –º–∏–Ω–∏–º–∏–∑–∏—Ä—É—é—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –º–µ—Ç–æ–¥ \"–ø–µ—Ä–µ–≤–æ—Ä–æ—Ç–∞ —É–≥–ª–∞\").\n",
      "3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞ –∑–∞–ø–æ–º–∏–Ω–∞–π—Ç–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ö–æ–¥–æ–≤, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–µ—à–∞—Ç—å —Ç–∏–ø–∏—á–Ω—ã–µ –∑–∞–¥–∞—á–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–∞–∫ –ø–æ–º–µ–Ω—è—Ç—å –º–µ—Å—Ç–∞–º–∏ –¥–≤–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–ª–∏—Ç–∫–∏).\n",
      "\n",
      "–°–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –±–µ–∑ –∑–Ω–∞–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Ö–æ–¥–æ–≤ —Ä–µ—à–∏—Ç—å –ø–∞–∑–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–≤–æ–ª—å–Ω–æ –Ω–µ–ø—Ä–æ—Å—Ç–æ, –æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ –≤—ã –Ω–µ –∏–º–µ–µ—Ç–µ –æ–ø—ã—Ç–∞ —Å –ø–æ–¥–æ–±–Ω—ã–º–∏ –≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∞–º–∏. –ù–æ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤, –ø–∞–∑–ª —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Ä–µ—à–∞–µ–º—ã–º –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤—Å–µ–≥–¥–∞. [SEP] </s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
      "‚úì –î–∞–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
      "\n",
      "–ü—Ä–∏–º–µ—Ä 2:\n",
      "–î–ª–∏–Ω–∞: 563 —Ç–æ–∫–µ–Ω–æ–≤\n",
      "‚úì –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: True\n",
      "‚úì –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: True\n",
      "‚úì [SEP]: True\n",
      "‚úì –ö–æ–Ω—Ç–µ–Ω—Ç: True\n",
      "<s><s> –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: —Å–ª—É—à–∞–π, —É –º–µ–Ω—è —Ç—É—Ç –≤–æ–∑–Ω–∏–∫–ª–∞ –∑–∞–¥–∞—á–∫–∞ –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –∫–æ–º–ø—å—é—Ç–µ—Ä–∞, –∏ —è –Ω–µ –º–æ–≥—É –≤ –Ω–µ–π —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è. –º–Ω–µ –Ω—É–∂–Ω–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –¥–æ—Å—Ç—É–ø –∫ –∫—ç—à-–ø–∞–º—è—Ç–∏ –≤ –º–Ω–æ–≥–æ—è–¥–µ—Ä–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π. —Ç—ã –Ω–µ –º–æ–≥ –±—ã –ø–æ–º–æ—á—å —Å —ç—Ç–∏–º? –≤–æ—Ç –∫–∞–∫ —è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é –∑–∞–¥–∞—á—É:\n",
      "\n",
      "1. –∏–º–µ–µ—Ç—Å—è –º–Ω–æ–≥–æ—è–¥–µ—Ä–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –æ–±—â–∏–º –∫—ç—à–µ–º –≤—Ç–æ—Ä–æ–≥–æ —É—Ä–æ–≤–Ω—è.\n",
      "2. –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º–∞—Ö–∏ –∫—ç—à–∞ –ø—Ä–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö.\n",
      "3. –∞–ª–≥–æ—Ä–∏—Ç–º –¥–æ–ª–∂–µ–Ω —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—Ç—å –¥–∞–Ω–Ω—ã–µ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ª–æ–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–Ω—ã–µ –ø—Ä–æ–º–∞—Ö–∏.\n",
      "\n",
      "–º–æ–∂–µ—Ç –µ—Å—Ç—å –∏–¥–µ–∏, –∫–∞–∫ —ç—Ç–æ –º–æ–∂–Ω–æ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –Ω–∞ —É—Ä–æ–≤–Ω–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞? –±—É–¥—É —Ä–∞–¥ –ª—é–±—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º –∏ —Å–æ–≤–µ—Ç–∞–º! –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –í–∞—à–∞ –∑–∞–¥–∞—á–∞ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –∏ –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–Ω–æ–≥–æ—è–¥–µ—Ä–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤. –î–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫—ç—à-–ø–∞–º—è—Ç–∏ –≤–∞–∂–Ω–æ —É—á–∏—Ç—ã–≤–∞—Ç—å —Ç–∞–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã, –∫–∞–∫ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∏ –≤—Ä–µ–º–µ–Ω–Ω–∞—è –ª–æ–∫–∞–ª—å–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö, –∞ —Ç–∞–∫–∂–µ –∏–∑–±–µ–≥–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –ø—Ä–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–∏. –í–æ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ —à–∞–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞:\n",
      "\n",
      "### –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á\n",
      "–ü—Ä–µ–∂–¥–µ –≤—Å–µ–≥–æ, –Ω—É–∂–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∑–∞–¥–∞—á, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ. –í–∞–∂–Ω–æ –ø–æ–Ω—è—Ç—å, –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∏ –∫–∞–∫ —á–∞—Å—Ç–æ –æ–Ω–∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞—é—Ç—Å—è.\n",
      "\n",
      "### –®–∞–≥ 2: –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
      "–î–∞–ª–µ–µ, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª–∏—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–æ–∫–∞–ª—å–Ω–æ—Å—Ç–∏. –≠—Ç–æ –º–æ–∂–µ—Ç –≤–∫–ª—é—á–∞—Ç—å –≤ —Å–µ–±—è:\n",
      "\n",
      "- **–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö**: —á—Ç–æ–±—ã –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –æ–¥–Ω–æ–º—É —ç–ª–µ–º–µ–Ω—Ç—É –¥–∞–Ω–Ω—ã—Ö —Ä—è–¥–æ–º –Ω–∞—Ö–æ–¥–∏–ª–∏—Å—å –∏ –¥—Ä—É–≥–∏–µ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã.\n",
      "- **–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —è–¥—Ä–∞–º–∏**: —á—Ç–æ–±—ã –∫–∞–∂–¥–æ–µ —è–¥—Ä–æ —Ä–∞–±–æ—Ç–∞–ª–æ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö –∏ –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–Ω—ã–µ –ø—Ä–æ–º–∞—Ö–∏.\n",
      "\n",
      "### –®–∞–≥ 3: –†–∞–∑–±–∏–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –±–ª–æ–∫–∏\n",
      "–ü–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–∞, —Å–ª–µ–¥—É–µ—Ç —Ä–∞–∑–±–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ –±–ª–æ–∫–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è. –í –∏–¥–µ–∞–ª–µ, —Ä–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ –¥–æ–ª–∂–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ä—É –ª–∏–Ω–µ–π–∫–∏ –∫—ç—à–∞.\n",
      "\n",
      "### –®–∞–≥ 4: –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ø—Ä–µ–¥–≤—ã–±–æ—Ä–∫–∏ (prefetching)\n",
      "–†–∞–∑—Ä–∞–±–æ—Ç–∞–π—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º –ø—Ä–µ–¥–≤—ã–±–æ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à –∑–∞—Ä–∞–Ω–µ–µ, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ –æ–±—Ä–∞—â–µ–Ω–∏–π –∫ –¥–∞–Ω–Ω—ã–º.\n",
      "\n",
      "### –®–∞–≥ 5: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º\n",
      "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Ç–∞–∫–∂–µ –æ–±–µ—Å–ø–µ—á–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º –º–µ–∂–¥—É —è–¥—Ä–∞–º–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Å–∏—Ç—É–∞—Ü–∏–π, –∫–æ–≥–¥–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —è–¥–µ—Ä –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ–±–Ω–æ–≤–ª—è—é—Ç –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à–µ.\n",
      "\n",
      "### –®–∞–≥ 6: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ç–ª–∞–¥–∫–∞\n",
      "–ü—Ä–æ–≤–µ–¥–∏—Ç–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞–±–æ—á–∏—Ö –Ω–∞–≥—Ä—É–∑–∫–∞—Ö. –û—Ü–µ–Ω–∏—Ç–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞, –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–º–∞—Ö–æ–≤ –∫—ç—à–∞ –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞—è —Å –±–∞–∑–æ–≤—ã–º —Å–ª—É—á–∞–µ–º.\n",
      "\n",
      "### –®–∞–≥ 7: –ò—Ç–µ—Ä–∞—Ü–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è\n",
      "–ù–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–Ω–µ—Å–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–∏–≤—ã –≤ –∞–ª–≥–æ—Ä–∏—Ç–º –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ. –ò—â–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.\n",
      "\n",
      "–≠—Ç–∏ —à–∞–≥–∏ –¥–æ–ª–∂–Ω—ã –ø–æ–º–æ—á—å –≤–∞–º –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫—ç—à-–ø–∞–º—è—Ç–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π. –£—Å–ø–µ—Ö–æ–≤ –≤ —Ä–∞–±–æ—Ç–µ! [SEP] </s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
      "‚úì –î–∞–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
      "\n",
      "–ü—Ä–∏–º–µ—Ä 3:\n",
      "–î–ª–∏–Ω–∞: 940 —Ç–æ–∫–µ–Ω–æ–≤\n",
      "‚úì –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: True\n",
      "‚úì –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: True\n",
      "‚úì [SEP]: True\n",
      "‚úì –ö–æ–Ω—Ç–µ–Ω—Ç: True\n",
      "<s><s> –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, –ø–æ–º–æ–≥–∏—Ç–µ –º–Ω–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è —Å –æ–¥–Ω–æ–π —Ç—Ä–∏–≥–æ–Ω–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π. –ú–Ω–µ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∞—Ä–∫—Å–∏–Ω—É—Å–∞ –∏ –∞—Ä–∫–∫–æ—Å–∏–Ω—É—Å–∞, –∏—Å–ø–æ–ª—å–∑—É—è –µ–¥–∏–Ω–∏—á–Ω—É—é –æ–∫—Ä—É–∂–Ω–æ—Å—Ç—å. –ú–æ–≥–ª–∏ –±—ã –≤—ã –ø–æ–∫–∞–∑–∞—Ç—å –º–Ω–µ –∏—Ö –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ, –∏ –æ–±—ä—è—Å–Ω–∏—Ç—å, –∫–∞–∫ –∏—Ö –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Ä–µ—à–µ–Ω–∏—è —É—Ä–∞–≤–Ω–µ–Ω–∏–π? –ö—Ä–æ–º–µ —Ç–æ–≥–æ, –∫–∞–∫ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —ç—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á, –Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ —Ñ–∏–∑–∏–∫–µ –∏–ª–∏ –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏? –ë—É–¥—É –æ—á–µ–Ω—å –ø—Ä–∏–∑–Ω–∞—Ç–µ–ª–µ–Ω –∑–∞ –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ä–∞–∑–±–æ—Ä —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏. –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä—ë–º—Å—è —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –∞—Ä–∫—Å–∏–Ω—É—Å–∞ –∏ –∞—Ä–∫–∫–æ—Å–∏–Ω—É—Å–∞ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –µ–¥–∏–Ω–∏—á–Ω–æ–π –æ–∫—Ä—É–∂–Ω–æ—Å—Ç–∏, –∞ —Ç–∞–∫–∂–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ —É—Ä–∞–≤–Ω–µ–Ω–∏—è—Ö –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á–∞—Ö.\n",
      "\n",
      "### –û—Å–Ω–æ–≤–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∞—Ä–∫—Å–∏–Ω—É—Å–∞ –∏ –∞—Ä–∫–∫–æ—Å–∏–Ω—É—Å–∞ –Ω–∞ –µ–¥–∏–Ω–∏—á–Ω–æ–π –æ–∫—Ä—É–∂–Ω–æ—Å—Ç–∏\n",
      "\n",
      "–ï–¥–∏–Ω–∏—á–Ω–∞—è –æ–∫—Ä—É–∂–Ω–æ—Å—Ç—å ‚Äî —ç—Ç–æ –æ–∫—Ä—É–∂–Ω–æ—Å—Ç—å —Å —Ä–∞–¥–∏—É—Å–æ–º —Ä–∞–≤–Ω—ã–º 1, —Ü–µ–Ω—Ç—Ä –∫–æ—Ç–æ—Ä–æ–π —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω –≤ –Ω–∞—á–∞–ª–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –Ω–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–Ω–æ–π –ø–ª–æ—Å–∫–æ—Å—Ç–∏.\n",
      "\n",
      "#### –ê—Ä–∫—Å–∏–Ω—É—Å\n",
      "–§—É–Ω–∫—Ü–∏—è –∞—Ä–∫—Å–∏–Ω—É—Å (`arcsin`) ‚Äî —ç—Ç–æ –æ–±—Ä–∞—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫ —Å–∏–Ω—É—Å—É. –û–Ω–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É–≥–æ–ª –ø–æ –µ–≥–æ —Å–∏–Ω—É—Å—É. –î–ª—è –∞—Ä–∫—Å–∏–Ω—É—Å–∞:\n",
      "- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: `arcsin(y) = x` ‚Üî `sin(x) = y`\n",
      "- –û–±–ª–∞—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π —Ñ—É–Ω–∫—Ü–∏–∏ –∞—Ä–∫—Å–∏–Ω—É—Å–∞: `[-œÄ/2, œÄ/2]` –∏–ª–∏ `[-90¬∞, 90¬∞]`\n",
      "\n",
      "#### –ê—Ä–∫–∫–æ—Å–∏–Ω—É—Å\n",
      "–§—É–Ω–∫—Ü–∏—è –∞—Ä–∫–∫–æ—Å–∏–Ω—É—Å (`arccos`) ‚Äî —ç—Ç–æ —Ç–∞–∫–∂–µ –æ–±—Ä–∞—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –Ω–æ –∫ –∫–æ—Å–∏–Ω—É—Å—É. –û–Ω–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É–≥–æ–ª –ø–æ –µ–≥–æ –∫–æ—Å–∏–Ω—É—Å—É. –î–ª—è –∞—Ä–∫–∫–æ—Å–∏–Ω—É—Å–∞:\n",
      "- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: `arccos(y) = x` ‚Üî `cos(x) = y`\n",
      "- –û–±–ª–∞—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π —Ñ—É–Ω–∫—Ü–∏–∏ –∞—Ä–∫–∫–æ—Å–∏–Ω—É—Å–∞: `[0, œÄ]` –∏–ª–∏ `[0¬∞, 180¬∞]`\n",
      "\n",
      "–ù–∞ –≥—Ä–∞—Ñ–∏–∫–µ –µ–¥–∏–Ω–∏—á–Ω–æ–π –æ–∫—Ä—É–∂–Ω–æ—Å—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏—è –∞—Ä–∫—Å–∏–Ω—É—Å–∞ –∏ –∞—Ä–∫–∫–æ—Å–∏–Ω—É—Å–∞ –º–æ–∂–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ —É–≥–ª—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ—Å–∏ X. –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –º–æ–≥—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –≤–∞–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –Ω–æ –≤—ã –º–æ–∂–µ—Ç–µ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ, –Ω–∞—Ä–∏—Å–æ–≤–∞–≤ –æ–∫—Ä—É–∂–Ω–æ—Å—Ç—å –∏ –æ—Ç–º–µ—Ç–∏–≤ –Ω–∞ –Ω–µ–π —É–≥–ª—ã, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è–º –∏–∑ –æ–±–ª–∞—Å—Ç–µ–π –∑–Ω–∞—á–µ–Ω–∏–π —Ñ—É–Ω–∫—Ü–∏–π.\n",
      "\n",
      "### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∞—Ä–∫—Å–∏–Ω—É—Å–∞ –∏ –∞—Ä–∫–∫–æ—Å–∏–Ω—É—Å–∞ –≤ —É—Ä–∞–≤–Ω–µ–Ω–∏—è—Ö\n",
      "\n",
      "–î–ª—è —Ä–µ—à–µ–Ω–∏—è —É—Ä–∞–≤–Ω–µ–Ω–∏–π –≤–∏–¥–∞ `sin(x) = y` –∏ `cos(x) = y` –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ –∞—Ä–∫—Å–∏–Ω—É—Å –∏ –∞—Ä–∫–∫–æ—Å–∏–Ω—É—Å. –ù–∞–ø—Ä–∏–º–µ—Ä:\n",
      "\n",
      "1. `sin(x) = 1/2`\n",
      "   –ß—Ç–æ–±—ã –Ω–∞–π—Ç–∏ `x`, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ä–∫—Å–∏–Ω—É—Å: `x = arcsin(1/2)`. –ó–Ω–∞—è –æ–±–ª–∞—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π –∞—Ä–∫—Å–∏–Ω—É—Å–∞, –ø–æ–ª—É—á–∞–µ–º `x = œÄ/6` –∏–ª–∏ `x = 30¬∞`.\n",
      "\n",
      "2. `cos(x) = -1`\n",
      "   –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ä–∫–∫–æ—Å–∏–Ω—É—Å: `x = arccos(-1)`. –ó–Ω–∞—è –æ–±–ª–∞—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π –∞—Ä–∫–∫–æ—Å–∏–Ω—É—Å–∞, –ø–æ–ª—É—á–∞–µ–º `x = œÄ` –∏–ª–∏ `x = 180¬∞`.\n",
      "\n",
      "### –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á–∞—Ö\n",
      "\n",
      "–ê—Ä–∫—Å–∏–Ω—É—Å –∏ –∞—Ä–∫–∫–æ—Å–∏–Ω—É—Å –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö, –≤–∫–ª—é—á–∞—è —Ñ–∏–∑–∏–∫—É –∏ –∏–Ω–∂–µ–Ω–µ—Ä–∏—é, –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É–≥–ª–æ–≤ –ø–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–º –æ—Ç–Ω–æ—à–µ–Ω–∏—è–º —Å—Ç–æ—Ä–æ–Ω –≤ —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–∞—Ö.\n",
      "\n",
      "#### –ü—Ä–∏–º–µ—Ä –≤ —Ñ–∏–∑–∏–∫–µ:\n",
      "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –∑–∞–¥–∞—á—É –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è —É–≥–ª–∞ –±—Ä–æ—Å–∫–∞ –ø—Ä–∏ –¥–≤–∏–∂–µ–Ω–∏–∏ —Ç–µ–ª–∞ –ø–æ –ø–∞—Ä–∞–±–æ–ª–∏—á–µ—Å–∫–æ–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–∏ –∏–∑–≤–µ—Å—Ç–Ω–æ–π –Ω–∞—á–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ `v` –∏ –¥–∏—Å—Ç–∞–Ω—Ü–∏–∏ `d` –¥–æ —Ç–æ—á–∫–∏ –ø–∞–¥–µ–Ω–∏—è.\n",
      "\n",
      "1. –£—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ —Ç–µ–ª–æ –ø—Ä–æ–ª–µ—Ç–∏—Ç –ø—Ä–∏ —É–≥–ª–µ –±—Ä–æ—Å–∫–∞ `Œ∏`, –≤—ã–≥–ª—è–¥–∏—Ç —Ç–∞–∫: `d = (v^2 * sin(2Œ∏)) / g`, –≥–¥–µ `g` ‚Äî —É—Å–∫–æ—Ä–µ–Ω–∏–µ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –ø–∞–¥–µ–Ω–∏—è.\n",
      "2. –í—ã—Ä–∞–∑–∏–º `sin(2Œ∏)`: `sin(2Œ∏) = d * g / v^2`.\n",
      "3. –î–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è —É–≥–ª–∞ `Œ∏` –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ä–∫—Å–∏–Ω—É—Å: `2Œ∏ = arcsin(d * g / v^2)`.\n",
      "4. –û—Ç—Å—é–¥–∞ `Œ∏ = 1/2 * arcsin(d * g / v^2)`.\n",
      "\n",
      "#### –ü—Ä–∏–º–µ—Ä –≤ –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏:\n",
      "–ü—É—Å—Ç—å —Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É–≥–æ–ª –Ω–∞–∫–ª–æ–Ω–∞ –ª–µ—Å—Ç–Ω–∏—Ü—ã, –æ–ø–∏—Ä–∞—é—â–µ–π—Å—è –Ω–∞ —Å—Ç–µ–Ω—É, –ø—Ä–∏ –∏–∑–≤–µ—Å—Ç–Ω–æ–π –≤—ã—Å–æ—Ç–µ `h`, –Ω–∞ –∫–æ—Ç–æ—Ä—É—é –æ–Ω–∞ –æ–ø–∏—Ä–∞–µ—Ç—Å—è, –∏ –¥–ª–∏–Ω–µ –ª–µ—Å—Ç–Ω–∏—Ü—ã `l`.\n",
      "\n",
      "1. –ò—Å–ø–æ–ª—å–∑—É—è —Ç—Ä–∏–≥–æ–Ω–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –≤ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–æ–º —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–µ, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º, —á—Ç–æ `cos(Œ∏) = h / l`.\n",
      "2. –ß—Ç–æ–±—ã –Ω–∞–π—Ç–∏ —É–≥–æ–ª `Œ∏`, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ä–∫–∫–æ—Å–∏–Ω—É—Å: `Œ∏ = arccos(h / l)`.\n",
      "\n",
      "–ù–∞–¥–µ—é—Å—å, —ç—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã –ø–æ–º–æ–≥–ª–∏ –≤–∞–º –ø–æ–Ω—è—Ç—å, –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞—Ä–∫—Å–∏–Ω—É—Å –∏ –∞—Ä–∫–∫–æ—Å–∏–Ω—É—Å –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á. –ï—Å–ª–∏ —É –≤–∞—Å –≤–æ–∑–Ω–∏–∫–Ω—É—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã, –Ω–µ —Å—Ç–µ—Å–Ω—è–π—Ç–µ—Å—å –∏—Ö –∑–∞–¥–∞—Ç—å! [SEP] </s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
      "‚úì –î–∞–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n"
     ]
    }
   ],
   "source": [
    "verify_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff75ea-774d-4be8-aa63-3f6af330305c",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc59e55d-5244-4334-8099-df62f702708e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA before train] allocated=2.85GB, reserved=4.15GB, peak=3.79GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA before train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "473a29fe-469b-4ab4-8a90-c4b94819eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_prep = dataset.select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "106e0802-751a-4c70-aeff-63237ff9cda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 275.48 examples/s]\n"
     ]
    }
   ],
   "source": [
    "check_data = check_data_prep.map(formatting_func_final,\n",
    "                                 batched=False,\n",
    "                                 # batch_size=1000,\n",
    "                                 remove_columns=check_data_prep.column_names  # –£–¥–∞–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b682a54-6d38-493b-8310-c972665aeb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "002a54cf-408b-4aa8-a693-d8cc14ccb033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9906/9906 [00:13<00:00, 710.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    formatting_func_final,\n",
    "    batched=False,\n",
    "    remove_columns=dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6df00f3-619e-4b4d-ade3-647d2d45480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12c71c9c-f233-4ab1-a928-418312c29b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: [1, 1, 16861, 125851, 1759, 1403, 52612, 26900, 2019, 5386]\n",
      "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Length: 2048\n"
     ]
    }
   ],
   "source": [
    "print(\"Input IDs:\", tokenized_dataset[0][\"input_ids\"][:10])\n",
    "print(\"Attention mask:\", tokenized_dataset[0][\"attention_mask\"][:10])\n",
    "print(\"Length:\", len(tokenized_dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21ec0976-ada6-4b61-bae4-490da14beefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_for_test = [\n",
    "    '–ö–∞–∫ –≤–∫—É—Å–Ω–æ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –∏–Ω–¥–µ–π–∫—É –Ω–∞ –≥—Ä–∏–ª–µ?',\n",
    "    '–ö–∞–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ø—Ä–∏–±–ª–∏–∂–∞—é—â–∏–π—Å—è –∏–Ω—Å—É–ª—å—Ç?',\n",
    "    '–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–∞–Ω–æ–Ω—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥—Ä–µ–≤–Ω–∏—Ö —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–π',\n",
    "    '–û–±–ª–∞–≥–∞—Ç—å –ª–∏ —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏ —Å—É–º–º—ã –ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –¥–æ–ª–≥–∞ –ø–æ –∑–∞–π–º—É –æ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –≥–¥–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–Ω—ã–π?',\n",
    "    '–†–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ –ø—Ä–æ –ö—É—Ä—á–∞—Ç–æ–≤–∞'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d426f8a-1de3-4e5b-95fe-98d9961b2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_correct(prompt):\n",
    "    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç\n",
    "    user_prompt = f\"<s> –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {prompt} –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:\"\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        user_prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=1024\n",
    "    ).to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=300,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é —á–∞—Å—Ç—å\n",
    "    generated = outputs[0][inputs.input_ids.shape[1]:]\n",
    "    response = tokenizer.decode(generated, skip_special_tokens=True)\n",
    "    \n",
    "    # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–π [SEP] –≤ –∫–æ–Ω—Ü–µ\n",
    "    response = response.replace(\"[SEP]\", \"\").strip()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d474931-462d-420c-82e8-0c274c789541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**–ò–Ω–¥–µ–π–∫–∞ –Ω–∞ –≥—Ä–∏–ª–µ: –ø–æ—à–∞–≥–æ–≤—ã–π —Ä–µ—Ü–µ–ø—Ç**\n",
      "\n",
      "**–ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã:**\n",
      "* –ò–Ω–¥–µ–π–∫–∞ (—Ñ–∏–ª–µ –∏–ª–∏ –¥—Ä—É–≥–∏–µ —á–∞—Å—Ç–∏) ‚Äî 1 –∫–≥;\n",
      "* –°–æ–ª—å ‚Äî –ø–æ –≤–∫—É—Å—É;\n",
      "* –ß—ë—Ä–Ω—ã–π –ø–µ—Ä–µ—Ü (–º–æ–ª–æ—Ç—ã–π) ‚Äî –ø–æ –≤–∫—É—Å—É;\n",
      "* –ß–µ—Å–Ω–æ–∫ ‚Äî 3‚Äì4 –∑—É–±—á–∏–∫–∞;\n",
      "* –†–æ–∑–º–∞—Ä–∏–Ω —Å–≤–µ–∂–∏–π ‚Äî 1 –≤–µ—Ç–æ—á–∫–∞;\n",
      "* –û–ª–∏–≤–∫–æ–≤–æ–µ –º–∞—Å–ª–æ ‚Äî 2‚Äì3 —Å—Ç. –ª.;\n",
      "* –õ–∏–º–æ–Ω–Ω—ã–π —Å–æ–∫ ‚Äî 2‚Äì3 —Å—Ç. –ª.;\n",
      "* –°–æ–µ–≤—ã–π —Å–æ—É—Å ‚Äî 1‚Äì2 —Å—Ç. –ª. (–ø–æ –∂–µ–ª–∞–Ω–∏—é);\n",
      "* –°–ø–µ—Ü–∏–∏ –¥–ª—è –ø—Ç–∏—Ü—ã (–ø–æ –∂–µ–ª–∞–Ω–∏—é) ‚Äî –ø–æ –≤–∫—É—Å—É.\n",
      "\n",
      "**–ü—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏–µ:**\n",
      "\n",
      "1. –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –∏–Ω–¥–µ–π–∫—É: –ø—Ä–æ–º–æ–π—Ç–µ –∏ –æ–±—Å—É—à–∏—Ç–µ –±—É–º–∞–∂–Ω—ã–º –ø–æ–ª–æ—Ç–µ–Ω—Ü–µ–º. –ù–∞—Ä–µ–∂—å—Ç–µ –∏–Ω–¥–µ–π–∫—É –Ω–∞ –ø–æ—Ä—Ü–∏–æ–Ω–Ω—ã–µ –∫—É—Å–∫–∏ –∏–ª–∏ –æ—Å—Ç–∞–≤—å—Ç–µ —Ü–µ–ª–∏–∫–æ–º, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–∞—à–∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π.\n",
      "\n",
      "2. –ß–µ—Å–Ω–æ–∫ –æ—á–∏—Å—Ç–∏—Ç–µ –∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–µ —á–µ—Ä–µ–∑ –ø—Ä–µ—Å—Å.\n",
      "\n",
      "3. –í –Ω–µ–±–æ–ª—å—à–æ–π –º–∏—Å–∫–µ —Å–º–µ—à–∞–π—Ç–µ –æ–ª–∏–≤–∫–æ–≤–æ–µ –º–∞—Å–ª–æ, –ª–∏–º–æ–Ω–Ω—ã–π —Å–æ–∫, —Å–æ–µ–≤—ã–π —Å–æ—É—Å, –∏–∑–º–µ–ª—å—á—ë–Ω–Ω—ã–π —á–µ—Å–Ω–æ–∫, —Å–æ–ª—å, –ø–µ—Ä–µ—Ü –∏ —Ä–æ–∑–º–∞—Ä–∏–Ω.\n",
      "\n",
      "4. –ü–æ–ª—É—á–µ–Ω–Ω—ã–º –º–∞—Ä–∏–Ω–∞–¥–æ–º —Ç—â–∞—Ç–µ–ª—å–Ω–æ –æ–±–º–∞–∂—å—Ç–µ –∏–Ω–¥–µ–π–∫—É —Å–æ –≤—Å–µ—Ö —Å—Ç–æ—Ä–æ–Ω.\n",
      "\n",
      "5. –û—Å—Ç–∞–≤—å—Ç–µ –º–∞—Ä–∏–Ω–æ–≤–∞—Ç—å—Å—è –º–∏–Ω–∏–º—É–º –Ω–∞ 30 –º–∏–Ω—É—Ç (–º–æ–∂–Ω–æ –∏ –Ω–∞ –±–æ–ª–µ–µ –¥–ª–∏—Ç–µ–ª—å–Ω—ã–π —Å—Ä–æ–∫).\n",
      "\n",
      "6. –†–∞–∑–æ–≥—Ä–µ–π—Ç–µ –≥—Ä–∏–ª—å. –ï—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ —É–≥–æ–ª—å–Ω—ã–π –≥—Ä–∏–ª—å, –¥–∞–π—Ç–µ —É–≥–ª—è–º –ø—Ä–æ–≥–æ—Ä–µ—Ç—å –¥–æ —Å–µ—Ä–æ–≥–æ —Ü–≤–µ—Ç–∞.\n",
      "\n",
      "7. –í—ã–ª–æ–∂–∏—Ç–µ –∏–Ω–¥–µ–π–∫—É –Ω–∞ –≥—Ä–∏–ª—å. –ñ–∞—Ä—å—Ç–µ –Ω–∞ —Å—Ä–µ–¥–Ω–µ–º\n",
      "--------------------------------------------------\n",
      "*–ü—Ä–∏ –ø–æ—è–≤–ª–µ–Ω–∏–∏ –ª—é–±—ã—Ö —Å–∏–º–ø—Ç–æ–º–æ–≤, —É–∫–∞–∑—ã–≤–∞—é—â–∏—Ö –Ω–∞ –∏–Ω—Å—É–ª—å—Ç, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –Ω–µ–∑–∞–º–µ–¥–ª–∏—Ç–µ–ª—å–Ω–æ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∑–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –ø–æ–º–æ—â—å—é. –¢–æ–ª—å–∫–æ –≤—Ä–∞—á –º–æ–∂–µ—Ç –ø—Ä–æ–≤–µ—Å—Ç–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –∏ –Ω–∞–∑–Ω–∞—á–∏—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –ª–µ—á–µ–Ω–∏–µ.*\n",
      "\n",
      "**–°–∏–º–ø—Ç–æ–º—ã –∏–Ω—Å—É–ª—å—Ç–∞ –º–æ–≥—É—Ç –≤–∫–ª—é—á–∞—Ç—å:**\n",
      "\n",
      "- –í–Ω–µ–∑–∞–ø–Ω—É—é —Å–ª–∞–±–æ—Å—Ç—å –∏–ª–∏ –æ–Ω–µ–º–µ–Ω–∏–µ –≤ –ª–∏—Ü–µ, —Ä—É–∫–µ –∏–ª–∏ –Ω–æ–≥–µ, –æ—Å–æ–±–µ–Ω–Ω–æ —Å –æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã —Ç–µ–ª–∞;\n",
      "- –í–Ω–µ–∑–∞–ø–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å–æ –∑—Ä–µ–Ω–∏–µ–º, —Ç–∞–∫–∏–µ –∫–∞–∫ –ø–æ—Ç–µ—Ä—è –∑—Ä–µ–Ω–∏—è –≤ –æ–¥–Ω–æ–º –∏–ª–∏ –æ–±–æ–∏—Ö –≥–ª–∞–∑–∞—Ö, –¥–≤–æ–µ–Ω–∏–µ –≤ –≥–ª–∞–∑–∞—Ö;\n",
      "- –¢—Ä—É–¥–Ω–æ—Å—Ç–∏ —Å —Ä–µ—á—å—é, –Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–µ–≤–Ω—è—Ç–Ω–∞—è —Ä–µ—á—å –∏–ª–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–¥–æ–±—Ä–∞—Ç—å –Ω—É–∂–Ω—ã–µ —Å–ª–æ–≤–∞;\n",
      "- –í–Ω–µ–∑–∞–ø–Ω–æ–µ –≥–æ–ª–æ–≤–æ–∫—Ä—É–∂–µ–Ω–∏–µ, –Ω–∞—Ä—É—à–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ –∏–ª–∏ –ø–æ—Ç–µ—Ä—è —Ä–∞–≤–Ω–æ–≤–µ—Å–∏—è;\n",
      "- –í–Ω–µ–∑–∞–ø–Ω—É—é —Å–∏–ª—å–Ω—É—é –≥–æ–ª–æ–≤–Ω—É—é –±–æ–ª—å, —á–∞—Å—Ç–æ —Å —á—É–≤—Å—Ç–≤–æ–º —Ä–∞—Å–ø–∏—Ä–∞–Ω–∏—è –∏–ª–∏ –¥–∞–≤–ª–µ–Ω–∏—è –≤ –≥–æ–ª–æ–≤–µ;\n",
      "- –û–Ω–µ–º–µ–Ω–∏–µ –∫–æ–Ω–µ—á–Ω–æ—Å—Ç–µ–π;\n",
      "- –°–ø—É—Ç–∞–Ω–Ω–æ—Å—Ç—å —Å–æ–∑–Ω–∞–Ω–∏—è, –¥–µ–∑–æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è.\n",
      "\n",
      "–í–∞–∂–Ω–æ –ø–æ–º–Ω–∏—Ç—å, —á—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∏–∑ —ç—Ç–∏—Ö —Å–∏–º–ø—Ç–æ–º–æ–≤ –º–æ–≥—É—Ç –ø–æ—è–≤–ª—è—Ç—å—Å—è –∏ –∏—Å—á–µ–∑–∞—Ç—å, –ø–æ—ç—Ç–æ–º—É –¥–∞–∂–µ –∫—Ä–∞—Ç–∫–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–æ—è–≤–ª–µ–Ω–∏—è –º–æ–≥—É—Ç –±—ã—Ç—å —Å–∏–≥–Ω–∞–ª–æ–º —Å–µ—Ä—å—ë–∑–Ω–æ–≥–æ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è. –ï—Å–ª–∏ –≤—ã –∑–∞–º–µ—Ç–∏–ª–∏ —É —Å–µ–±—è –∏–ª–∏ —É –∫–æ–≥–æ-—Ç–æ –∏–∑ –±–ª–∏–∑–∫–∏—Ö –ø–æ–¥–æ–±–Ω—ã–µ —Å–∏–º–ø—Ç–æ–º—ã, —Å—Ä–æ—á–Ω–æ –≤—ã–∑–æ–≤–∏—Ç–µ —Å–∫–æ—Ä—É—é –º–µ–¥–∏—Ü–∏–Ω—Å–∫—É—é –ø–æ–º–æ—â—å.\n",
      "--------------------------------------------------\n",
      "1. **–ï–≥–∏–ø–µ—Ç**:\n",
      "- —Å—Ç—Ä–æ–≥–∞—è —Å–∏–º–º–µ—Ç—Ä–∏—è –∏ –≥–µ–æ–º–µ—Ç—Ä–∏—á–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º;\n",
      "- –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫—Ä—É–ø–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –∫–∞–º–Ω—è –¥–ª—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞;\n",
      "- –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–Ω –∏ –ø–∏–ª–æ–Ω–æ–≤ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π;\n",
      "- –º–æ–Ω—É–º–µ–Ω—Ç–∞–ª—å–Ω–æ—Å—Ç—å –∏ –º–∞—Å—à—Ç–∞–±–Ω–æ—Å—Ç—å –∑–¥–∞–Ω–∏–π;\n",
      "- –∏–µ—Ä–æ–≥–ª–∏—Ñ–∏—á–µ—Å–∫–∏–µ –Ω–∞–¥–ø–∏—Å–∏ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Å—Ç–µ–Ω–∞—Ö —Ö—Ä–∞–º–æ–≤ –∏ –≥—Ä–æ–±–Ω–∏—Ü;\n",
      "- –ø–æ–∫–ª–æ–Ω–µ–Ω–∏–µ –ø—Ä–∏—Ä–æ–¥–µ –∏ –±–æ–∂–µ—Å—Ç–≤–∞–º —á–µ—Ä–µ–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ñ–æ—Ä–º—ã –∏ —Å–∏–º–≤–æ–ª—ã.\n",
      "\n",
      "2. **–î—Ä–µ–≤–Ω—è—è –ì—Ä–µ—Ü–∏—è**:\n",
      "- –≥–∞—Ä–º–æ–Ω–∏—á–Ω—ã–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ –∏ –±–∞–ª–∞–Ω—Å;\n",
      "- –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º—Ä–∞–º–æ—Ä–∞ –∏ –¥—Ä—É–≥–∏—Ö –Ω–∞—Ç—É—Ä–∞–ª—å–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤;\n",
      "- –æ—Ä–¥–µ—Ä–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ (–¥–æ—Ä–∏—á–µ—Å–∫–∏–π, –∏–æ–Ω–∏—á–µ—Å–∫–∏–π, –∫–æ—Ä–∏–Ω—Ñ—Å–∫–∏–π –æ—Ä–¥–µ—Ä–∞);\n",
      "- —Ö—Ä–∞–º—ã –∏ —Ç–µ–∞—Ç—Ä—ã —Å –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞–º–∏ –¥–ª—è –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–æ–±—Ä–∞–Ω–∏–π;\n",
      "- –∞–∫—Ä–æ–ø–æ–ª—å –∫–∞–∫ —Ü–µ–Ω—Ç—Ä –≥–æ—Ä–æ–¥–∞;\n",
      "- —Å–∫—É–ª—å–ø—Ç—É—Ä—ã –∏ —Ä–µ–ª—å–µ—Ñ—ã –Ω–∞ —Ñ–∞—Å–∞–¥–∞—Ö –∑–¥–∞–Ω–∏–π.\n",
      "\n",
      "3. **–î—Ä–µ–≤–Ω–∏–π –†–∏–º**:\n",
      "- –∞—Ä–æ—á–Ω—ã–µ –∏ —Å–≤–æ–¥—á–∞—Ç—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏;\n",
      "- –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–µ—Ç–æ–Ω–∞ –¥–ª—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞;\n",
      "- –∞–∫–≤–µ–¥—É–∫–∏, –º–æ—Å—Ç—ã –∏ –¥–æ—Ä–æ–≥–∏ –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã;\n",
      "- –∞–º—Ñ–∏—Ç–µ–∞—Ç—Ä—ã –∏ —Ç–µ—Ä–º—ã –¥–ª—è –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π;\n",
      "- –∞—Ä–∫–∏ –∏ –∫–æ–ª–æ–Ω–Ω—ã –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ç—è–∂—ë–ª—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π;\n",
      "- –º–æ–Ω—É–º–µ–Ω—Ç–∞–ª—å–Ω–æ—Å—Ç—å –∏ –≤–µ–ª–∏—á–∏–µ –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ.\n",
      "\n",
      "4. **–î—Ä–µ–≤–Ω–∏–π –ö–∏—Ç–∞–π**:\n",
      "- —Å–∏–º–º–µ—Ç—Ä–∏—è –∏ —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å –ø–ª–∞–Ω–∏—Ä–æ–≤–∫–∏;\n",
      "- –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–µ—Ä–µ–≤–∞ –∏ –∫–∏—Ä–ø–∏—á–∞ –¥–ª—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞;\n",
      "- –ø–∞–≥–æ–¥–∞ –∫–∞–∫ —Å–∏–º–≤–æ–ª –±—É–¥–¥–∏–π—Å–∫–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã;\n",
      "- —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏—Ä–æ–¥–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞–º–∏;\n",
      "- –≤–∞–∂–Ω–æ—Å—Ç—å –≥–∞—Ä–º–æ–Ω–∏–∏ —Å –ø—Ä–∏—Ä–æ–¥–æ–π –∏ –∫–æ—Å–º–æ—Å–æ–º.\n",
      "\n",
      "5. **–î—Ä–µ–≤–Ω—è—è –ú–µ—Å–æ–ø–æ—Ç–∞–º–∏\n",
      "--------------------------------------------------\n",
      "–°–æ–≥–ª–∞—Å–Ω–æ —Å—Ç–∞—Ç—å–µ 415 –ì—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–≥–æ –∫–æ–¥–µ–∫—Å–∞ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏, –ø—Ä–æ—â–µ–Ω–∏–µ –¥–æ–ª–≥–∞ —è–≤–ª—è–µ—Ç—Å—è –æ–¥–Ω–∏–º –∏–∑ —Å–ø–æ—Å–æ–±–æ–≤ –ø—Ä–µ–∫—Ä–∞—â–µ–Ω–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤.\n",
      "\n",
      "–ü—Ä–∏ —ç—Ç–æ–º, –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø—É–Ω–∫—Ç–æ–º 1 —Å—Ç–∞—Ç—å–∏ 423 –ì—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–≥–æ –∫–æ–¥–µ–∫—Å–∞ –†–§, –¥–æ–≥–æ–≤–æ—Ä –∑–∞–π–º–∞, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –æ–¥–Ω–∞ –∏–∑ —Å—Ç–æ—Ä–æ–Ω –æ–±—è–∑—É–µ—Ç—Å—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω–µ –¥–µ–Ω—å–≥–∏ –∏–ª–∏ –≤–µ—â–∏, –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–µ —Ä–æ–¥–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏, —è–≤–ª—è–µ—Ç—Å—è –¥–æ–≥–æ–≤–æ—Ä–æ–º –≤–æ–∑–º–µ–∑–¥–Ω—ã–º, –µ—Å–ª–∏ –∏–∑ –∑–∞–∫–æ–Ω–∞, –∏–Ω—ã—Ö –ø—Ä–∞–≤–æ–≤—ã—Ö –∞–∫—Ç–æ–≤, —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –∏–ª–∏ —Å—É—â–µ—Å—Ç–≤–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ –Ω–µ –≤—ã—Ç–µ–∫–∞–µ—Ç –∏–Ω–æ–µ.\n",
      "\n",
      "–ß—Ç–æ –∫–∞—Å–∞–µ—Ç—Å—è —Å—Ç—Ä–∞—Ö–æ–≤—ã—Ö –≤–∑–Ω–æ—Å–æ–≤, —Ç–æ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø—É–Ω–∫—Ç–æ–º 1 —Å—Ç–∞—Ç—å–∏ 4221 –ù–∞–ª–æ–≥–æ–≤–æ–≥–æ –∫–æ–¥–µ–∫—Å–∞ –†–§, –æ–±—ä–µ–∫—Ç–æ–º –æ–±–ª–æ–∂–µ–Ω–∏—è —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏ –ø—Ä–∏–∑–Ω–∞—é—Ç—Å—è –≤—ã–ø–ª–∞—Ç—ã –∏ –∏–Ω—ã–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –≤ –ø–æ–ª—å–∑—É —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –ª–∏—Ü, –ø—Ä–æ–∏–∑–≤–æ–¥–∏–º—ã–µ –≤ —Ä–∞–º–∫–∞—Ö —Ç—Ä—É–¥–æ–≤—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π –∏ –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ-–ø—Ä–∞–≤–æ–≤—ã—Ö –¥–æ–≥–æ–≤–æ—Ä–æ–≤, –ø—Ä–µ–¥–º–µ—Ç–æ–º –∫–æ—Ç–æ—Ä—ã—Ö —è–≤–ª—è–µ—Ç—Å—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–∞–±–æ—Ç, –æ–∫–∞–∑–∞–Ω–∏–µ —É—Å–ª—É–≥.\n",
      "\n",
      "–ü—Ä–æ—â–µ–Ω–∏–µ –¥–æ–ª–≥–∞ –ø–æ –∑–∞–π–º—É, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤—ã–ø–ª–∞—Ç–æ–π –∏–ª–∏ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ–º –≤ —Ä–∞–º–∫–∞—Ö —Ç—Ä—É–¥–æ–≤—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π. –ü–æ—ç—Ç–æ–º—É, –µ—Å–ª–∏ –ø—Ä–æ—â–µ–Ω–∏–µ –¥–æ–ª–≥–∞ –Ω–µ —Å–≤—è–∑–∞–Ω–æ —Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–º —Ç—Ä—É–¥–æ–≤—ã—Ö –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–µ–π –∏ –Ω–µ –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–æ —Ç—Ä—É–¥–æ–≤—ã–º –¥–æ–≥–æ–≤–æ—Ä–æ–º –∏–ª–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º–∏ –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ –∞–∫—Ç–∞–º–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, —Ç–æ —Å—É–º–º—ã –ø—Ä–æ—â—ë–Ω–Ω–æ–≥–æ –¥–æ–ª–≥–∞ –Ω–µ –æ–±–ª–∞–≥–∞—é—Ç—Å—è —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏.\n",
      "\n",
      "–û–¥–Ω–∞–∫–æ, –µ—Å–ª–∏ –ø—Ä–æ—â–µ–Ω–∏–µ –¥–æ–ª–≥–∞ –∏–º–µ–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤—ã–ø–ª–∞—Ç—ã, —Å–≤—è–∑–∞–Ω–Ω–æ–π —Å —Ç—Ä—É–¥–æ–≤—ã–º–∏ –æ—Ç–Ω–æ—à–µ–Ω–∏—è–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ —ç—Ç–æ —á–∞—Å—Ç—å –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –¥–æ–≥–æ–≤–æ—Ä–∞, —Ä–µ–≥—É–ª–∏—Ä—É—é—â–µ–≥–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –º–µ–∂–¥—É —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª–µ–º –∏ —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–º), —Ç–æ —Ç–∞–∫–∏–µ —Å—É–º–º—ã –º–æ–≥—É—Ç –±—ã—Ç—å –ø—Ä–∏–∑–Ω–∞–Ω—ã –æ–±—ä–µ–∫—Ç–æ–º –æ–±–ª–æ–∂–µ–Ω–∏—è —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏.\n",
      "\n",
      "–î–ª—è —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–±–ª–æ–∂–µ–Ω–∏—è —Å—É–º–º –ø—Ä–æ—â—ë–Ω–Ω–æ–≥–æ –¥–æ–ª–≥–∞ —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É—á–∏—Ç—ã–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–∞ –∏ —É—Å–ª–æ–≤–∏—è —Å–¥–µ–ª–∫–∏, –∞ —Ç–∞–∫–∂–µ –ø—Ä–∞–≤–æ–≤—É—é –ø—Ä–∏—Ä–æ–¥—É –æ—Ç–Ω–æ—à–µ–Ω–∏–π –º–µ–∂–¥—É —Å—Ç–æ—Ä–æ–Ω–∞–º–∏. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É –≤ –æ–±–ª–∞—Å—Ç–∏ –Ω–∞–ª–æ–≥–æ–≤–æ–≥–æ\n",
      "--------------------------------------------------\n",
      "–ö—É—Ä—á–∞—Ç–æ–≤ –ò–≥–æ—Ä—å –í–∞—Å–∏–ª—å–µ–≤–∏—á (1902‚Äì1960) ‚Äî —Å–æ–≤–µ—Ç—Å–∫–∏–π —Ñ–∏–∑–∏–∫, –∞–∫–∞–¥–µ–º–∏–∫ –ê–ù –°–°–°–† (1943), –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä –∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Ä–∞–±–æ—Ç –ø–æ –∞—Ç–æ–º–Ω–æ–π –Ω–∞—É–∫–µ –∏ —Ç–µ—Ö–Ω–∏–∫–µ –≤ –°–°–°–†, –æ—Å–Ω–æ–≤–∞—Ç–µ–ª—å –∏ –ø–µ—Ä–≤—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –ò–Ω—Å—Ç–∏—Ç—É—Ç–∞ –∞—Ç–æ–º–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–∏ (1943).\n",
      "\n",
      "–ö—É—Ä—á–∞—Ç–æ–≤ —Ä–æ–¥–∏–ª—Å—è –≤ –ø–æ—Å—ë–ª–∫–µ –°–∏–º (–Ω—ã–Ω–µ ‚Äî –≥–æ—Ä–æ–¥ –°–∏–º, –ß–µ–ª—è–±–∏–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å) –≤ —Å–µ–º—å–µ –ø–æ–º–æ—â–Ω–∏–∫–∞ –ª–µ—Å–Ω–∏—á–µ–≥–æ. –ü–æ—Å–ª–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è —à–∫–æ–ª—ã –≤ 1919 –≥–æ–¥—É —Ä–∞–±–æ—Ç–∞–ª —Å–Ω–∞—á–∞–ª–∞ —É—á–∏—Ç–µ–ª–µ–º, –∑–∞—Ç–µ–º —á–µ—Ä—Ç—ë–∂–Ω–∏–∫–æ–º, —Ä–∞—Å—á—ë—Ç—á–∏–∫–æ–º, –∏–Ω–∂–µ–Ω–µ—Ä–æ–º –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è—Ö.\n",
      "\n",
      "–í 1923 –≥–æ–¥—É –ö—É—Ä—á–∞—Ç–æ–≤ –ø–æ—Å—Ç—É–ø–∏–ª –≤ –ü–µ—Ç—Ä–æ–≥—Ä–∞–¥—Å–∫–∏–π –ø–æ–ª–∏—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∏–Ω—Å—Ç–∏—Ç—É—Ç, –≥–¥–µ –Ω–∞—á–∞–ª –∑–∞–Ω–∏–º–∞—Ç—å—Å—è —Ñ–∏–∑–∏–∫–æ–π –ø–æ–¥ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º –∞–∫–∞–¥–µ–º–∏–∫–∞ –ê. –§. –ò–æ—Ñ—Ñ–µ. –í 1930 –≥–æ–¥—É –æ–Ω –±—ã–ª –ø—Ä–∏–≥–ª–∞—à—ë–Ω –Ω–∞ —Ä–∞–±–æ—Ç—É –≤ –õ–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∏–π —Ñ–∏–∑–∏–∫–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∏–Ω—Å—Ç–∏—Ç—É—Ç, –≥–¥–µ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–ª –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—é —è–¥–µ—Ä–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –∏ –≤—ë–ª —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—É—é —Ä–∞–±–æ—Ç—É –ø–æ —Ñ–∏–∑–∏–∫–µ —Ç–≤—ë—Ä–¥–æ–≥–æ —Ç–µ–ª–∞.\n",
      "\n",
      "–í 1932 –≥–æ–¥—É –ö—É—Ä—á–∞—Ç–æ–≤ –Ω–∞—á–∞–ª –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ —Ä–∞—Å—â–µ–ø–ª–µ–Ω–∏—é —è–¥—Ä–∞. –í 1935 –≥–æ–¥—É –≤–º–µ—Å—Ç–µ —Å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º–∏ –≤–ø–µ—Ä–≤—ã–µ –≤ –°–°–°–† —Ä–∞—Å—â–µ–ø–∏–ª–∏ —è–¥—Ä–æ –∞—Ç–æ–º–∞ –ª–∏—Ç–∏—è.\n",
      "\n",
      "–° –Ω–∞—á–∞–ª–æ–º –í–µ–ª–∏–∫–æ–π –û—Ç–µ—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –≤–æ–π–Ω—ã –ö—É—Ä—á–∞—Ç–æ–≤ –Ω–∞—á–∞–ª —Ä–∞–±–æ—Ç—É –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –∞—Ç–æ–º–Ω–æ–π –±–æ–º–±—ã. –í 1942 –≥–æ–¥—É –æ–Ω –≤–æ–∑–≥–ª–∞–≤–∏–ª –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—é, –∫–æ—Ç–æ—Ä–∞—è –∑–∞–Ω–∏–º–∞–ª–∞—Å—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–æ–π —è–¥–µ—Ä–Ω–æ–≥–æ –æ—Ä—É–∂–∏—è. –í 1945 –≥–æ–¥—É –ø–æ–¥ –µ–≥–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º –±—ã–ª –∑–∞–ø—É—â–µ–Ω –ø–µ—Ä–≤—ã–π —Å–æ–≤–µ—Ç—Å–∫–∏–π —Ü–∏–∫–ª–æ—Ç—Ä–æ–Ω ‚Äî –ø–µ—Ä–≤—ã–π –≤ –ï–≤—Ä–æ–ø–µ –∞—Ç–æ–º–Ω—ã–π —Ä–µ–∞–∫—Ç–æ—Ä. –í 1946 –≥–æ–¥—É –±—ã–ª –∑–∞–ø—É—â–µ–Ω –ø–µ—Ä–≤—ã–π –≤ –ï–≤—Ä–æ–ø–µ –∞—Ç–æ–º–Ω—ã–π —Ä–µ–∞–∫—Ç–æ—Ä –§-1.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for text in prompts_for_test:\n",
    "    print(generate_answer_correct(text))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20343904-1c95-40b4-9608-916bb205d43d",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8697d42d-d783-42dc-b25e-3fd396b56b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs type: <class 'int'>\n",
      "Attention mask type: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Input IDs type:\", type(tokenized_dataset[0][\"input_ids\"][0]))\n",
    "print(\"Attention mask type:\", type(tokenized_dataset[0][\"attention_mask\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c06dc27-afa2-4ede-8e20-46870b13ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "eval_dataset = dataset_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea396750-153e-4bf2-b6a4-474bb4563d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./yandexgpt-lora-finetuned\",\n",
    "    per_device_train_batch_size=1, #2,\n",
    "    per_device_eval_batch_size=1, #2,\n",
    "    gradient_accumulation_steps=8, #4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=1, #3,\n",
    "    \n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=5,           # –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–µ 5 —à–∞–≥–æ–≤\n",
    "    logging_first_step=True,   # –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–≤—ã–π —à–∞–≥\n",
    "    logging_strategy=\"steps\",  # –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –ø–æ —à–∞–≥–∞–º\n",
    "    \n",
    "    eval_strategy=\"steps\",  # –û—Ü–µ–Ω–∫–∞ –ø–æ —à–∞–≥–∞–º –≤–º–µ—Å—Ç–æ —ç–ø–æ—Ö\n",
    "    eval_steps=50,               # –û—Ü–µ–Ω–∏–≤–∞—Ç—å –∫–∞–∂–¥—ã–µ 50 —à–∞–≥–æ–≤\n",
    "\n",
    "    log_level=\"info\",           # –ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "    disable_tqdm=False,         # –í–∫–ª—é—á–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä\n",
    "    \n",
    "    save_strategy=\"steps\",       # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ø–æ —à–∞–≥–∞–º\n",
    "    save_steps=100,              # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–∞–∂–¥—ã–µ 100 —à–∞–≥–æ–≤\n",
    "    save_total_limit=1,\n",
    "    \n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    optim=\"paged_adamw_8bit\",       # –í–∞–∂–Ω–æ –¥–ª—è QLoRA\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fe6a9ba-ab7a-4d64-8371-761db18c74eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n",
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False), # CustomDataCollator(tokenizer, mlm=False), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b7f0661-1b84-4bd8-92b8-ad6c1d4b6b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config._attn_implementation = \"eager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea620b50-2774-4c84-a6b5-b0d0827bea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "485034b9-7c00-476b-9253-e472dc1f69d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=2.86GB, reserved=4.15GB, peak=3.79GB\n",
      "NVML used=5.33GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e78705e-2304-4dbe-aa2e-43a4f7bbd27a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipped Embedding(129024, 4096): 504.0M params\n",
      "skipped: 504.0M params\n",
      "***** Running training *****\n",
      "  Num examples = 8,915\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 1,115\n",
      "  Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1115' max='1115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1115/1115 14:09:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.129100</td>\n",
       "      <td>1.239659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.132100</td>\n",
       "      <td>1.199858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.196600</td>\n",
       "      <td>1.190117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.189400</td>\n",
       "      <td>1.185444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.102200</td>\n",
       "      <td>1.181259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.158700</td>\n",
       "      <td>1.177102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.161700</td>\n",
       "      <td>1.174204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.004000</td>\n",
       "      <td>1.171757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>1.170132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.166675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.156100</td>\n",
       "      <td>1.165008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.032400</td>\n",
       "      <td>1.162337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.087700</td>\n",
       "      <td>1.161175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.033900</td>\n",
       "      <td>1.158879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>1.157367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.091300</td>\n",
       "      <td>1.156302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.972900</td>\n",
       "      <td>1.155033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.178800</td>\n",
       "      <td>1.153673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.088700</td>\n",
       "      <td>1.152290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.079200</td>\n",
       "      <td>1.151331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.988400</td>\n",
       "      <td>1.150913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.121400</td>\n",
       "      <td>1.150435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./yandexgpt-lora-finetuned/checkpoint-100\n",
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 129024\n",
      "}\n",
      "\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "chat template saved in ./yandexgpt-lora-finetuned/checkpoint-100/chat_template.jinja\n",
      "tokenizer config file saved in ./yandexgpt-lora-finetuned/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in ./yandexgpt-lora-finetuned/checkpoint-100/special_tokens_map.json\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./yandexgpt-lora-finetuned/checkpoint-200\n",
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 129024\n",
      "}\n",
      "\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "chat template saved in ./yandexgpt-lora-finetuned/checkpoint-200/chat_template.jinja\n",
      "tokenizer config file saved in ./yandexgpt-lora-finetuned/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in ./yandexgpt-lora-finetuned/checkpoint-200/special_tokens_map.json\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./yandexgpt-lora-finetuned/checkpoint-300\n",
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 129024\n",
      "}\n",
      "\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "chat template saved in ./yandexgpt-lora-finetuned/checkpoint-300/chat_template.jinja\n",
      "tokenizer config file saved in ./yandexgpt-lora-finetuned/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in ./yandexgpt-lora-finetuned/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [yandexgpt-lora-finetuned/checkpoint-100] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./yandexgpt-lora-finetuned/checkpoint-400\n",
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 129024\n",
      "}\n",
      "\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "chat template saved in ./yandexgpt-lora-finetuned/checkpoint-400/chat_template.jinja\n",
      "tokenizer config file saved in ./yandexgpt-lora-finetuned/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in ./yandexgpt-lora-finetuned/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [yandexgpt-lora-finetuned/checkpoint-200] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./yandexgpt-lora-finetuned/checkpoint-500\n",
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 129024\n",
      "}\n",
      "\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "chat template saved in ./yandexgpt-lora-finetuned/checkpoint-500/chat_template.jinja\n",
      "tokenizer config file saved in ./yandexgpt-lora-finetuned/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./yandexgpt-lora-finetuned/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [yandexgpt-lora-finetuned/checkpoint-300] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./yandexgpt-lora-finetuned/checkpoint-600\n",
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 129024\n",
      "}\n",
      "\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "chat template saved in ./yandexgpt-lora-finetuned/checkpoint-600/chat_template.jinja\n",
      "tokenizer config file saved in ./yandexgpt-lora-finetuned/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in ./yandexgpt-lora-finetuned/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [yandexgpt-lora-finetuned/checkpoint-400] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./yandexgpt-lora-finetuned/checkpoint-700\n",
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 129024\n",
      "}\n",
      "\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "chat template saved in ./yandexgpt-lora-finetuned/checkpoint-700/chat_template.jinja\n",
      "tokenizer config file saved in ./yandexgpt-lora-finetuned/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in ./yandexgpt-lora-finetuned/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [yandexgpt-lora-finetuned/checkpoint-500] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./yandexgpt-lora-finetuned/checkpoint-800\n",
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 129024\n",
      "}\n",
      "\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "chat template saved in ./yandexgpt-lora-finetuned/checkpoint-800/chat_template.jinja\n",
      "tokenizer config file saved in ./yandexgpt-lora-finetuned/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in ./yandexgpt-lora-finetuned/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [yandexgpt-lora-finetuned/checkpoint-600] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./yandexgpt-lora-finetuned/checkpoint-900\n",
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 129024\n",
      "}\n",
      "\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "chat template saved in ./yandexgpt-lora-finetuned/checkpoint-900/chat_template.jinja\n",
      "tokenizer config file saved in ./yandexgpt-lora-finetuned/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in ./yandexgpt-lora-finetuned/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [yandexgpt-lora-finetuned/checkpoint-700] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./yandexgpt-lora-finetuned/checkpoint-1000\n",
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 129024\n",
      "}\n",
      "\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "chat template saved in ./yandexgpt-lora-finetuned/checkpoint-1000/chat_template.jinja\n",
      "tokenizer config file saved in ./yandexgpt-lora-finetuned/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./yandexgpt-lora-finetuned/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [yandexgpt-lora-finetuned/checkpoint-800] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 991\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./yandexgpt-lora-finetuned/checkpoint-1100\n",
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 129024\n",
      "}\n",
      "\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "chat template saved in ./yandexgpt-lora-finetuned/checkpoint-1100/chat_template.jinja\n",
      "tokenizer config file saved in ./yandexgpt-lora-finetuned/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in ./yandexgpt-lora-finetuned/checkpoint-1100/special_tokens_map.json\n",
      "Deleting older checkpoint [yandexgpt-lora-finetuned/checkpoint-900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./yandexgpt-lora-finetuned/checkpoint-1115\n",
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 129024\n",
      "}\n",
      "\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "chat template saved in ./yandexgpt-lora-finetuned/checkpoint-1115/chat_template.jinja\n",
      "tokenizer config file saved in ./yandexgpt-lora-finetuned/checkpoint-1115/tokenizer_config.json\n",
      "Special tokens file saved in ./yandexgpt-lora-finetuned/checkpoint-1115/special_tokens_map.json\n",
      "Deleting older checkpoint [yandexgpt-lora-finetuned/checkpoint-1000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./yandexgpt-lora-finetuned/checkpoint-1100 (score: 1.150435209274292).\n",
      "Deleting older checkpoint [yandexgpt-lora-finetuned/checkpoint-1115] due to args.save_total_limit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1115, training_loss=1.080232146930267, metrics={'train_runtime': 51017.2504, 'train_samples_per_second': 0.175, 'train_steps_per_second': 0.022, 'total_flos': 8.270852483186688e+17, 'train_loss': 1.080232146930267, 'epoch': 1.0})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93a3e3bc-4a99-4502-9a23-c6c5a625bbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=2.87GB, reserved=7.30GB, peak=5.41GB\n",
      "NVML used=8.58GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89e91db9-cc43-4edc-9b05-0ee8fb95ca9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./yandexgpt-lora-finetuned\n",
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 129024\n",
      "}\n",
      "\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "chat template saved in ./yandexgpt-lora-finetuned/chat_template.jinja\n",
      "tokenizer config file saved in ./yandexgpt-lora-finetuned/tokenizer_config.json\n",
      "Special tokens file saved in ./yandexgpt-lora-finetuned/special_tokens_map.json\n",
      "chat template saved in ./yandexgpt-lora-finetuned/chat_template.jinja\n",
      "tokenizer config file saved in ./yandexgpt-lora-finetuned/tokenizer_config.json\n",
      "Special tokens file saved in ./yandexgpt-lora-finetuned/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./yandexgpt-lora-finetuned/tokenizer_config.json',\n",
       " './yandexgpt-lora-finetuned/special_tokens_map.json',\n",
       " './yandexgpt-lora-finetuned/chat_template.jinja',\n",
       " './yandexgpt-lora-finetuned/tokenizer.model',\n",
       " './yandexgpt-lora-finetuned/added_tokens.json')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(\"./yandexgpt-lora-finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d6c27-2e80-4afb-b73a-a37deaf073ef",
   "metadata": {},
   "source": [
    "### –û—Ü–µ–Ω–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11c2bebc-aff7-46ae-aa94-0978997240ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=2.87GB, reserved=7.30GB, peak=5.41GB\n",
      "NVML used=8.59GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a63e4c00-1cca-4ebb-9030-a4d33aa68f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è 4-–±–∏—Ç–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ (—Ç–∞–∫–∞—è –∂–µ –∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5321a252-3732-4eb5-a69d-ef81881da2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/config.json\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 129024\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/model.safetensors.index.json\n",
      "Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n",
      "target_dtype {target_dtype} is replaced by `CustomDtype.INT4` for 4-bit BnB quantization\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:07<00:00,  1.77s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at yandex/YandexGPT-5-Lite-8B-instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"temperature\": 0.3,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"yandex/YandexGPT-5-Lite-8B-instruct\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe369f62-ff0b-4ab4-9fa7-ede6a261bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file tokenizer.model from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/tokenizer.model\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/viv232/.cache/huggingface/hub/models--yandex--YandexGPT-5-Lite-8B-instruct/snapshots/b556811768376b46c69caab60c4d1b69df9faaa1/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file chat_template.jinja from cache at None\n"
     ]
    }
   ],
   "source": [
    "tokenizer_lr = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    use_fast=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b952e542-0364-461c-a3da-76573d15c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer_lr.pad_token is None:\n",
    "    tokenizer_lr.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "90f7aeaa-9886-46d1-8184-1eec818fd3c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(129024, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=129024, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_adapter_path = \"./yandexgpt-lora-finetuned\"  # –ø—É—Ç—å –∫ –≤–∞—à–µ–º—É –∞–¥–∞–ø—Ç–µ—Ä—É\n",
    "model_lr = PeftModel.from_pretrained(base_model, lora_adapter_path)\n",
    "model_lr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "49b03022-3eee-45fe-b598-053b0324a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_correct_lr(prompt):\n",
    "    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç\n",
    "    user_prompt = f\"<s> –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {prompt} –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:\"\n",
    "    \n",
    "    inputs = tokenizer_lr(\n",
    "        user_prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=1024\n",
    "    ).to(model_lr.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model_lr.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=300,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer_lr.pad_token_id,\n",
    "            eos_token_id=tokenizer_lr.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é —á–∞—Å—Ç—å\n",
    "    generated = outputs[0][inputs.input_ids.shape[1]:]\n",
    "    response = tokenizer_lr.decode(generated, skip_special_tokens=True)\n",
    "    \n",
    "    # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–π [SEP] –≤ –∫–æ–Ω—Ü–µ\n",
    "    response = response.replace(\"[SEP]\", \"\").strip()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6be28a66-517a-4810-a20a-88bf2a0be2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=8.36GB, reserved=12.34GB, peak=8.51GB\n",
      "NVML used=13.66GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d20be388-a445-47d5-a595-64e02d7da11f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–ª—è –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è –≤–∫—É—Å–Ω–æ–π –∏–Ω–¥–µ–π–∫–∏ –Ω–∞ –≥—Ä–∏–ª–µ –≤–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è —Å–ª–µ–¥–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º —à–∞–≥–∞–º. –í–æ—Ç –ø—Ä–æ—Å—Ç–æ–π —Ä–µ—Ü–µ–ø—Ç –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è –∏–Ω–¥–µ–π–∫–∏ –Ω–∞ –≥—Ä–∏–ª–µ:\n",
      "\n",
      "### –ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã:\n",
      "- –ò–Ω–¥–µ–π–∫–∞ (–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ —Ñ–∏–ª–µ) ‚Äì 1 –∫–≥\n",
      "- –°–æ–ª—å ‚Äì –ø–æ –≤–∫—É—Å—É\n",
      "- –ß–µ—Ä–Ω—ã–π –ø–µ—Ä–µ—Ü ‚Äì –ø–æ –≤–∫—É—Å—É\n",
      "- –ü—Ä–∏–ø—Ä–∞–≤–∞ –¥–ª—è –ø—Ç–∏—Ü—ã ‚Äì –ø–æ –≤–∫—É—Å—É\n",
      "- –û–ª–∏–≤–∫–æ–≤–æ–µ –º–∞—Å–ª–æ ‚Äì –¥–ª—è —Å–º–∞–∑—ã–≤–∞–Ω–∏—è\n",
      "\n",
      "### –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:\n",
      "\n",
      "#### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω–¥–µ–π–∫–∏:\n",
      "1. **–†–∞–∑–º–æ—Ä–æ–∑—å—Ç–µ –∏–Ω–¥–µ–π–∫—É** (–µ—Å–ª–∏ –æ–Ω–∞ –∑–∞–º–æ—Ä–æ–∂–µ–Ω–∞), –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ.\n",
      "2. **–ù–∞—Ä–µ–∂—å—Ç–µ –∏–Ω–¥–µ–π–∫—É** –Ω–∞ –ø–æ—Ä—Ü–∏–æ–Ω–Ω—ã–µ –∫—É—Å–æ—á–∫–∏.\n",
      "3. **–°–º–µ—à–∞–π—Ç–µ —Å–ø–µ—Ü–∏–∏ —Å –º–∞—Å–ª–æ–º**: –≤ –≥–ª—É–±–æ–∫–æ–π –º–∏—Å–∫–µ —Å–º–µ—à–∞–π—Ç–µ —Å–æ–ª—å, –ø–µ—Ä–µ—Ü, –ø—Ä–∏–ø—Ä–∞–≤—É –¥–ª—è –ø—Ç–∏—Ü—ã –∏ –Ω–µ–º–Ω–æ–≥–æ –æ–ª–∏–≤–∫–æ–≤–æ–≥–æ –º–∞—Å–ª–∞.\n",
      "4. **–ú–∞—Ä–∏–Ω—É–π—Ç–µ –∏–Ω–¥–µ–π–∫—É**: –ø–æ–ª–æ–∂–∏—Ç–µ –∫—É—Å–æ—á–∫–∏ –∏–Ω–¥–µ–π–∫–∏ –≤ –º–∏—Å–∫—É —Å–æ —Å–º–µ—Å—å—é —Å–ø–µ—Ü–∏–π –∏ —Ö–æ—Ä–æ—à–æ –ø–µ—Ä–µ–º–µ—à–∞–π—Ç–µ, —á—Ç–æ–±—ã –∫–∞–∂–¥—ã–π –∫—É—Å–æ—á–µ–∫ –±—ã–ª –ø–æ–∫—Ä—ã—Ç –º–∞—Ä–∏–Ω–∞–¥–æ–º. –û—Å—Ç–∞–≤—å—Ç–µ –º–∞—Ä–∏–Ω–æ–≤–∞—Ç—å—Å—è –Ω–∞ 30 –º–∏–Ω—É—Ç.\n",
      "\n",
      "#### –ì—Ä–∏–ª—å:\n",
      "1. **–†–∞–∑–æ–≥—Ä–µ–π—Ç–µ –≥—Ä–∏–ª—å**: –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–æ–≥—Ä–µ–π—Ç–µ –≥—Ä–∏–ª—å –¥–æ —Å—Ä–µ–¥–Ω–µ–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã.\n",
      "2. **–°–º–∞–∂—å—Ç–µ —Ä–µ—à–µ—Ç–∫—É –≥—Ä–∏–ª—è**: —Å–º–∞–∂—å—Ç–µ —Ä–µ—à–µ—Ç–∫—É –≥—Ä–∏–ª—è –æ–ª–∏–≤–∫–æ–≤—ã–º –º–∞—Å–ª–æ–º, —á—Ç–æ–±—ã –∏–Ω–¥–µ–π–∫–∞ –Ω–µ –ø—Ä–∏–ª–∏–ø–∞–ª–∞.\n",
      "3. **–ñ–∞—Ä—å—Ç–µ –∏–Ω–¥–µ–π–∫—É**: –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –≤—ã–ª–æ–∂–∏—Ç–µ –º–∞—Ä–∏–Ω–æ–≤–∞–Ω–Ω—ã–µ –∫—É—Å–æ—á–∫–∏ –∏–Ω–¥–µ–π–∫–∏ –Ω–∞ –≥—Ä–∏–ª—å. –ñ–∞—Ä—å—Ç–µ —Å –∫–∞–∂–¥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã –ø—Ä–∏–º–µ—Ä–Ω–æ –ø–æ 5-7 –º–∏–Ω—É—Ç, –ø–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞—è, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—É—é –∑–æ–ª–æ—Ç–∏—Å—Ç—É—é –∫–æ—Ä–æ—á–∫—É.\n",
      "4. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å**: –∏–Ω–¥–µ–π–∫–∞ –≥–æ—Ç–æ–≤–∞, –∫–æ–≥–¥–∞ –µ—ë –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç 75 –≥—Ä–∞–¥—É—Å–æ–≤ –¶–µ–ª—å—Å–∏—è –∏–ª–∏\n",
      "--------------------------------------------------\n",
      "–ò–Ω—Å—É–ª—å—Ç ‚Äì —ç—Ç–æ –æ—Å—Ç—Ä–æ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ –º–æ–∑–≥–æ–≤–æ–≥–æ –∫—Ä–æ–≤–æ–æ–±—Ä–∞—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —Å–µ—Ä—å–µ–∑–Ω—ã–º –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è–º. –í–∞–∂–Ω–æ —É–º–µ—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–∏–±–ª–∏–∂–∞—é—â–µ–≥–æ—Å—è –∏–Ω—Å—É–ª—å—Ç–∞, —á—Ç–æ–±—ã –≤–æ–≤—Ä–µ–º—è –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∑–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –ø–æ–º–æ—â—å—é. –í–æ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ —Å–ª–µ–¥—É–µ—Ç –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ:\n",
      "\n",
      "1. **–°–ª–∞–±–æ—Å—Ç—å –∏–ª–∏ –æ–Ω–µ–º–µ–Ω–∏–µ** –≤ –ª–∏—Ü–µ, —Ä—É–∫–µ –∏–ª–∏ –Ω–æ–≥–µ, –æ—Å–æ–±–µ–Ω–Ω–æ –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω–µ —Ç–µ–ª–∞.\n",
      "2. **–°–ø—É—Ç–∞–Ω–Ω–æ—Å—Ç—å —Å–æ–∑–Ω–∞–Ω–∏—è** –∏–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å —Ä–µ—á—å—é, –≤–∫–ª—é—á–∞—è –≤–Ω–µ–∑–∞–ø–Ω–æ–µ –∑–∞—Ç—Ä—É–¥–Ω–µ–Ω–∏–µ –≤ –ø–æ–¥–±–æ—Ä–µ —Å–ª–æ–≤ –∏–ª–∏ –ø–æ–Ω–∏–º–∞–Ω–∏–∏ —Ä–µ—á–∏.\n",
      "3. **–ü—Ä–æ–±–ª–µ–º—ã —Å–æ –∑—Ä–µ–Ω–∏–µ–º**, —Ç–∞–∫–∏–µ –∫–∞–∫ –≤–Ω–µ–∑–∞–ø–Ω–æ–µ —É—Ö—É–¥—à–µ–Ω–∏–µ –∑—Ä–µ–Ω–∏—è –≤ –æ–¥–Ω–æ–º –∏–ª–∏ –æ–±–æ–∏—Ö –≥–ª–∞–∑–∞—Ö, –¥–≤–æ–µ–Ω–∏–µ –≤ –≥–ª–∞–∑–∞—Ö.\n",
      "4. **–ì–æ–ª–æ–≤–Ω–∞—è –±–æ–ª—å**, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–∏–ª—å–Ω–æ–π –∏ –≤–Ω–µ–∑–∞–ø–Ω–æ–π, –Ω–µ –ø–æ—Ö–æ–∂–∞—è –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ.\n",
      "5. **–¢—Ä—É–¥–Ω–æ—Å—Ç–∏ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–µ–π** –∏ —Ä–∞–≤–Ω–æ–≤–µ—Å–∏–µ–º, –≤–Ω–µ–∑–∞–ø–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å —Ö–æ–¥—å–±–æ–π.\n",
      "6. **–ü–æ—Ç–µ—Ä—è —Å–æ–∑–Ω–∞–Ω–∏—è** –∏–ª–∏ –∫—Ä–∞—Ç–∫–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏ —Å–æ–∑–Ω–∞–Ω–∏—è.\n",
      "\n",
      "–ï—Å–ª–∏ –≤—ã –∑–∞–º–µ—Ç–∏–ª–∏ —É —Å–µ–±—è –∏–ª–∏ —É –∫–æ–≥–æ-—Ç–æ –∏–∑ –≤–∞—à–µ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑ —ç—Ç–∏—Ö —Å–∏–º–ø—Ç–æ–º–æ–≤, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å—Ä–æ—á–Ω–æ –≤—ã–∑–≤–∞—Ç—å —Å–∫–æ—Ä—É—é –ø–æ–º–æ—â—å. –ù–µ –∏–≥–Ω–æ—Ä–∏—Ä—É–π—Ç–µ —ç—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–æ–º–µ–¥–ª–µ–Ω–∏–µ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ–æ–±—Ä–∞—Ç–∏–º—ã–º –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è–º.\n",
      "\n",
      "–ü–æ–º–Ω–∏—Ç–µ, —á—Ç–æ —á–µ–º —Ä–∞–Ω—å—à–µ –Ω–∞—á–∞—Ç–æ –ª–µ—á–µ–Ω–∏–µ –∏–Ω—Å—É–ª—å—Ç–∞, —Ç–µ–º –±–æ–ª—å—à–µ —à–∞–Ω—Å–æ–≤ –Ω–∞ –ø–æ–ª–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ.\n",
      "--------------------------------------------------\n",
      "–û—Å–Ω–æ–≤–Ω—ã–µ –∫–∞–Ω–æ–Ω—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥—Ä–µ–≤–Ω–∏—Ö —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–π - —ç—Ç–æ –ø—Ä–∞–≤–∏–ª–∞ –∏ –ø—Ä–∏–Ω—Ü–∏–ø—ã, –∫–æ—Ç–æ—Ä—ã–º–∏ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–≤–∞–ª–∏—Å—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä—ã –∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª–∏ –≤ —Å–æ–∑–¥–∞–Ω–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö —Å–æ–æ—Ä—É–∂–µ–Ω–∏–π. –≠—Ç–∏ –∫–∞–Ω–æ–Ω—ã –≤–∞—Ä—å–∏—Ä–æ–≤–∞–ª–∏—Å—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫—É–ª—å—Ç—É—Ä–Ω–æ–≥–æ –∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∫–∞–∂–¥–æ–π —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–∏, –Ω–æ –º–æ–∂–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–±—â–∏—Ö —á–µ—Ä—Ç, –∫–æ—Ç–æ—Ä—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã –¥–ª—è –º–Ω–æ–≥–∏—Ö –¥—Ä–µ–≤–Ω–∏—Ö –∫—É–ª—å—Ç—É—Ä.\n",
      "\n",
      "### –ï–≥–∏–ø–µ—Ç\n",
      "1. **–°—Ç—Ä–æ–≥–∏–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏**: –ï–≥–∏–ø–µ—Ç—Å–∫–∏–µ —Ö—Ä–∞–º—ã –∏ –ø–∏—Ä–∞–º–∏–¥—ã —Å—Ç—Ä–æ–∏–ª–∏—Å—å —Å —Å–æ–±–ª—é–¥–µ–Ω–∏–µ–º —Å—Ç—Ä–æ–≥–∏—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–ø–æ—Ä—Ü–∏–π, —á—Ç–æ –ø—Ä–∏–¥–∞–≤–∞–ª–æ –∏–º –≤–µ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∏ –º–æ–Ω—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –≤–∏–¥.\n",
      "2. **–°–∏–º–º–µ—Ç—Ä–∏—è –∏ —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å**: –ï–≥–∏–ø–µ—Ç—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –æ—Ç–ª–∏—á–∞–ª–∞—Å—å —Å–∏–º–º–µ—Ç—Ä–∏–µ–π –∏ —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å—é —Ñ–æ—Ä–º, —á—Ç–æ –¥–µ–ª–∞–ª–æ –µ—ë —É–∑–Ω–∞–≤–∞–µ–º–æ–π.\n",
      "3. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–∞–º–Ω—è**: –ó–¥–∞–Ω–∏—è –≤–æ–∑–≤–æ–¥–∏–ª–∏—Å—å –∏–∑ –∫–∞–º–Ω—è, —á—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–ª–æ –∏—Ö –¥–æ–ª–≥–æ–≤–µ—á–Ω–æ—Å—Ç—å.\n",
      "4. **–ò–µ—Ä–æ–≥–ª–∏—Ñ—ã –∏ —Ä–µ–ª—å–µ—Ñ—ã**: –°—Ç–µ–Ω—ã —Ö—Ä–∞–º–æ–≤ –∏ –≥—Ä–æ–±–Ω–∏—Ü —É–∫—Ä–∞—à–∞–ª–∏—Å—å –∏–µ—Ä–æ–≥–ª–∏—Ñ–∞–º–∏ –∏ —Ä–µ–ª—å–µ—Ñ–∞–º–∏, —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞—é—â–∏–º–∏ –æ –∂–∏–∑–Ω–∏ —Ñ–∞—Ä–∞–æ–Ω–æ–≤ –∏ –±–æ–≥–æ–≤.\n",
      "\n",
      "### –ì—Ä–µ—Ü–∏—è\n",
      "1. **–ì–∞—Ä–º–æ–Ω–∏—è –∏ —Å–∏–º–º–µ—Ç—Ä–∏—è**: –ì—Ä–µ—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –≤–æ–ø–ª–æ—â–∞–ª–∞ –ø—Ä–∏–Ω—Ü–∏–ø—ã –≥–∞—Ä–º–æ–Ω–∏–∏ –∏ —Å–∏–º–º–µ—Ç—Ä–∏–∏, —á—Ç–æ –æ—Ç—Ä–∞–∂–∞–ª–æ –∏–¥–µ–∞–ª—ã –∫—Ä–∞—Å–æ—Ç—ã –∏ —Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–∞.\n",
      "2. **–î–æ—Ä–∏—á–µ—Å–∫–∏–π, –∏–æ–Ω–∏—á–µ—Å–∫–∏–π –∏ –∫–æ—Ä–∏–Ω—Ñ—Å–∫–∏–π –æ—Ä–¥–µ—Ä–∞**: –ì—Ä–µ—á–µ—Å–∫–∏–µ —Ö—Ä–∞–º—ã –∏ –∑–¥–∞–Ω–∏—è —Å—Ç—Ä–æ–∏–ª–∏—Å—å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –æ—Ä–¥–µ—Ä–æ–≤, –∫–∞–∂–¥—ã–π –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –∏–º–µ–ª —Å–≤–æ–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —á–µ—Ä—Ç—ã.\n",
      "3. **–°—Ç–∞—Ç—É–∏ –∏ —Å–∫—É–ª—å–ø—Ç—É—Ä–Ω—ã–µ —É–∫—Ä–∞—à–µ–Ω–∏—è**: –ó–¥–∞–Ω–∏—è —á–∞—Å—Ç–æ —É–∫—Ä–∞—à–∞–ª–∏—Å—å —Å—Ç–∞—Ç—É—è–º–∏ –∏ —Ä–µ–ª—å–µ—Ñ–∞–º–∏, –∏–∑–æ–±—Ä–∞–∂–∞—é—â–∏–º–∏ –±–æ–≥–æ–≤, –≥–µ—Ä–æ–µ–≤ –∏ –º–∏—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Å—Ü–µ–Ω—ã.\n",
      "4. **–ê–∫—Ä–æ–ø–æ–ª—å**: –í–∞–∂–Ω–æ–π —á–∞—Å—Ç—å—é –≥—Ä–µ—á–µ—Å–∫–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –±—ã–ª –∞–∫—Ä–æ–ø–æ–ª—å,\n",
      "--------------------------------------------------\n",
      "–í–æ–ø—Ä–æ—Å –æ –Ω–∞–ª–æ–≥–æ–æ–±–ª–æ–∂–µ–Ω–∏–∏ —Å—É–º–º –ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –¥–æ–ª–≥–∞ –ø–æ –∑–∞–π–º—É –æ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, –≤ –∫–æ—Ç–æ—Ä–æ–π —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–Ω—ã–π, —Å–≤—è–∑–∞–Ω —Å –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—è–º–∏ –Ω–∞–ª–æ–≥–æ–æ–±–ª–æ–∂–µ–Ω–∏—è –≤ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏. –†–∞—Å—Å–º–æ—Ç—Ä–∏–º —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å –ø–æ—à–∞–≥–æ–≤–æ.\n",
      "\n",
      "1. **–ü—Ä–æ—â–µ–Ω–∏–µ –¥–æ–ª–≥–∞ –∫–∞–∫ –¥–æ—Ö–æ–¥:**\n",
      "   –ü—Ä–æ—â–µ–Ω–∏–µ –¥–æ–ª–≥–∞ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –∫–∞–∫ –¥–æ—Ö–æ–¥, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π —Ñ–∏–∑–∏—á–µ—Å–∫–∏–º –ª–∏—Ü–æ–º, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–¥–ª–µ–∂–∏—Ç –Ω–∞–ª–æ–≥–æ–æ–±–ª–æ–∂–µ–Ω–∏—é. –≠—Ç–æ —Ä–µ–≥—É–ª–∏—Ä—É–µ—Ç—Å—è —Å—Ç–∞—Ç—å–µ–π 209 –ù–∞–ª–æ–≥–æ–≤–æ–≥–æ –∫–æ–¥–µ–∫—Å–∞ –†–§.\n",
      "\n",
      "2. **–ù–î–§–õ:**\n",
      "   –ü—Ä–æ—â–µ–Ω–Ω—ã–π –¥–æ–ª–≥ –ø–æ–¥–ª–µ–∂–∏—Ç –æ–±–ª–æ–∂–µ–Ω–∏—é –Ω–∞–ª–æ–≥–æ–º –Ω–∞ –¥–æ—Ö–æ–¥—ã —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –ª–∏—Ü (–ù–î–§–õ). –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Å—Ç–∞–≤–∫–∞ –ù–î–§–õ –¥–ª—è —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –ª–∏—Ü —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 13%, –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ –Ω–µ –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–æ –∏–Ω–æ–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è —Ä–µ–∑–∏–¥–µ–Ω—Ç–æ–≤ –†–§).\n",
      "\n",
      "3. **–°—Ç—Ä–∞—Ö–æ–≤—ã–µ –≤–∑–Ω–æ—Å—ã:**\n",
      "   –°—Ç—Ä–∞—Ö–æ–≤—ã–µ –≤–∑–Ω–æ—Å—ã - —ç—Ç–æ –ø–ª–∞—Ç–µ–∂–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å –¥–µ–ª–∞–µ—Ç –≤ –ø–æ–ª—å–∑—É —Ä–∞–±–æ—Ç–Ω–∏–∫–∞ –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –ø–µ–Ω—Å–∏–æ–Ω–Ω–æ–≥–æ, —Å–æ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ —Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏—è.\n",
      "\n",
      "4. **–°–≤—è–∑—å –ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –¥–æ–ª–≥–∞ –∏ —Å—Ç—Ä–∞—Ö–æ–≤—ã—Ö –≤–∑–Ω–æ—Å–æ–≤:**\n",
      "   –ü—Ä–æ—â–µ–Ω–Ω—ã–π –¥–æ–ª–≥ —Å–∞–º –ø–æ —Å–µ–±–µ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º –¥–ª—è –Ω–∞—á–∏—Å–ª–µ–Ω–∏—è —Å—Ç—Ä–∞—Ö–æ–≤—ã—Ö –≤–∑–Ω–æ—Å–æ–≤, —Ç–∞–∫ –∫–∞–∫ —Å—Ç—Ä–∞—Ö–æ–≤—ã–µ –≤–∑–Ω–æ—Å—ã –Ω–∞—á–∏—Å–ª—è—é—Ç—Å—è –Ω–∞ –¥–æ—Ö–æ–¥—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã –≤ —Ä–∞–º–∫–∞—Ö —Ç—Ä—É–¥–æ–≤—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π.\n",
      "\n",
      "5. **–ò—Å–∫–ª—é—á–µ–Ω–∏—è:**\n",
      "   –û–¥–Ω–∞–∫–æ, –µ—Å–ª–∏ –ø—Ä–æ—â–µ–Ω–∏–µ –¥–æ–ª–≥–∞ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—é —É—Å–ª–æ–≤–∏–π —Ç—Ä—É–¥–æ–≤—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞—Ä–ø–ª–∞—Ç—ã –∏–ª–∏ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏), —Ç–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–æ–≥—É—Ç –ø–æ–≤–ª–µ—á—å –∑–∞ —Å–æ–±–æ–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ—Ä–∞—Å—á–µ—Ç–∞ —Å—Ç—Ä–∞—Ö–æ–≤—ã—Ö –≤–∑–Ω–æ—Å–æ–≤.\n",
      "\n",
      "6. **–ó–∞–∫–ª—é—á–µ–Ω–∏–µ:**\n",
      "   –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –ø—Ä–æ—â–µ–Ω–∏–µ –¥–æ–ª–≥–∞ –ø–æ –∑–∞–π–º—É –æ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –Ω–µ –æ–±–ª–∞–≥–∞–µ—Ç—Å—è —Å—Ç—Ä–∞—Ö–æ–≤—ã–º–∏ –≤–∑–Ω–æ—Å–∞–º–∏, —Ç–∞–∫ –∫–∞–∫ —Å—Ç—Ä–∞—Ö–æ–≤—ã–µ –≤–∑–Ω–æ—Å—ã –Ω–∞—á–∏—Å–ª—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ –¥–æ—Ö–æ–¥—ã, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –≤ —Ä–∞–º–∫–∞—Ö —Ç—Ä—É–¥–æ–≤—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π. –û–¥–Ω–∞–∫–æ, –ø—Ä–æ—â–µ–Ω–Ω—ã–π –¥–æ–ª–≥ –ø–æ–¥–ª–µ–∂–∏—Ç –Ω–∞–ª–æ–≥–æ–æ–±–ª–æ–∂–µ–Ω–∏—é –ù–î–§–õ, –µ—Å–ª–∏ –æ–Ω –±—ã–ª –ø—Ä–∏–∑–Ω–∞–Ω –¥–æ—Ö–æ–¥–æ–º\n",
      "--------------------------------------------------\n",
      "–ò–≥–æ—Ä—å –í–∞—Å–∏–ª—å–µ–≤–∏—á –ö—É—Ä—á–∞—Ç–æ–≤ (1902‚Äì1960) –±—ã–ª –≤—ã–¥–∞—é—â–∏–º—Å—è —Å–æ–≤–µ—Ç—Å–∫–∏–º —Ñ–∏–∑–∏–∫–æ–º, –∫–æ—Ç–æ—Ä—ã–π —Å—ã–≥—Ä–∞–ª –∫–ª—é—á–µ–≤—É—é —Ä–æ–ª—å –≤ —Å–æ–∑–¥–∞–Ω–∏–∏ –∞—Ç–æ–º–Ω–æ–π –∏ –≤–æ–¥–æ—Ä–æ–¥–Ω–æ–π –±–æ–º–±, –∞ —Ç–∞–∫–∂–µ –≤ —Ä–∞–∑–≤–∏—Ç–∏–∏ –∞—Ç–æ–º–Ω–æ–π —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏ –≤ –°–°–°–†.\n",
      "\n",
      "### –†–∞–Ω–Ω–∏–µ –≥–æ–¥—ã –∏ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ\n",
      "–ò–≥–æ—Ä—å –ö—É—Ä—á–∞—Ç–æ–≤ —Ä–æ–¥–∏–ª—Å—è 12 —è–Ω–≤–∞—Ä—è 1902 –≥–æ–¥–∞ –≤ –°–∏–º–±–∏—Ä—Å–∫–µ (–Ω—ã–Ω–µ—à–Ω–∏–π –£–ª—å—è–Ω–æ–≤—Å–∫), –†–æ—Å—Å–∏—è. –û–Ω –ø–æ–ª—É—á–∏–ª –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ñ–∏–∑–∏–∫–æ-–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Ñ–∞–∫—É–ª—å—Ç–µ—Ç–µ –ö—Ä—ã–º—Å–∫–æ–≥–æ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞, –∞ –∑–∞—Ç–µ–º –≤ –õ–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–æ–º –ø–æ–ª–∏—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º –∏–Ω—Å—Ç–∏—Ç—É—Ç–µ.\n",
      "\n",
      "### –ù–∞—É—á–Ω–∞—è –∫–∞—Ä—å–µ—Ä–∞\n",
      "–ü–æ—Å–ª–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è —É—á–µ–±—ã –ö—É—Ä—á–∞—Ç–æ–≤ –Ω–∞—á–∞–ª —Å–≤–æ—é –Ω–∞—É—á–Ω—É—é –∫–∞—Ä—å–µ—Ä—É –≤ –æ–±–ª–∞—Å—Ç–∏ —Ñ–∏–∑–∏–∫–∏. –û–Ω —Ä–∞–±–æ—Ç–∞–ª –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –Ω–∞—É—á–Ω—ã—Ö –∏–Ω—Å—Ç–∏—Ç—É—Ç–∞—Ö –∏ –∑–∞–Ω–∏–º–∞–ª—Å—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º–∏ –≤ –æ–±–ª–∞—Å—Ç–∏ —è–¥–µ—Ä–Ω–æ–π —Ñ–∏–∑–∏–∫–∏.\n",
      "\n",
      "### –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ç–æ–º–Ω–æ–π –±–æ–º–±—ã\n",
      "–í 1940-—Ö –≥–æ–¥–∞—Ö –ö—É—Ä—á–∞—Ç–æ–≤ –≤–æ–∑–≥–ª–∞–≤–∏–ª —Ä–∞–±–æ—Ç—É –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –∞—Ç–æ–º–Ω–æ–π –±–æ–º–±—ã –≤ –°–°–°–†. –ü–æ–¥ –µ–≥–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º –±—ã–ª–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω—ã –∏ –ø—Ä–æ–≤–µ–¥–µ–Ω—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã, —á—Ç–æ –ø–æ–∑–≤–æ–ª–∏–ª–æ –°–°–°–† —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–≤–µ—Å—Ç–∏ –ø–µ—Ä–≤–æ–µ –∏—Å–ø—ã—Ç–∞–Ω–∏–µ –∞—Ç–æ–º–Ω–æ–π –±–æ–º–±—ã –≤ 1949 –≥–æ–¥—É.\n",
      "\n",
      "### –°–æ–∑–¥–∞–Ω–∏–µ –≤–æ–¥–æ—Ä–æ–¥–Ω–æ–π –±–æ–º–±—ã\n",
      "–í 1950-—Ö –≥–æ–¥–∞—Ö –ö—É—Ä—á–∞—Ç–æ–≤ —Ç–∞–∫–∂–µ —Ä—É–∫–æ–≤–æ–¥–∏–ª —Ä–∞–±–æ—Ç–∞–º–∏ –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –≤–æ–¥–æ—Ä–æ–¥–Ω–æ–π –±–æ–º–±—ã. –°–°–°–† —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–≤–µ–ª –ø–µ—Ä–≤–æ–µ –∏—Å–ø—ã—Ç–∞–Ω–∏–µ –≤–æ–¥–æ—Ä–æ–¥–Ω–æ–π –±–æ–º–±—ã –≤ 1953 –≥–æ–¥—É.\n",
      "\n",
      "### –†–∞–∑–≤–∏—Ç–∏–µ –∞—Ç–æ–º–Ω–æ–π —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏\n",
      "–ö—É—Ä—á–∞—Ç–æ–≤ —Ç–∞–∫–∂–µ –≤–Ω–µ—Å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –≤–∫–ª–∞–¥ –≤ —Ä–∞–∑–≤–∏—Ç–∏–µ –∞—Ç–æ–º–Ω–æ–π —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏ –≤ –°–°–°–†. –û–Ω –∞–∫—Ç–∏–≤–Ω–æ —É—á–∞—Å—Ç–≤–æ–≤–∞–ª –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–µ –ø–µ—Ä–≤—ã—Ö —Å–æ–≤–µ—Ç—Å–∫–∏—Ö –∞—Ç–æ–º–Ω—ã—Ö —ç–ª–µ–∫—Ç—Ä–æ—Å—Ç–∞–Ω—Ü–∏–π.\n",
      "\n",
      "### –°–º–µ—Ä—Ç—å –∏ –Ω–∞—Å–ª–µ–¥–∏–µ\n",
      "–ò–≥–æ—Ä—å –ö—É—Ä—á–∞—Ç–æ–≤ —Å–∫–æ–Ω—á–∞–ª—Å—è 7 —Ñ–µ–≤—Ä–∞–ª—è 1960 –≥–æ–¥–∞ –≤ –ú–æ—Å–∫–≤–µ. –ï–≥–æ –≤–∫–ª–∞–¥ –≤ —è–¥–µ—Ä–Ω—É—é —Ñ–∏–∑–∏\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for text in prompts_for_test:\n",
    "    print(generate_answer_correct_lr(text))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee0e83-e509-46ed-a1c5-9ac4ebd80440",
   "metadata": {},
   "source": [
    "# –î–æ–æ–±—É—á–µ–Ω–∏–µ —ç–Ω–∫–æ–¥–µ—Ä–∞ e5-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9b58575-aa3e-46f1-ab85-4c6668ea06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, random, math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, losses, models\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from bitsandbytes.optim import AdamW8bit\n",
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f15ef1d-4cd8-4c56-9243-02ec909c32df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d193c3b7-52b9-4db3-a366-2b62572a3a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e17bc5d-be16-4def-91c3-15a31f61e3c0",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2bdcb49b-4b52-4b78-b2a6-42a345b424db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45328/45328 [00:00<00:00, 614055.00 examples/s]\n",
      "Generating validation split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5036/5036 [00:00<00:00, 397121.87 examples/s]\n",
      "Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23936/23936 [00:00<00:00, 1033879.41 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pairs: 2000 | Val pairs: 500\n",
      "Sample train pair: ('–≥–¥–µ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –º–µ—Ç—Ä–æ–ø–æ–ª–∏—Ç–µ–Ω—ã —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã', '–ö—Ä–æ–º–µ —Ç–æ–≥–æ, –ú–∞–∫—Å–∏–º–æ–º –ì–æ—Ä—å–∫–∏–º –≤ –ì–æ—Ä–æ–¥–µ –ñ—ë–ª—Ç–æ–≥–æ –î—å—è–≤–æ–ª–∞ –±—ã–ª–æ –≤–≤–µ–¥–µ–Ω–æ –≤ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ —Å–ª–æ–≤–æ-–∫–∞–ª—å–∫–∞ –ø–æ–¥–∑–µ–º–∫–∞ . –û–Ω–æ –ø—Ä–∏–∂–∏–ª–æ—Å—å, –Ω–æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è –∑–∞—Ä—É–±–µ–∂–Ω—ã—Ö –º–µ—Ç—Ä–æ–ø–æ–ª–∏—Ç–µ–Ω–æ–≤ (–ª–æ–Ω–¥–æ–Ω—Å–∫–∞—è –ø–æ–¥–∑–µ–º–∫–∞, –Ω—å—é-–π–æ—Ä–∫—Å–∫–∞—è –ø–æ–¥–∑–µ–º–∫–∞ –∏ —Ç. –¥.), —Ö–æ—Ç—è –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ —Ä–æ—Å—Å–∏–π—Å–∫–æ–π –ø—Ä–µ—Å—Å–µ –∏ –ø—Ä–∏–º–µ–Ω–∏—Ç–µ–ª—å–Ω–æ –∫ —Ä–æ—Å—Å–∏–π—Å–∫–∏–º –º–µ—Ç—Ä–æ–ø–æ–ª–∏—Ç–µ–Ω–∞–º, –ø—Ä–æ–ª–æ–∂–µ–Ω–Ω—ã–º –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ–¥ –∑–µ–º–ª—ë–π. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —ç—Å—Ç–∞–∫–∞–¥–Ω—ã–µ –º–µ—Ç—Ä–æ–ø–æ–ª–∏—Ç–µ–Ω—ã –Ω–∞–∑—ã–≤–∞—é—Ç –Ω–∞–¥–∑–µ–º–∫–∞–º–∏ , –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ, —á—Ç–æ —Ç–∞–∫–∏—Ö –º–µ—Ç—Ä–æ–ø–æ–ª–∏—Ç–µ–Ω–æ–≤ –≤ –†–æ—Å—Å–∏–∏ –ø–æ–∫–∞ –µ—â—ë –Ω–µ—Ç.')\n"
     ]
    }
   ],
   "source": [
    "def extract_pairs(ds, max_samples=None, seed=42):\n",
    "    pairs = []\n",
    "    for ex in ds:\n",
    "        q = ex.get(\"question\")\n",
    "        pos = ex.get(\"context\")\n",
    "        pairs.append((q, pos))\n",
    "\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        random.shuffle(pairs)\n",
    "\n",
    "    if max_samples is not None:\n",
    "        pairs = pairs[:max_samples]\n",
    "    return pairs\n",
    "\n",
    "\n",
    "ds_train = load_dataset(\"kuznetsoffandrey/sberquad\", split=\"train[:2000]\")\n",
    "ds_val = load_dataset(\"kuznetsoffandrey/sberquad\", split=\"validation[:500]\")\n",
    "\n",
    "train_pairs = extract_pairs(ds_train)\n",
    "val_pairs   = extract_pairs(ds_val)\n",
    "\n",
    "print(f\"Train pairs: {len(train_pairs)} | Val pairs: {len(val_pairs)}\")\n",
    "print(\"Sample train pair:\", train_pairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b996a3-db2d-43e3-9d7c-80df487d544b",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "12ba2a2d-0a8c-45a8-9eac-21dd5142a972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--intfloat--multilingual-e5-large/snapshots/0dc5580a448e4284468b8909bae50fa925907bc5/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"dtype\": \"float32\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/viv232/.cache/huggingface/hub/models--intfloat--multilingual-e5-large/snapshots/0dc5580a448e4284468b8909bae50fa925907bc5/model.safetensors\n",
      "All model checkpoint weights were used when initializing XLMRobertaModel.\n",
      "\n",
      "All the weights of XLMRobertaModel were initialized from the model checkpoint at intfloat/multilingual-e5-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaModel for predictions without further training.\n",
      "loading file sentencepiece.bpe.model from cache at /home/viv232/.cache/huggingface/hub/models--intfloat--multilingual-e5-large/snapshots/0dc5580a448e4284468b8909bae50fa925907bc5/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /home/viv232/.cache/huggingface/hub/models--intfloat--multilingual-e5-large/snapshots/0dc5580a448e4284468b8909bae50fa925907bc5/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/viv232/.cache/huggingface/hub/models--intfloat--multilingual-e5-large/snapshots/0dc5580a448e4284468b8909bae50fa925907bc5/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/viv232/.cache/huggingface/hub/models--intfloat--multilingual-e5-large/snapshots/0dc5580a448e4284468b8909bae50fa925907bc5/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 7,110,656 || all params: 567,001,088 || trainable%: 1.2541\n"
     ]
    }
   ],
   "source": [
    "flush()\n",
    "\n",
    "base_name = \"intfloat/multilingual-e5-large\"\n",
    "st_model = SentenceTransformer(base_name, device=device)\n",
    "\n",
    "# –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–π AutoModel\n",
    "backbone = st_model[0].auto_model\n",
    "\n",
    "# –í–∫–ª—é—á–∞–µ–º gradient checkpointing\n",
    "if hasattr(backbone, \"gradient_checkpointing_enable\"):\n",
    "    backbone.gradient_checkpointing_enable()\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "    task_type=TaskType.FEATURE_EXTRACTION,\n",
    ")\n",
    "peft_backbone = get_peft_model(backbone, lora_cfg)\n",
    "peft_backbone.print_trainable_parameters()\n",
    "\n",
    "st_model[0].auto_model = peft_backbone\n",
    "\n",
    "loss_fn = losses.MultipleNegativesRankingLoss(st_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4bd646d8-bae5-4714-a959-180680825f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@5: 0.984\n"
     ]
    }
   ],
   "source": [
    "def embed(texts, model, batch_size=128, normalize=True):\n",
    "    vectors = model.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=normalize,\n",
    "        device=device,\n",
    "        show_progress_bar=False,\n",
    "    )\n",
    "    return vectors\n",
    "\n",
    "queries = [q for q,_ in val_pairs]\n",
    "docs    = [d for _,d in val_pairs]\n",
    "\n",
    "q_vecs = embed(queries, st_model)\n",
    "d_vecs = embed(docs, st_model)\n",
    "\n",
    "sims = np.matmul(q_vecs, d_vecs.T)\n",
    "k = min(5, sims.shape[1])\n",
    "topk_idx = np.argpartition(-sims, kth=k-1, axis=1)[:, :k]\n",
    "\n",
    "true_idx = np.arange(len(val_pairs))\n",
    "hits = (topk_idx == true_idx[:, None]).any(axis=1)\n",
    "hit5 = hits.mean()\n",
    "print(f\"Hit@5: {hit5:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c7351eb-e9fd-4020-9436-d31b7d797e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    {\n",
    "        \"anchor\": q,\n",
    "        \"positive\": d\n",
    "    }\n",
    "    for q, d in train_pairs\n",
    "]\n",
    "train_ds = Dataset.from_list(train_data)\n",
    "\n",
    "val_data = [\n",
    "    {\n",
    "        \"anchor\": q,\n",
    "        \"positive\": d\n",
    "    }\n",
    "    for q, d in val_pairs\n",
    "]\n",
    "val_ds = Dataset.from_list(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6df40986-1c11-4b4f-8462-1610ecc66bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "average_tokens_across_devices is True but world size is 1. Setting it to False automatically.\n",
      "Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n",
      "PyTorch: setting up devices\n",
      "average_tokens_across_devices is True but world size is 1. Setting it to False automatically.\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using auto half precision backend\n",
      "                                                                     "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 32\n",
    "gradient_accumulation_steps = 4\n",
    "max_steps_cap = 120\n",
    "warmup_ratio = 0.05\n",
    "\n",
    "steps_per_epoch = min(math.ceil(len(train_ds) / batch_size), max_steps_cap)\n",
    "total_steps = steps_per_epoch * epochs\n",
    "\n",
    "loss_fn = losses.MultipleNegativesRankingLoss(st_model)\n",
    "\n",
    "training_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"st-encoder-qlora-out\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    learning_rate=2e-4,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    num_train_epochs=epochs,\n",
    "    max_steps=total_steps,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"no\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    report_to=\"none\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_drop_last=True,\n",
    "    dataloader_num_workers=0,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=st_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    loss=loss_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "87867341-baf0-4a26-969b-0b0b795d6278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=10.47GB, reserved=14.91GB, peak=13.94GB\n",
      "NVML used=16.27GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9cfe28ba-a91a-47f3-83e2-75d91afb297e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipped Embedding(250002, 1024, padding_idx=1): 244.142578125M params\n",
      "skipped Embedding(514, 1024, padding_idx=1): 244.64453125M params\n",
      "skipped Embedding(1, 1024): 244.6455078125M params\n",
      "skipped: 244.6455078125M params\n",
      "***** Running training *****\n",
      "  Num examples = 2,000\n",
      "  Num Epochs = 40\n",
      "  Instantaneous batch size per device = 32\n",
      "  Training with DataParallel so batch size has been adjusted to: 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 315\n",
      "  Number of trainable parameters = 7,110,656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [315/315 7:13:06, Epoch 39/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.198900</td>\n",
       "      <td>0.055596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.057347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.057545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>0.059949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.059919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>0.059835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 16\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 16\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 16\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 16\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 16\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=315, training_loss=0.24426108958229187, metrics={'train_runtime': 26072.3939, 'train_samples_per_second': 3.093, 'train_steps_per_second': 0.012, 'total_flos': 0.0, 'train_loss': 0.24426108958229187, 'epoch': 39.38709677419355})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a40f2658-6dd3-4d03-9e35-9e73ffda1847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=10.48GB, reserved=19.19GB, peak=18.06GB\n",
      "NVML used=20.56GB / total=23.99GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ecf6f259-b021-4f02-813c-a02c625045bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/viv232/.cache/huggingface/hub/models--intfloat--multilingual-e5-large/snapshots/0dc5580a448e4284468b8909bae50fa925907bc5/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"dtype\": \"float32\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "tokenizer config file saved in st-encoder-qlora-out/final_model/tokenizer_config.json\n",
      "Special tokens file saved in st-encoder-qlora-out/final_model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "st_model.save(\"st-encoder-qlora-out/final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2b251a2-11b8-4e5a-b330-4538c2314819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@5: 0.972\n"
     ]
    }
   ],
   "source": [
    "q_vecs_after = embed(queries, st_model)\n",
    "d_vecs_after = embed(docs, st_model)\n",
    "\n",
    "sims_after = np.matmul(q_vecs_after, d_vecs_after.T)\n",
    "\n",
    "k = min(5, sims_after.shape[1])\n",
    "topk_idx = np.argpartition(-sims_after, kth=k-1, axis=1)[:, :k]\n",
    "\n",
    "true_idx = np.arange(len(val_pairs))\n",
    "hits = (topk_idx == true_idx[:, None]).any(axis=1)\n",
    "hit5 = hits.mean()\n",
    "\n",
    "print(f\"Hit@5: {hit5:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da5bc1-435d-41f8-b547-0781aa557909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
